{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Spatial-omics pipeline and analysis","text":"<p>Built on top of SpatialData, Sopa enables processing and analyses of image-based spatial omics using a standard data structure and output. We currently support the following technologies: Xenium, MERSCOPE, CosMX, PhenoCycler, MACSIMA, Hyperion. Sopa was designed for generability and low memory consumption on large images (scales to <code>1TB+</code> images).</p> <p>The pipeline outputs contain: (i) Xenium Explorer files for interactive visualization, (ii) an HTML report for quick quality controls, and (iii) a SpatialData <code>.zarr</code> directory for further analyses.</p>"},{"location":"#overview","title":"Overview","text":"<p>The following illustration describes the main steps of <code>sopa</code>:</p> <p> </p>"},{"location":"#why-use-sopa","title":"Why use <code>sopa</code>","text":"<ul> <li><code>sopa</code> is designed to be memory-efficient, and it scales to large datasets with millions of cells</li> <li>Depending on your need, you can use our Snakemake pipeline, our CLI, or our API</li> <li>It's straightforward to move on to another spatial omics technology since <code>sopa</code> is general to every image-based spatial omics</li> <li>You can open any data with the Xenium Explorer, which is a user-friendly software with many functions</li> <li>Spatial statistics are optimized since geometric operations use <code>shapely</code> internally</li> <li>You can customize <code>sopa</code> and add your own segmentation or annotation tool if desired</li> <li><code>sopa</code> integrates naturally with other community tools such as Scanpy or Squidpy.</li> </ul>"},{"location":"cite_us/","title":"Cite us","text":"<p>Our article is published in Nature Communications. You can cite our paper as below:</p> <pre><code>@article{blampey_sopa_2024,\n    title = {Sopa: a technology-invariant pipeline for analyses of image-based spatial omics},\n    volume = {15},\n    url = {https://www.nature.com/articles/s41467-024-48981-z},\n    doi = {10.1038/s41467-024-48981-z},\n    journal = {Nature Communications},\n    author = {Blampey, Quentin and Mulder, Kevin and Gardet, Margaux and Christodoulidis, Stergios and Dutertre, Charles-Antoine and Andr\u00e9, Fabrice and Ginhoux, Florent and Courn\u00e8de, Paul-Henry},\n    year = {2024},\n    note = {Publisher: Nature Publishing Group},\n    pages = {4981},\n}\n</code></pre> <p>This library has been developed by Quentin Blampey, PhD student in Biomathematics / Deep Learning. The following institutions funded this work:</p> <ul> <li>Lab of Mathematics and Computer Science (MICS), CentraleSup\u00e9lec (Engineering School, Paris-Saclay University).</li> <li>PRISM center, Gustave Roussy Institute (Cancer campus, Paris-Saclay University).</li> </ul>"},{"location":"cli/","title":"CLI (command-line-interface)","text":""},{"location":"cli/#usage","title":"Usage","text":"<p>When installing <code>sopa</code> as written in our getting-started guidelines, a new command named <code>sopa</code> becomes available.</p> <p>CLI helper</p> <p>Run <code>sopa --help</code> to get details about all the command line purposes. You can also use this helper on any subcommand, for instance, <code>sopa read --help</code>.</p> <pre><code>// Run the Sopa CLI helper\n$ sopa --help\n Usage: sopa [OPTIONS] COMMAND [ARGS]...\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 aggregate     Aggregate transcripts/channels inside cells      \u2502\n\u2502 annotate      Perform cell-type annotation                     \u2502\n\u2502 check         Run some sanity checks                           \u2502\n\u2502 crop          Crop an image based on a user-defined polygon    \u2502\n\u2502 explorer      Conversion to the Xenium Explorer's inputs       \u2502\n\u2502 patchify      Create patches with overlaps                     \u2502\n\u2502 read          Read any technology + write a SpatialData object \u2502\n\u2502 report        Create a web-report with figures/QCs             \u2502\n\u2502 resolve       Resolve the segmentation conflicts over patches  \u2502\n\u2502 segmentation  Perform cell segmentation on patches             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n// Example: run cellpose segmentation\n$ sopa segmentation cellpose sdata.zarr\n... [Logs] ...\n</code></pre>"},{"location":"cli/#notes","title":"Notes","text":"<p>If you don't know in which order to run these commands, refer to the image in the homepage, or see our CLI usage tutorial.</p> <p>When running the <code>sopa</code> CLI, some arguments are required, while some are optional. For instance, for the <code>sopa read</code> command, <code>sdata_path</code> is an argument, and a path has to be given directly, while <code>technology</code> is an option (in this case, the <code>--technology</code> prefix has to be used). For instance, if you read MERSCOPE data, it will be:</p> <pre><code>sopa read /path/to/merscope/directory --technology merscope\n</code></pre> <p>Note that <code>/path/to/merscope/directory</code> refers to <code>sdata_path</code>, which is an argument. You should not add the suffix <code>--sdata_path</code>, as it is an argument.</p> <p>Required options</p> <p>All the arguments are required, as shown by the <code>[required]</code> hint on the CLI helper. Note that some options may also be required too (in this case, the term <code>[required]</code> will appear on the CLI helper). But they still need to be called as a normal option.</p>"},{"location":"cli/#sopa-commands","title":"<code>sopa</code> commands","text":"<p>Usage:</p> <pre><code>$ sopa [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>aggregate</code>: Create an <code>anndata</code> table containing the...</li> <li><code>annotate</code>: Perform cell-type annotation (based on...</li> <li><code>check</code>: Run some sanity checks (e.g., on the YAML...</li> <li><code>crop</code>: Crop an image based on a user-defined...</li> <li><code>explorer</code>: Convertion to the Xenium Explorer's...</li> <li><code>patchify</code>: Create patches with overlaps.</li> <li><code>read</code>: Read any technology data, and write a...</li> <li><code>report</code>: Create a HTML report of the pipeline run...</li> <li><code>resolve</code>: Resolve the segmentation conflicts over...</li> <li><code>segmentation</code>: Perform cell segmentation on patches.</li> </ul>"},{"location":"cli/#sopa-aggregate","title":"<code>sopa aggregate</code>","text":"<p>Create an <code>anndata</code> table containing the transcript count and/or the channel intensities per cell</p> <p>Usage:</p> <pre><code>$ sopa aggregate [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--gene-column TEXT</code>: Column of the transcript dataframe representing the gene names. If not provided, it will not compute transcript count</li> <li><code>--average-intensities / --no-average-intensities</code>: Whether to average the channel intensities inside each cell  [default: no-average-intensities]</li> <li><code>--expand-radius-ratio FLOAT</code>: Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code> for channels averaging only. This help better aggregate boundary stainings  [default: 0]</li> <li><code>--min-transcripts INTEGER</code>: Cells with less transcript than this integer will be filtered  [default: 0]</li> <li><code>--min-intensity-ratio FLOAT</code>: Cells whose mean channel intensity is less than <code>min_intensity_ratio * quantile_90</code> will be filtered  [default: 0]</li> <li><code>--image-key TEXT</code>: Optional image key of the SpatialData object. By default, considers the only one image. It can be useful if another image is added later on</li> <li><code>--method-name TEXT</code>: If segmentation was performed with a generic method, this is the name of the method used.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-annotate","title":"<code>sopa annotate</code>","text":"<p>Perform cell-type annotation (based on transcripts and/or channel intensities)</p> <p>Usage:</p> <pre><code>$ sopa annotate [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>fluorescence</code>: Simple annotation based on fluorescence,...</li> <li><code>tangram</code>: Tangram segmentation (i.e., uses an...</li> </ul>"},{"location":"cli/#sopa-annotate-fluorescence","title":"<code>sopa annotate fluorescence</code>","text":"<p>Simple annotation based on fluorescence, where each provided channel corresponds to one cell type.</p> <p>For each cell, one z-score statistic is computed and the population with the highest z-score is attributed.</p> <p>Usage:</p> <pre><code>$ sopa annotate fluorescence [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--marker-cell-dict TEXT</code>: [required]</li> <li><code>--cell-type-key TEXT</code>: Key added in <code>adata.obs</code> corresponding to the cell type  [default: cell_type]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-annotate-tangram","title":"<code>sopa annotate tangram</code>","text":"<p>Tangram segmentation (i.e., uses an annotated scRNAseq reference to transfer cell-types)</p> <p>Usage:</p> <pre><code>$ sopa annotate tangram [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--sc-reference-path TEXT</code>: Path to the scRNAseq annotated reference, as a <code>.h5ad</code> file  [required]</li> <li><code>--cell-type-key TEXT</code>: Key of <code>adata_ref.obs</code> containing the cell-types  [required]</li> <li><code>--reference-preprocessing TEXT</code>: Preprocessing method applied to the reference. Either None (raw counts), or <code>normalized</code> (sc.pp.normalize_total) or <code>log1p</code> (sc.pp.normalize_total and sc.pp.log1p)</li> <li><code>--bag-size INTEGER</code>: Number of cells in each bag of the spatial table. Low values will decrease the memory usage  [default: 10000]</li> <li><code>--max-obs-reference INTEGER</code>: Maximum samples to be considered in the reference for tangram. Low values will decrease the memory usage  [default: 10000]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-check","title":"<code>sopa check</code>","text":"<p>Run some sanity checks (e.g., on the YAML config, on the tangram reference, ...)</p> <p>Usage:</p> <pre><code>$ sopa check [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>config</code>: Perform sanity checks on a sopa yaml config</li> <li><code>reference</code>: Perform sanity checks on a tangram...</li> </ul>"},{"location":"cli/#sopa-check-config","title":"<code>sopa check config</code>","text":"<p>Perform sanity checks on a sopa yaml config</p> <p>Usage:</p> <pre><code>$ sopa check config [OPTIONS] PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>PATH</code>: Path to the YAML config  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-check-reference","title":"<code>sopa check reference</code>","text":"<p>Perform sanity checks on a tangram scRNAseq reference</p> <p>Usage:</p> <pre><code>$ sopa check reference [OPTIONS] REFERENCE_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>REFERENCE_PATH</code>: Path to the scRNAseq reference as a <code>.h5ad</code> file  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--cell-type-key TEXT</code>: Key of adata.obs containing the cell types  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-crop","title":"<code>sopa crop</code>","text":"<p>Crop an image based on a user-defined polygon (interactive mode).</p> <p>Usage</p> <ul> <li> <p>[Locally] Only <code>--sdata-path</code> is required</p> </li> <li> <p>[On a cluster] Run <code>sopa crop</code> with <code>--sdata-path</code> and <code>--intermediate-image</code> on the cluster. Then, download the image locally, and run <code>sopa crop</code> with <code>--intermediate-image</code> and <code>--intermediate-polygon</code>. Then, upload the polygon and run <code>sopa crop</code> on the cluster with <code>--sdata-path</code> and <code>--intermediate-polygon</code>.</p> </li> </ul> <p>Usage:</p> <pre><code>$ sopa crop [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--sdata-path TEXT</code>: Path to the SpatialData <code>.zarr</code> directory</li> <li><code>--intermediate-image TEXT</code>: Path to the intermediate image, with a <code>.zip</code> extension. Use this only if the interactive mode is not available</li> <li><code>--intermediate-polygon TEXT</code>: Path to the intermediate polygon, with a <code>.zip</code> extension. Use this locally, after downloading the intermediate_image</li> <li><code>--channels TEXT</code>: List of channel names to be displayed. Optional if there are already only 1 or 3 channels</li> <li><code>--scale-factor FLOAT</code>: Resize the image by this value (high value for a lower memory usage)  [default: 10]</li> <li><code>--margin-ratio FLOAT</code>: Ratio of the image margin on the display (compared to the image size)  [default: 0.1]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-explorer","title":"<code>sopa explorer</code>","text":"<p>Convertion to the Xenium Explorer's inputs, and image alignment</p> <p>Usage:</p> <pre><code>$ sopa explorer [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>add-aligned</code>: After alignment on the Xenium Explorer,...</li> <li><code>update-obs</code>: Update the cell categories for the Xenium...</li> <li><code>write</code>: Convert a spatialdata object to Xenium...</li> </ul>"},{"location":"cli/#sopa-explorer-add-aligned","title":"<code>sopa explorer add-aligned</code>","text":"<p>After alignment on the Xenium Explorer, add an image to the SpatialData object</p> <p>Usage:</p> <pre><code>$ sopa explorer add-aligned [OPTIONS] SDATA_PATH IMAGE_PATH TRANSFORMATION_MATRIX_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> <li><code>IMAGE_PATH</code>: Path to the image file to be added (<code>.ome.tif</code> used in the explorer during alignment)  [required]</li> <li><code>TRANSFORMATION_MATRIX_PATH</code>: Path to the <code>matrix.csv</code> file returned by the Explorer after alignment  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--original-image-key TEXT</code>: Optional original-image key (of sdata.images) on which the new image will be aligned. This doesn't need to be provided if there is only one image</li> <li><code>--overwrite / --no-overwrite</code>: Whether to overwrite the image if existing  [default: no-overwrite]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-explorer-update-obs","title":"<code>sopa explorer update-obs</code>","text":"<p>Update the cell categories for the Xenium Explorer's (i.e. what's in <code>adata.obs</code>). This is useful when you perform analysis and update your <code>AnnData</code> object</p> <p>Usage</p> <p>Make sure you have already run <code>sopa explorer write</code> before. This command should only be used if you updated <code>adata.obs</code></p> <p>Usage:</p> <pre><code>$ sopa explorer update-obs [OPTIONS] ADATA_PATH OUTPUT_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>ADATA_PATH</code>: Path to the anndata file (<code>zarr</code> or <code>h5ad</code>) containing the new observations  [required]</li> <li><code>OUTPUT_PATH</code>: Path to the Xenium Explorer directory (it will update <code>analysis.zarr.zip</code>)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-explorer-write","title":"<code>sopa explorer write</code>","text":"<p>Convert a spatialdata object to Xenium Explorer's inputs</p> <p>Usage:</p> <pre><code>$ sopa explorer write [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--output-path TEXT</code>: Path to a directory where Xenium Explorer's outputs will be saved. By default, writes to the same path as <code>sdata_path</code> but with the <code>.explorer</code> suffix</li> <li><code>--gene-column TEXT</code>: Column name of the points dataframe containing the gene names</li> <li><code>--shapes-key TEXT</code>: Sdata key for the boundaries. By default, uses the baysor boundaires, else the cellpose boundaries</li> <li><code>--pixel-size FLOAT</code>: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.  [default: 0.2125]</li> <li><code>--pixelsize FLOAT</code>: <code>pixelsize</code> is deprecated and will be removed in future versions. Use <code>pixel_size</code> instead.</li> <li><code>--lazy / --no-lazy</code>: If <code>True</code>, will not load the full images in memory (except if the image memory is below <code>ram_threshold_gb</code>)  [default: lazy]</li> <li><code>--ram-threshold-gb INTEGER</code>: Threshold (in gygabytes) from which image can be loaded in memory. If <code>None</code>, the image is never loaded in memory  [default: 4]</li> <li><code>--mode TEXT</code>: String that indicated which files should be created. <code>'-ib'</code> means everything except images and boundaries, while <code>'+tocm'</code> means only transcripts/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything</li> <li><code>--save-h5ad / --no-save-h5ad</code>: Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)  [default: save-h5ad]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-patchify","title":"<code>sopa patchify</code>","text":"<p>Create patches with overlaps. Afterwards, segmentation will be run on each patch</p> <p>Usage:</p> <pre><code>$ sopa patchify [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>baysor</code>: Prepare patches for transcript-based...</li> <li><code>comseg</code>: Prepare patches for transcript-based...</li> <li><code>image</code>: Prepare patches for staining-based...</li> </ul>"},{"location":"cli/#sopa-patchify-baysor","title":"<code>sopa patchify baysor</code>","text":"<p>Prepare patches for transcript-based segmentation with Baysor</p> <p>Usage:</p> <pre><code>$ sopa patchify baysor [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-width-microns FLOAT</code>: Width (and height) of each patch in microns  [required]</li> <li><code>--patch-overlap-microns FLOAT</code>: Number of overlapping microns between the patches. We advise to choose approximately twice the diameter of a cell  [required]</li> <li><code>--baysor-temp-dir TEXT</code>: Temporary directory where baysor inputs and outputs will be saved. By default, uses <code>.sopa_cache/baysor_boundaries</code></li> <li><code>--config-path TEXT</code>: Path to the baysor config (you can also directly provide the argument via the <code>config</code> option)</li> <li><code>--config TEXT</code>: Dictionnary of baysor parameters, overwrite the config_path argument if provided  [default: {}]</li> <li><code>--cell-key TEXT</code>: Optional column of the transcripts dataframe that indicates in which cell-id each transcript is, in order to use prior segmentation Default is 'cell' if cell_key=None</li> <li><code>--unassigned-value INTEGER</code>: If --cell-key is provided, this is the value given to transcripts that are not inside any cell (if it's already 0, don't provide this argument)</li> <li><code>--use-prior / --no-use-prior</code>: Whether to use cellpose segmentation as a prior for baysor (if True, make sure to first run Cellpose)  [default: no-use-prior]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-patchify-comseg","title":"<code>sopa patchify comseg</code>","text":"<p>Prepare patches for transcript-based segmentation with ComSeg</p> <p>Usage:</p> <pre><code>$ sopa patchify comseg [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-width-microns FLOAT</code>: Width (and height) of each patch in microns  [required]</li> <li><code>--patch-overlap-microns FLOAT</code>: Number of overlapping microns between the patches. We advise to choose approximately twice the diameter of a cell  [required]</li> <li><code>--comseg-temp-dir TEXT</code>: Temporary directory where baysor inputs and outputs will be saved. By default, uses <code>.sopa_cache/comseg_boundaries</code></li> <li><code>--config-path TEXT</code>: Path to the ComSeg json config file (you can also directly provide the argument via the <code>config</code> option)</li> <li><code>--config TEXT</code>: Dictionnary of ComSeg parameters, overwrite the config_path argument if provided  [default: {}]</li> <li><code>--cell-key TEXT</code>: Optional column of the transcripts dataframe that indicates in which cell-id each transcript is, in order to use prior segmentation. Default is cell if cell_key=None</li> <li><code>--unassigned-value INTEGER</code>: If --cell-key is provided, this is the value given to transcripts that are not inside any cell (if it's already 0, don't provide this argument)</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-patchify-image","title":"<code>sopa patchify image</code>","text":"<p>Prepare patches for staining-based segmentation (including Cellpose)</p> <p>Usage:</p> <pre><code>$ sopa patchify image [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-width-pixel FLOAT</code>: Width (and height) of each patch in pixels  [default: 5000]</li> <li><code>--patch-overlap-pixel FLOAT</code>: Number of overlapping pixels between the patches. We advise to choose approximately twice the diameter of a cell  [default: 100]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-read","title":"<code>sopa read</code>","text":"<p>Read any technology data, and write a standardized SpatialData object.</p> <p>Either <code>--technology</code> or <code>--config-path</code> has to be provided.</p> <p>Usage:</p> <pre><code>$ sopa read [OPTIONS] DATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>DATA_PATH</code>: Path to one data sample (most of the time, this corresponds to a directory with images files and eventually a transcript file)  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--technology TEXT</code>: Name of the technology used to collected the data (<code>xenium</code>/<code>merfish</code>/<code>cosmx</code>/<code>phenocycler</code>/<code>macsima</code>/<code>hyperion</code>)</li> <li><code>--sdata-path TEXT</code>: Optional path to write the SpatialData object. If not provided, will write to the <code>{data_path}.zarr</code> directory</li> <li><code>--config-path TEXT</code>: Path to the snakemake config. This can be useful in order not to provide the <code>--technology</code> and the <code>--kwargs</code> arguments</li> <li><code>--kwargs TEXT</code>: Dictionary provided to the reader function as kwargs  [default: {}]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-report","title":"<code>sopa report</code>","text":"<p>Create a HTML report of the pipeline run and some quality controls</p> <p>Usage:</p> <pre><code>$ sopa report [OPTIONS] SDATA_PATH PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> <li><code>PATH</code>: Path to the HTML report  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve","title":"<code>sopa resolve</code>","text":"<p>Resolve the segmentation conflicts over patches overlaps</p> <p>Usage:</p> <pre><code>$ sopa resolve [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>baysor</code>: Resolve patches conflicts after baysor...</li> <li><code>cellpose</code>: Resolve patches conflicts after cellpose...</li> <li><code>comseg</code>: Resolve patches conflicts after comseg...</li> <li><code>generic</code>: Resolve patches conflicts after generic...</li> </ul>"},{"location":"cli/#sopa-resolve-baysor","title":"<code>sopa resolve baysor</code>","text":"<p>Resolve patches conflicts after baysor segmentation. Provide either <code>--baysor-temp-dir</code> or <code>--patches-dirs</code></p> <p>Usage:</p> <pre><code>$ sopa resolve baysor [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--gene-column TEXT</code>: Column of the transcripts dataframe containing the genes names  [required]</li> <li><code>--baysor-temp-dir TEXT</code>: Path to the directory containing all the baysor patches (see <code>sopa patchify</code>). By default, uses the <code>.sopa_cache/baysor_boundaries</code> directory</li> <li><code>--min-area FLOAT</code>: Cells with an area less than this value (in microns^2) will be filtered  [default: 0]</li> <li><code>--patches-dirs TEXT</code>: List of patches directories inside <code>baysor_temp_dir</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve-cellpose","title":"<code>sopa resolve cellpose</code>","text":"<p>Resolve patches conflicts after cellpose segmentation</p> <p>Usage:</p> <pre><code>$ sopa resolve cellpose [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-dir TEXT</code>: Directory containing the cellpose segmentation on patches (or multiple directories if using multi-step segmentation). By default, uses the <code>.sopa_cache/cellpose_boundaries</code> directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve-comseg","title":"<code>sopa resolve comseg</code>","text":"<p>Resolve patches conflicts after comseg segmentation. Provide either <code>--comseg-temp-dir</code> or <code>--patches-dirs</code></p> <p>Usage:</p> <pre><code>$ sopa resolve comseg [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--gene-column TEXT</code>: Column of the transcripts dataframe containing the genes names  [required]</li> <li><code>--comseg-temp-dir TEXT</code>: Path to the directory containing all the comseg patches (see <code>sopa patchify</code>). By default, uses the <code>.sopa_cache/comseg_boundaries</code> directory</li> <li><code>--min-area FLOAT</code>: Cells with an area less than this value (in microns^2) will be filtered  [default: 0]</li> <li><code>--patches-dirs TEXT</code>: List of patches directories inside <code>comseg_temp_dir</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-resolve-generic","title":"<code>sopa resolve generic</code>","text":"<p>Resolve patches conflicts after generic segmentation</p> <p>Usage:</p> <pre><code>$ sopa resolve generic [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--method-name TEXT</code>: Name of the method used during segmentation. This is also the key correspnding to the boundaries in <code>sdata.shapes</code>  [required]</li> <li><code>--patch-dir TEXT</code>: Directory containing the generic segmentation on patches (or multiple directories if using multi-step segmentation). By default, uses the <code>.sopa_cache/&lt;method_name&gt;</code> directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-segmentation","title":"<code>sopa segmentation</code>","text":"<p>Perform cell segmentation on patches. NB: for <code>baysor</code>, use directly the <code>baysor</code> command line.</p> <p>Usage:</p> <pre><code>$ sopa segmentation [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>cellpose</code>: Perform cellpose segmentation.</li> <li><code>comseg</code>: Perform ComSeg segmentation.</li> <li><code>generic-staining</code>: Perform generic staining-based segmentation.</li> </ul>"},{"location":"cli/#sopa-segmentation-cellpose","title":"<code>sopa segmentation cellpose</code>","text":"<p>Perform cellpose segmentation. This can be done on all patches directly, or on one individual patch.</p> <p>Usage</p> <ul> <li> <p>[On one patch] Use this mode to run patches in parallel. Provide <code>--patch-index</code> to run one patch, and execute all patches in a parallel manner (you need to define your own parallelization, else, use the Snakemake pipeline).</p> </li> <li> <p>[On all patches at once] For small images, you can run the segmentation method sequentially (<code>--patch-index</code> is not needed)</p> </li> </ul> <p>Usage:</p> <pre><code>$ sopa segmentation cellpose [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--diameter FLOAT</code>: Cellpose diameter parameter  [required]</li> <li><code>--channels TEXT</code>: Names of the channels used for Cellpose. If one channel, then provide just a nucleus channel. If two channels, this is the nucleus and then the cytoplasm channel  [required]</li> <li><code>--flow-threshold FLOAT</code>: Cellpose <code>flow_threshold</code> parameter  [default: 2]</li> <li><code>--cellprob-threshold FLOAT</code>: Cellpose <code>cellprob_threshold</code> parameter  [default: -6]</li> <li><code>--model-type TEXT</code>: Name of the cellpose model  [default: cyto3]</li> <li><code>--pretrained-model TEXT</code>: Path to the pretrained model to be loaded</li> <li><code>--min-area INTEGER</code>: Minimum area (in pixels^2) for a cell to be considered as valid  [default: 0]</li> <li><code>--clip-limit FLOAT</code>: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)  [default: 0.2]</li> <li><code>--gaussian-sigma FLOAT</code>: Parameter for scipy gaussian_filter (applied before running cellpose)  [default: 1]</li> <li><code>--patch-index INTEGER</code>: Index of the patch on which cellpose should be run. NB: the number of patches is <code>len(sdata['sopa_patches'])</code></li> <li><code>--patch-dir TEXT</code>: Path to the temporary cellpose directory inside which we will store each individual patch segmentation. By default, saves into the <code>.sopa_cache/cellpose_boundaries</code> directory</li> <li><code>--method-kwargs TEXT</code>: Kwargs for the cellpose method builder. This should be a dictionnary, in inline string format.  [default: {}]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-segmentation-comseg","title":"<code>sopa segmentation comseg</code>","text":"<p>Perform ComSeg segmentation. This can be done on all patches directly, or on one individual patch.</p> <p>Usage:</p> <pre><code>$ sopa segmentation comseg [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--patch-index INTEGER</code>: Index of the patch on which the segmentation method should be run.`</li> <li><code>--patch-dir TEXT</code>: Path to the temporary the segmentation method directory inside which we will store each individual patch segmentation. By default, saves into the <code>.sopa_cache/comseg</code> directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#sopa-segmentation-generic-staining","title":"<code>sopa segmentation generic-staining</code>","text":"<p>Perform generic staining-based segmentation. This can be done on all patches directly, or on one individual patch.</p> <p>Usage</p> <p>First, define a new segmentation method, and write it under <code>sopa.segmentation.methods</code>. It should correspond to a function that is a \"callable builder\", i.e. kwargs will be provided to this function, and it will return a callable that will be applied on patches.</p> <p>As for Cellpose, two modes ara available:</p> <ul> <li> <p>[On one patch] Use this mode to run patches in parallel. Provide <code>--patch-index</code> to run one patch, and execute all patches in a parallel manner (you need to define your own parallelization, else, use the Snakemake pipeline).</p> </li> <li> <p>[On all patches at once] For small images, you can run the segmentation method sequentially (<code>--patch-index</code> is not needed)</p> </li> </ul> <p>Usage:</p> <pre><code>$ sopa segmentation generic-staining [OPTIONS] SDATA_PATH\n</code></pre> <p>Arguments:</p> <ul> <li><code>SDATA_PATH</code>: Path to the SpatialData <code>.zarr</code> directory  [required]</li> </ul> <p>Options:</p> <ul> <li><code>--method-name TEXT</code>: Name of the segmentation method builder to use. The corresponding function (<code>sopa.segmentation.methods.&lt;method_name&gt;</code>) will be used, and the kwargs below will be used to instantiate the method.  [required]</li> <li><code>--method-kwargs TEXT</code>: Kwargs for the method. This should be a dictionnary, in inline string format.  [default: {}]</li> <li><code>--channels TEXT</code>: Names of the channels used for segmentation.  [required]</li> <li><code>--min-area INTEGER</code>: Minimum area (in pixels^2) for a cell to be considered as valid  [default: 0]</li> <li><code>--clip-limit FLOAT</code>: Parameter for skimage.exposure.equalize_adapthist (applied before running the segmentation method)  [default: 0.2]</li> <li><code>--gaussian-sigma FLOAT</code>: Parameter for scipy gaussian_filter (applied before running the segmentation method)  [default: 1]</li> <li><code>--patch-index INTEGER</code>: Index of the patch on which the segmentation method should be run. NB: the number of patches is <code>len(sdata['sopa_patches'])</code></li> <li><code>--patch-dir TEXT</code>: Path to the temporary the segmentation method directory inside which we will store each individual patch segmentation. By default, saves into the <code>.sopa_cache/&lt;method_name&gt;</code> directory</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"faq/","title":"Frequently asked questions","text":""},{"location":"faq/#what-kind-of-inputs-do-i-need-to-run-sopa","title":"What kind of inputs do I need to run Sopa?","text":"<p>You need the raw inputs of your machine, that is:</p> <ul> <li> <p>One or multiple image(s), usually corresponding to one or multiple <code>.tiff</code> file(s)</p> </li> <li> <p>Optionally, a file of transcript location, usually a <code>.csv</code> or <code>.parquet</code> file</p> </li> </ul> <p>In this documentation, <code>data_path</code> denotes the path to your raw data. Select the correct tab below to understand what is the right path to your raw data:</p> XeniumMERSCOPECosMXMACSimaPhenoCyclerHyperionOthers (CZI, ...) <p><code>data_path</code> is the path to the directory containing the following files: <code>morphology.ome.tif</code>, <code>experiment.xenium</code> and <code>transcripts.parquet</code>. In brief, you should have this file structure:</p> <pre><code>.\n\u251c\u2500 morphology_focus.ome.tif   # or a directory (for recent versions of the Xenium)\n\u251c\u2500 experiment.xenium\n\u2514\u2500 transcripts.parquet\n</code></pre> <p><code>data_path</code> is the path to the \"region\" directory containing a <code>detected_transcripts.csv</code> file and an <code>images</code> directory. For instance, the directory may be called <code>region_0</code>. In brief, you should have this file structure:</p> <pre><code>.\n\u251c\u2500 detected_transcripts.csv\n\u2514\u2500 images\n   \u251c\u2500 mosaic_{stain}_z{z_layer}.tif\n   \u2514\u2500 micron_to_mosaic_pixel_transform.csv\n</code></pre> <p><code>data_path</code> is the path to the directory containing:</p> <ul> <li>a transcript file <code>*_tx_file</code> (with columns <code>target</code>, <code>x_global_px</code>, <code>y_global_px</code>)</li> <li>a FOV locations file <code>*_fov_positions_file</code> (with columns <code>FOV</code>, <code>X_mm</code>, <code>Y_mm</code>)</li> <li>a <code>Morphology_ChannelID_Dictionary.txt</code> file containing channel names</li> <li>a <code>Morphology2D</code> directory containing the images, end in <code>_F*.TIF</code>.</li> </ul> <p>These files must be exported as flat files in AtomX. That is: within a study, click on \"Export\" and then select files from the \"Flat CSV Files\" section (transcripts flat and FOV position flat). You should have this file structure:</p> <pre><code>.\n\u251c\u2500 &lt;DATASET_ID&gt;_tx_file.csv (or csv.gz)\n\u251c\u2500 &lt;DATASET_ID&gt;_fov_positions_file.csv (or csv.gz)\n\u251c\u2500 Morphology_ChannelID_Dictionary.txt\n\u2514\u2500 Morphology2D\n   \u251c\u2500 XXX_F001.TIF\n   \u251c\u2500 XXX_F002.TIF\n   \u2514\u2500 ...\n</code></pre> <p><code>data_path</code> is the path to the directory containing multiple <code>.ome.tif</code> files (one file per channel). In brief, you should have this file structure:</p> <pre><code>.\n\u251c\u2500 AAA.ome.tif\n\u251c\u2500 BBB.ome.tif\n\u2514\u2500 CCC.ome.tif\n</code></pre> <p><code>data_path</code> is the path to one <code>.qptiff</code> file, or one <code>.tif</code> file (if exported from QuPath).</p> <p><code>data_path</code> is path to the directory containing multiple <code>.ome.tiff</code> files (one file per channel). In brief, you should have this file structure: <pre><code>.\n\u251c\u2500 AAA.ome.tiff\n\u251c\u2500 BBB.ome.tiff\n\u2514\u2500 CCC.ome.tiff\n</code></pre></p> <p>Other file formats (ND2, CZI, LIF, or DV) are supported via the <code>aicsimageio</code> reader. In that case, you'll need to add new dependencies: <code>pip install aicsimageio</code> (and, for CZI data, also <code>pip install aicspylibczi</code>).</p> <p>This reader is called <code>aicsimageio</code>, i.e. you can use it via <code>sopa.io.aicsimageio(data_path)</code>, where <code>data_path</code> is the path to your data file containing your image(s). For the Snakemake pipeline, provide <code>aicsimageio</code> as a <code>technology</code> in the config file.</p>"},{"location":"faq/#i-have-small-artifact-cells-how-do-remove-them","title":"I have small artifact cells, how do remove them?","text":"<p>You may have small cells that were segmented but that should be removed. For that, <code>Sopa</code> offers three filtering approaches: using their area, their transcript count, or their fluorescence intensity. Refer to the following config parameters from this example config: <code>min_area</code>, <code>min_transcripts</code>, and <code>min_intensity_ratio</code>.</p> <p>If using the CLI, <code>--min-area</code> can be provided to <code>sopa segmentation cellpose</code> or <code>sopa resolve baysor</code>, and <code>--min-transcripts</code>/<code>--min-intensity-ratio</code> can be provided to <code>sopa aggregate</code>.</p>"},{"location":"faq/#cellpose-is-not-segmenting-enough-cells-what-should-i-do","title":"Cellpose is not segmenting enough cells; what should I do?","text":"<ul> <li>The main Cellpose parameter to check is <code>diameter</code>, i.e. a typical cell diameter in pixels. Note that this is highly specific to the technology you're using since the micron-to-pixel ratio can differ. We advise you to start with the default parameter for your technology of interest (see the <code>diameter</code> parameter inside our config files here).</li> <li>Maybe <code>min_area</code> is too high, and all the cells are filtered because they are smaller than this area. Remind that, when using Cellpose, the areas correspond to pixels^2.</li> <li>This can be due to a low image quality. If the image is too pixelated, consider increasing <code>gaussian_sigma</code> (e.g., <code>2</code>) under the cellpose parameters of our config. If the image has a low contrast, consider increasing <code>clip_limit</code> (e.g., <code>0.3</code>). These parameters are detailed in this example config.</li> <li>Consider updating the official Cellpose parameters. In particular, try <code>cellprob_threshold=-6</code> and <code>flow_threshold=2</code>.</li> </ul>"},{"location":"faq/#how-to-use-a-custom-cellpose-model","title":"How to use a custom Cellpose model?","text":"<p>You can use any existing Cellpose model with the <code>model_type</code> argument (via the API, CLI, or Snakemake pipeline). For the Snakemake pipeline, see here how to set this argument. If you have a custom pretrained model, use the <code>pretrained_model</code> argument instead of <code>model_type</code>, and give the path to your cellpose model.</p>"},{"location":"faq/#how-to-use-a-prior-cell-segmentation","title":"How to use a prior cell segmentation?","text":"<p>If you have MERSCOPE or Xenium data, you probably already have a cell segmentation. This can be used as a prior for Baysor, instead of running Cellpose with Sopa. For that, you have an existing config file for the Snakemake pipeline for both MERSCOPE and Xenium data. If using the API/CLI, consider using the <code>cell_key</code> and the <code>unassigned_value</code> arguments when creating the patches for the transcripts. For MERSCOPE data, <code>cell_key=\"cell_id\"</code> and <code>unassigned_value=-1</code>. For Xenium data, <code>cell_key=\"cell_id\"</code> and <code>unassigned_value=\"UNASSIGNED\"</code>.</p>"},{"location":"faq/#how-to-provide-dictionnaries-to-cli-arguments","title":"How to provide dictionnaries to CLI arguments?","text":"<p>Some CLI arguments are optionnal dictionnaries. For instance, <code>sopa read</code> has a <code>--kwargs</code> option. In that case, a dictionnary can be provided as an inline string, for instance:</p> <p><code>--kwargs \"{'backend': 'rioxarray'}\"</code></p>"},{"location":"faq/#how-to-fix-an-out-of-memory-issue-on-merscope-data","title":"How to fix an \"out-of-memory\" issue on MERSCOPE data?","text":"<p>If using MERSCOPE data, images can be huge. To improve RAM efficiency, you can install <code>rioxarray</code> (<code>pip install rioxarray</code>). Then, the <code>rioxarray</code> will be used by default by the reader (no change needed, it will be detected automatically).</p>"},{"location":"faq/#can-i-use-nextflow-instead-of-snakemake","title":"Can I use Nextflow instead of Snakemake?","text":"<p>Nextflow is not supported yet, but we are working on it. You can also help re-write our Snakemake pipeline for Nextflow (see issue #7).</p>"},{"location":"faq/#i-have-another-issue-how-do-i-fix-it","title":"I have another issue; how do I fix it?","text":"<p>Don't hesitate to open an issue on Sopa's Github repository, and detail your issue with as much precision as possible for the maintainers to be able to reproduce it.</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#installation","title":"Installation","text":"<p>Sopa can be installed on every OS with <code>pip</code> or <code>poetry</code>.</p> <p>The preferred Python version is <code>python==3.10</code>, but we also support <code>3.9</code> to <code>3.11</code>.</p> <p>Advice (optional)</p> <p>We advise creating a new environment via a package manager (except if you use Poetry, which will automatically create the environment).</p> <p>For instance, you can create a new <code>conda</code> environment:</p> <pre><code>conda create --name sopa python=3.10\nconda activate sopa\n</code></pre> <p>Choose one of the following, depending on your needs (it should take at most a few minutes):</p> From PyPILocal install (pip)Poetry (dev mode) <pre><code>pip install sopa\n\n# or to install extras\npip install 'sopa[cellpose,baysor,tangram]'\n</code></pre> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\npip install .\n</code></pre> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\npoetry install --all-extras\n</code></pre> <p>Baysor usage</p> <p>Even though <code>pip install 'sopa[baysor]'</code> will install some dependencies related to baysor, you still have to install the <code>baysor</code> command line (see the official repository) if you want to use it.</p>"},{"location":"getting_started/#snakemake-setup","title":"Snakemake setup","text":"<p>To use the Snakemake pipeline, the installation process is slightly different because you'll need the whole repository.</p> <ol> <li> <p>Clone the <code>sopa</code> repository, and move to the root of the project: <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n</code></pre></p> </li> <li> <p>Create a <code>conda</code> environment called <code>sopa</code>: <pre><code>conda create --name sopa python=3.10\n</code></pre></p> </li> <li> <p>At the root of the <code>sopa</code> directory, install the package in dev mode, and choose the extras you want (among cellpose/baysor/tangram, depending on your desired usage): <pre><code>conda activate sopa\npip install -e \".[snakemake,cellpose,baysor,tangram]\"\n</code></pre></p> </li> </ol> <p>Now, follow our snakemake tutorial to run your first pipeline.</p> <p>Note</p> <p>You can also use a separate environment for <code>snakemake</code>. In this case, you don't need to install the <code>'snakemake'</code> extra when installing <code>sopa</code>. But you may still need to install other extras, for instance, <code>'cellpose'</code> if you plan to run Cellpose.</p>"},{"location":"getting_started/#usage","title":"Usage","text":"<p>Sopa comes in three different flavours, each corresponding to a different use case:</p> <ul> <li><code>Snakemake pipeline</code>: choose a config, and run our pipeline on your spatial data in a few minutes. See our snakemake tutorial.</li> <li><code>CLI</code>: use our command-line-interface to prototype quickly your own pipeline</li> <li><code>API</code>: use directly <code>sopa</code> as a Python package for full flexibility and customization (see a tutorial here)</li> </ul>"},{"location":"api/_sdata/","title":"sopa._sdata","text":"<p>Note</p> <p>These are convenient tools that operates on <code>SpatialData</code> objects</p>"},{"location":"api/_sdata/#sopa._sdata.get_boundaries","title":"<code>sopa._sdata.get_boundaries(sdata, return_key=False, warn=False)</code>","text":"<p>Gets the baysor boundaries or cellpose boundaries of a SpatialData object after running Sopa</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>return_key</code> <code>bool</code> <p>Whether to return the key of the shapes or not.</p> <code>False</code> <code>warn</code> <code>bool</code> <p>If <code>True</code>, prints a warning if no boundary is found. Else, raises an error.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame | tuple[str, GeoDataFrame] | None</code> <p>A <code>GeoDataFrame</code> containing the boundaries, or a tuple <code>(shapes_key, geo_df)</code></p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_boundaries(\n    sdata: SpatialData, return_key: bool = False, warn: bool = False\n) -&gt; gpd.GeoDataFrame | tuple[str, gpd.GeoDataFrame] | None:\n    \"\"\"Gets the baysor boundaries or cellpose boundaries of a SpatialData object after running Sopa\n\n    Args:\n        sdata: A SpatialData object\n        return_key: Whether to return the key of the shapes or not.\n        warn: If `True`, prints a warning if no boundary is found. Else, raises an error.\n\n    Returns:\n        A `GeoDataFrame` containing the boundaries, or a tuple `(shapes_key, geo_df)`\n    \"\"\"\n    VALID_BOUNDARIES = [\n        SopaKeys.BAYSOR_BOUNDARIES,\n        SopaKeys.COMSEG_BOUNDARIES,\n        SopaKeys.CELLPOSE_BOUNDARIES,\n    ]\n    for shapes_key in VALID_BOUNDARIES:\n        res = _try_get_boundaries(sdata, shapes_key, return_key)\n        if res is not None:\n            return res\n\n    error_message = (\n        \"sdata object has no valid segmentation boundary. Consider running Sopa segmentation first.\"\n    )\n\n    if not warn:\n        raise ValueError(error_message)\n\n    log.warn(error_message)\n    return (None, None) if return_key else None\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.get_intrinsic_cs","title":"<code>sopa._sdata.get_intrinsic_cs(sdata, element, name=None)</code>","text":"<p>Gets the name of the intrinsic coordinate system of an element</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>element</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code>, or its key</p> required <code>name</code> <code>str | None</code> <p>Name to provide to the intrinsic coordinate system if not existing. By default, uses the element id.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Name of the intrinsic coordinate system</p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_intrinsic_cs(\n    sdata: SpatialData, element: SpatialElement | str, name: str | None = None\n) -&gt; str:\n    \"\"\"Gets the name of the intrinsic coordinate system of an element\n\n    Args:\n        sdata: A SpatialData object\n        element: `SpatialElement`, or its key\n        name: Name to provide to the intrinsic coordinate system if not existing. By default, uses the element id.\n\n    Returns:\n        Name of the intrinsic coordinate system\n    \"\"\"\n    if name is None:\n        name = f\"_{element if isinstance(element, str) else id(element)}_intrinsic\"\n\n    if isinstance(element, str):\n        element = sdata[element]\n\n    for cs, transform in get_transformation(element, get_all=True).items():\n        if isinstance(transform, Identity):\n            return cs\n\n    set_transformation(element, Identity(), name)\n    return name\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.to_intrinsic","title":"<code>sopa._sdata.to_intrinsic(sdata, element, element_cs)</code>","text":"<p>Transforms a <code>SpatialElement</code> into the intrinsic coordinate system of another <code>SpatialElement</code></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A SpatialData object</p> required <code>element</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code> to transform, or its key</p> required <code>element_cs</code> <code>SpatialElement | str</code> <p><code>SpatialElement</code> of the target coordinate system, or its key</p> required <p>Returns:</p> Type Description <code>SpatialElement</code> <p>The <code>SpatialElement</code> after transformation in the target coordinate system</p> Source code in <code>sopa/_sdata.py</code> <pre><code>def to_intrinsic(\n    sdata: SpatialData, element: SpatialElement | str, element_cs: SpatialElement | str\n) -&gt; SpatialElement:\n    \"\"\"Transforms a `SpatialElement` into the intrinsic coordinate system of another `SpatialElement`\n\n    Args:\n        sdata: A SpatialData object\n        element: `SpatialElement` to transform, or its key\n        element_cs: `SpatialElement` of the target coordinate system, or its key\n\n    Returns:\n        The `SpatialElement` after transformation in the target coordinate system\n    \"\"\"\n    if isinstance(element, str):\n        element = sdata[element]\n    cs = get_intrinsic_cs(sdata, element_cs)\n    return sdata.transform_element_to_coordinate_system(element, cs)\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.get_intensities","title":"<code>sopa._sdata.get_intensities(sdata)</code>","text":"<p>Gets the intensity dataframe of shape <code>n_obs x n_channels</code></p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_intensities(sdata: SpatialData) -&gt; pd.DataFrame | None:\n    \"\"\"Gets the intensity dataframe of shape `n_obs x n_channels`\"\"\"\n    assert SopaKeys.TABLE in sdata.tables, f\"No '{SopaKeys.TABLE}' found in sdata.tables\"\n\n    adata = sdata.tables[SopaKeys.TABLE]\n\n    if not adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_HAS_INTENSITIES]:\n        return None\n\n    if adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_HAS_TRANSCRIPTS]:\n        return adata.obsm[SopaKeys.INTENSITIES_OBSM]\n\n    return adata.to_df()\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.iter_scales","title":"<code>sopa._sdata.iter_scales(image)</code>","text":"<p>Iterates through all the scales of a <code>DataTree</code></p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>DataTree</code> <p>a <code>DataTree</code></p> required <p>Yields:</p> Type Description <code>DataArray</code> <p>Each scale (as a <code>xr.DataArray</code>)</p> Source code in <code>sopa/_sdata.py</code> <pre><code>def iter_scales(image: DataTree) -&gt; Iterator[xr.DataArray]:\n    \"\"\"Iterates through all the scales of a `DataTree`\n\n    Args:\n        image: a `DataTree`\n\n    Yields:\n        Each scale (as a `xr.DataArray`)\n    \"\"\"\n    assert isinstance(\n        image, DataTree\n    ), f\"Multiscale iteration is reserved for type DataTree. Found {type(image)}\"\n\n    for scale in image:\n        yield next(iter(image[scale].values()))\n</code></pre>"},{"location":"api/_sdata/#sopa._sdata.get_spatial_image","title":"<code>sopa._sdata.get_spatial_image(sdata, key=None, return_key=False)</code>","text":"<p>Gets a DataArray from a SpatialData object (if the image has multiple scale, the <code>scale0</code> is returned)</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>SpatialData object.</p> required <code>key</code> <code>str | None</code> <p>Optional image key. If <code>None</code>, returns the only image (if only one), or raises an error.</p> <code>None</code> <code>return_key</code> <code>bool</code> <p>Whether to also return the key of the image.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray | tuple[str, DataArray]</code> <p>If <code>return_key</code> is False, only the image is returned, else a tuple <code>(image_key, image)</code></p> Source code in <code>sopa/_sdata.py</code> <pre><code>def get_spatial_image(\n    sdata: SpatialData, key: str | None = None, return_key: bool = False\n) -&gt; DataArray | tuple[str, DataArray]:\n    \"\"\"Gets a DataArray from a SpatialData object (if the image has multiple scale, the `scale0` is returned)\n\n    Args:\n        sdata: SpatialData object.\n        key: Optional image key. If `None`, returns the only image (if only one), or raises an error.\n        return_key: Whether to also return the key of the image.\n\n    Returns:\n        If `return_key` is False, only the image is returned, else a tuple `(image_key, image)`\n    \"\"\"\n    key = get_key(sdata, \"images\", key)\n\n    assert key is not None, \"One image in `sdata.images` is required\"\n\n    image = sdata.images[key]\n    if isinstance(image, DataTree):\n        image = next(iter(image[\"scale0\"].values()))\n\n    if return_key:\n        return key, image\n    return image\n</code></pre>"},{"location":"api/annotation/","title":"sopa.annotation","text":""},{"location":"api/annotation/#sopa.annotation.tangram_annotate","title":"<code>sopa.annotation.tangram_annotate(sdata, adata_sc, cell_type_key, reference_preprocessing=None, bag_size=10000, max_obs_reference=10000, **kwargs)</code>","text":"<p>Tangram multi-level annotation. Tangram is run on multiple bags of cells to decrease the RAM usage.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>adata_sc</code> <code>AnnData</code> <p>A scRNAseq annotated reference</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata_sc.obs</code> containing the cell types. For multi-level annotation, provide other levels like such: if <code>cell_type_key = \"ct\"</code>, then <code>\"ct_level1\"</code> and <code>\"ct_level2\"</code> are the two next levels</p> required <code>reference_preprocessing</code> <code>str</code> <p>Preprocessing method used on the reference. Can be <code>\"log1p\"</code> (normalize_total + log1p) or <code>\"normalized\"</code> (just normalize_total). By default, consider that no processing was applied (raw counts)</p> <code>None</code> <code>bag_size</code> <code>int</code> <p>Size of each bag on which tangram will be run. Use smaller bags to lower the RAM usage</p> <code>10000</code> <code>max_obs_reference</code> <code>int</code> <p>Maximum number of cells used in <code>adata_sc</code> at each level. Decrease it to lower the RAM usage.</p> <code>10000</code> Source code in <code>sopa/annotation/tangram/run.py</code> <pre><code>def tangram_annotate(\n    sdata: SpatialData,\n    adata_sc: AnnData,\n    cell_type_key: str,\n    reference_preprocessing: str = None,\n    bag_size: int = 10_000,\n    max_obs_reference: int = 10_000,\n    **kwargs,\n):\n    \"\"\"Tangram multi-level annotation. Tangram is run on multiple bags of cells to decrease the RAM usage.\n\n    Args:\n        sdata: A `SpatialData` object\n        adata_sc: A scRNAseq annotated reference\n        cell_type_key: Key of `adata_sc.obs` containing the cell types. For multi-level annotation, provide other levels like such: if `cell_type_key = \"ct\"`, then `\"ct_level1\"` and `\"ct_level2\"` are the two next levels\n        reference_preprocessing: Preprocessing method used on the reference. Can be `\"log1p\"` (normalize_total + log1p) or `\"normalized\"` (just normalize_total). By default, consider that no processing was applied (raw counts)\n        bag_size: Size of each bag on which tangram will be run. Use smaller bags to lower the RAM usage\n        max_obs_reference: Maximum number of cells used in `adata_sc` at each level. Decrease it to lower the RAM usage.\n    \"\"\"\n    assert SopaKeys.TABLE in sdata.tables, f\"No '{SopaKeys.TABLE}' found in sdata.tables\"\n\n    ad_sp = sdata.tables[SopaKeys.TABLE]\n\n    MultiLevelAnnotation(\n        ad_sp,\n        adata_sc,\n        cell_type_key,\n        reference_preprocessing,\n        bag_size,\n        max_obs_reference,\n        **kwargs,\n    ).run()\n</code></pre>"},{"location":"api/annotation/#sopa.annotation.higher_z_score","title":"<code>sopa.annotation.higher_z_score(adata, marker_cell_dict, cell_type_key='cell_type')</code>","text":"<p>Simple channel-based segmentation using a marker-to-population dictionary</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>marker_cell_dict</code> <code>dict</code> <p>Dictionary whose keys are channels, and values are the corresponding populations.</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata.obs</code> where annotations will be stored</p> <code>'cell_type'</code> Source code in <code>sopa/annotation/fluorescence.py</code> <pre><code>def higher_z_score(adata: AnnData, marker_cell_dict: dict, cell_type_key: str = \"cell_type\"):\n    \"\"\"Simple channel-based segmentation using a marker-to-population dictionary\n\n    Args:\n        adata: An `AnnData` object\n        marker_cell_dict: Dictionary whose keys are channels, and values are the corresponding populations.\n        cell_type_key: Key of `adata.obs` where annotations will be stored\n    \"\"\"\n    adata.obsm[SopaKeys.Z_SCORES] = preprocess_fluo(adata)\n\n    markers, cell_types = list(marker_cell_dict.keys()), np.array(list(marker_cell_dict.values()))\n    ct_indices = adata.obsm[SopaKeys.Z_SCORES][markers].values.argmax(1)\n\n    adata.obs[cell_type_key] = cell_types[ct_indices]\n    adata.uns[SopaKeys.UNS_KEY][SopaKeys.UNS_CELL_TYPES] = [cell_type_key]\n\n    log.info(f\"Annotation counts: {adata.obs[cell_type_key].value_counts()}\")\n</code></pre>"},{"location":"api/annotation/#sopa.annotation.preprocess_fluo","title":"<code>sopa.annotation.preprocess_fluo(adata)</code>","text":"<p>Preprocess fluorescence data. For each column \\(X\\), we compute \\(asinh(\\frac{X}{5Q(0.2, X)})\\) and apply standardization</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A dataframe of preprocessed channels intensities</p> Source code in <code>sopa/annotation/fluorescence.py</code> <pre><code>def preprocess_fluo(adata: AnnData) -&gt; pd.DataFrame:\n    \"\"\"Preprocess fluorescence data. For each column $X$, we compute $asinh(\\\\frac{X}{5Q(0.2, X)})$ and apply standardization\n\n    Args:\n        adata: An `AnnData` object\n\n    Returns:\n        A dataframe of preprocessed channels intensities\n    \"\"\"\n    if SopaKeys.INTENSITIES_OBSM in adata.obsm:\n        df = adata.obsm[SopaKeys.INTENSITIES_OBSM]\n    else:\n        df = adata.to_df()\n\n    divider = 5 * np.quantile(df, 0.2, axis=0)\n    divider[divider == 0] = df.max(axis=0)[divider == 0]\n\n    scaled = np.arcsinh(df / divider)\n    return (scaled - scaled.mean(0)) / scaled.std(0)\n</code></pre>"},{"location":"api/io/","title":"sopa.io","text":"<p>Notes</p> <p>Due to many updates in the data format provided by the different companies, you might have issues loading your data. In this case, consider opening an issue detailing the version of the machine you used and the error log, as well as an example of file names that you are trying to read.</p> <p>Related to <code>spatialdata-io</code></p> <p>A library called <code>spatialdata-io</code> already contains a lot of readers. Here, we updated some readers already existing in <code>spatialdata-io</code>, and added a few others. In the future, we will completely rely on <code>spatialdata-io</code>.</p>"},{"location":"api/io/#readers","title":"Readers","text":""},{"location":"api/io/#sopa.io.xenium","title":"<code>sopa.io.xenium(path, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read Xenium data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> This function reads the following files <ul> <li><code>transcripts.parquet</code>: transcripts locations and names</li> <li><code>experiment.xenium</code>: metadata file</li> <li><code>morphology_focus.ome.tif</code>: morphology image (or a directory, for recent versions of the Xenium)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the Xenium directory containing all the experiment files</p> required <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the Xenium experiment</p> Source code in <code>sopa/io/reader/xenium.py</code> <pre><code>def xenium(\n    path: str | Path,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"Read Xenium data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.xenium.html).\n\n    This function reads the following files:\n        - `transcripts.parquet`: transcripts locations and names\n        - `experiment.xenium`: metadata file\n        - `morphology_focus.ome.tif`: morphology image (or a directory, for recent versions of the Xenium)\n\n\n    Args:\n        path: Path to the Xenium directory containing all the experiment files\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n\n    Returns:\n        A `SpatialData` object representing the Xenium experiment\n    \"\"\"\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    return xenium_spatialdata_io(\n        path,\n        cells_table=False,\n        aligned_images=False,\n        morphology_mip=False,\n        nucleus_labels=False,\n        cells_labels=False,\n        cells_as_circles=False,\n        nucleus_boundaries=False,\n        cells_boundaries=False,\n        image_models_kwargs=image_models_kwargs,\n        imread_kwargs=imread_kwargs,\n    )\n</code></pre>"},{"location":"api/io/#sopa.io.merscope","title":"<code>sopa.io.merscope(path, backend=None, z_layers=3, region_name=None, slide_name=None, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read MERSCOPE data as a <code>SpatialData</code> object. For more information, refer to spatialdata-io.</p> This function reads the following files <ul> <li><code>detected_transcripts.csv</code>: transcripts locations and names</li> <li>all the images under the <code>images</code> directory</li> <li><code>images/micron_to_mosaic_pixel_transform.csv</code>: affine transformation</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the MERSCOPE directory containing all the experiment files</p> required <code>backend</code> <code>Literal['dask_image', 'rioxarray'] | None</code> <p>Either <code>\"dask_image\"</code> or <code>\"rioxarray\"</code> (the latter uses less RAM, but requires <code>rioxarray</code> to be installed). By default, uses <code>\"rioxarray\"</code> if and only if the <code>rioxarray</code> library is installed.</p> <code>None</code> <code>z_layers</code> <code>int | list[int] | None</code> <p>Indices of the z-layers to consider. Either one <code>int</code> index, or a list of <code>int</code> indices. If <code>None</code>, then no image is loaded. By default, only the middle layer is considered (that is, layer 3).</p> <code>3</code> <code>region_name</code> <code>str | None</code> <p>Name of the region of interest, e.g., <code>'region_0'</code>. If <code>None</code> then the name of the <code>path</code> directory is used.</p> <code>None</code> <code>slide_name</code> <code>str | None</code> <p>Name of the slide/run. If <code>None</code> then the name of the parent directory of <code>path</code> is used (whose name starts with a date).</p> <code>None</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the MERSCOPE experiment</p> Source code in <code>sopa/io/reader/merscope.py</code> <pre><code>def merscope(\n    path: str | Path,\n    backend: Literal[\"dask_image\", \"rioxarray\"] | None = None,\n    z_layers: int | list[int] | None = 3,\n    region_name: str | None = None,\n    slide_name: str | None = None,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"Read MERSCOPE data as a `SpatialData` object. For more information, refer to [spatialdata-io](https://spatialdata.scverse.org/projects/io/en/latest/generated/spatialdata_io.merscope.html).\n\n    This function reads the following files:\n        - `detected_transcripts.csv`: transcripts locations and names\n        - all the images under the `images` directory\n        - `images/micron_to_mosaic_pixel_transform.csv`: affine transformation\n\n    Args:\n        path: Path to the MERSCOPE directory containing all the experiment files\n        backend: Either `\"dask_image\"` or `\"rioxarray\"` (the latter uses less RAM, but requires `rioxarray` to be installed). By default, uses `\"rioxarray\"` if and only if the `rioxarray` library is installed.\n        z_layers: Indices of the z-layers to consider. Either one `int` index, or a list of `int` indices. If `None`, then no image is loaded. By default, only the middle layer is considered (that is, layer 3).\n        region_name: Name of the region of interest, e.g., `'region_0'`. If `None` then the name of the `path` directory is used.\n        slide_name: Name of the slide/run. If `None` then the name of the parent directory of `path` is used (whose name starts with a date).\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n\n    Returns:\n        A `SpatialData` object representing the MERSCOPE experiment\n    \"\"\"\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    return merscope_spatialdata_io(\n        path,\n        backend=backend,\n        z_layers=z_layers,\n        region_name=region_name,\n        slide_name=slide_name,\n        image_models_kwargs=image_models_kwargs,\n        imread_kwargs=imread_kwargs,\n        cells_boundaries=False,\n        cells_table=False,\n    )\n</code></pre>"},{"location":"api/io/#sopa.io.cosmx","title":"<code>sopa.io.cosmx(path, dataset_id=None, fov=None, read_proteins=False, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read Cosmx Nanostring data. The fields of view are stitched together, except if <code>fov</code> is provided.</p> This function reads the following files <ul> <li><code>*_fov_positions_file.csv</code> or <code>*_fov_positions_file.csv.gz</code>: FOV locations</li> <li><code>Morphology2D</code> directory: all the FOVs morphology images</li> <li><code>Morphology_ChannelID_Dictionary.txt</code>: Morphology channels names</li> <li><code>*_tx_file.csv.gz</code> or <code>*_tx_file.csv</code>: Transcripts location and names</li> <li>If <code>read_proteins</code> is <code>True</code>, all the images under the nested <code>ProteinImages</code> directories will be read</li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the root directory containing Nanostring files.</p> required <code>dataset_id</code> <code>Optional[str]</code> <p>Optional name of the dataset (needs to be provided if not infered).</p> <code>None</code> <code>fov</code> <code>int | str | None</code> <p>Name or number of one single field of view to be read. If a string is provided, an example of correct syntax is \"F008\". By default, reads all FOVs.</p> <code>None</code> <code>read_proteins</code> <code>bool</code> <p>Whether to read the proteins or the transcripts.</p> <code>False</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object representing the CosMX experiment</p> Source code in <code>sopa/io/reader/cosmx.py</code> <pre><code>def cosmx(\n    path: str | Path,\n    dataset_id: Optional[str] = None,\n    fov: int | str | None = None,\n    read_proteins: bool = False,\n    image_models_kwargs: dict | None = None,\n    imread_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"\n    Read *Cosmx Nanostring* data. The fields of view are stitched together, except if `fov` is provided.\n\n    This function reads the following files:\n        - `*_fov_positions_file.csv` or `*_fov_positions_file.csv.gz`: FOV locations\n        - `Morphology2D` directory: all the FOVs morphology images\n        - `Morphology_ChannelID_Dictionary.txt`: Morphology channels names\n        - `*_tx_file.csv.gz` or `*_tx_file.csv`: Transcripts location and names\n        - If `read_proteins` is `True`, all the images under the nested `ProteinImages` directories will be read\n\n    Args:\n        path: Path to the root directory containing *Nanostring* files.\n        dataset_id: Optional name of the dataset (needs to be provided if not infered).\n        fov: Name or number of one single field of view to be read. If a string is provided, an example of correct syntax is \"F008\". By default, reads all FOVs.\n        read_proteins: Whether to read the proteins or the transcripts.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n\n    Returns:\n        A `SpatialData` object representing the CosMX experiment\n    \"\"\"\n    path = Path(path)\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    dataset_id = _infer_dataset_id(path, dataset_id)\n    fov_locs = _read_fov_locs(path, dataset_id)\n    fov_id, fov = _check_fov_id(fov)\n\n    protein_dir_dict = {}\n    if read_proteins:\n        protein_dir_dict = {\n            int(protein_dir.parent.name[3:]): protein_dir\n            for protein_dir in list(path.rglob(\"**/FOV*/ProteinImages\"))\n        }\n        assert len(protein_dir_dict), f\"No directory called 'ProteinImages' was found under {path}\"\n\n    ### Read image(s)\n    images_dir = _find_dir(path, \"Morphology2D\")\n    morphology_coords = _cosmx_morphology_coords(path)\n\n    if fov is None:\n        image, c_coords = _read_stitched_image(\n            images_dir,\n            fov_locs,\n            protein_dir_dict,\n            morphology_coords,\n            **imread_kwargs,\n        )\n        image_name = \"stitched_image\"\n    else:\n        pattern = f\"*{fov_id}.TIF\"\n        fov_files = list(images_dir.rglob(pattern))\n\n        assert len(fov_files), f\"No file matches the pattern {pattern} inside {images_dir}\"\n        assert (\n            len(fov_files) == 1\n        ), f\"Multiple files match the pattern {pattern}: {', '.join(fov_files)}\"\n\n        image, c_coords = _read_fov_image(\n            fov_files[0], protein_dir_dict.get(fov), morphology_coords, **imread_kwargs\n        )\n        image_name = f\"{fov}_image\"\n\n    parsed_image = Image2DModel.parse(\n        image, dims=(\"c\", \"y\", \"x\"), c_coords=c_coords, **image_models_kwargs\n    )\n\n    if read_proteins:\n        return SpatialData(images={image_name: parsed_image})\n\n    ### Read transcripts\n    transcripts_data = _read_transcripts_csv(path, dataset_id)\n\n    if fov is None:\n        transcripts_data[\"x\"] = transcripts_data[\"x_global_px\"] - fov_locs[\"xmin\"].min()\n        transcripts_data[\"y\"] = transcripts_data[\"y_global_px\"] - fov_locs[\"ymin\"].min()\n        coordinates = None\n        points_name = \"points\"\n    else:\n        transcripts_data = transcripts_data[transcripts_data[\"fov\"] == fov]\n        coordinates = {\"x\": \"x_local_px\", \"y\": \"y_local_px\"}\n        points_name = f\"{fov}_points\"\n\n    transcripts = PointsModel.parse(\n        transcripts_data,\n        coordinates=coordinates,\n        feature_key=CosmxKeys.TARGET_OF_TRANSCRIPT,\n    )\n\n    return SpatialData(images={image_name: parsed_image}, points={points_name: transcripts})\n</code></pre>"},{"location":"api/io/#sopa.io.macsima","title":"<code>sopa.io.macsima(path, **kwargs)</code>","text":"<p>Read MACSIMA data as a <code>SpatialData</code> object</p> Notes <p>For all dulicated name, their index will be added in brackets after, for instance you will often find <code>DAPI (000)</code> to indicate the DAPI channel of index <code>000</code></p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the MACSIMA <code>.tif</code> images</p> required <code>kwargs</code> <code>int</code> <p>Kwargs for <code>_general_tif_directory_reader</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/macsima.py</code> <pre><code>def macsima(path: Path, **kwargs: int) -&gt; SpatialData:\n    \"\"\"Read MACSIMA data as a `SpatialData` object\n\n    Notes:\n        For all dulicated name, their index will be added in brackets after, for instance you will often find `DAPI (000)` to indicate the DAPI channel of index `000`\n\n    Args:\n        path: Path to the directory containing the MACSIMA `.tif` images\n        kwargs: Kwargs for `_general_tif_directory_reader`\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    return _general_tif_directory_reader(\n        path, files_to_channels=_get_channel_names_macsima, **kwargs\n    )\n</code></pre>"},{"location":"api/io/#sopa.io.phenocycler","title":"<code>sopa.io.phenocycler(path, channels_renaming=None, image_models_kwargs=None)</code>","text":"<p>Read Phenocycler data as a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to a <code>.qptiff</code> file, or a <code>.tif</code> file (if exported from QuPath)</p> required <code>channels_renaming</code> <code>dict | None</code> <p>A dictionnary whose keys correspond to channels and values to their corresponding new name. Not all channels need to be renamed.</p> <code>None</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/phenocycler.py</code> <pre><code>def phenocycler(\n    path: str | Path, channels_renaming: dict | None = None, image_models_kwargs: dict | None = None\n) -&gt; SpatialData:\n    \"\"\"Read Phenocycler data as a `SpatialData` object\n\n    Args:\n        path: Path to a `.qptiff` file, or a `.tif` file (if exported from QuPath)\n        channels_renaming: A dictionnary whose keys correspond to channels and values to their corresponding new name. Not all channels need to be renamed.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs, _ = _default_image_kwargs(image_models_kwargs)\n\n    path = Path(path)\n    image_name = path.absolute().stem\n\n    if path.suffix == \".qptiff\":\n        with tf.TiffFile(path) as tif:\n            series = tif.series[0]\n            names = _get_channel_names_qptiff(series)\n\n            delayed_image = delayed(lambda series: series.asarray())(tif)\n            image = da.from_delayed(delayed_image, dtype=series.dtype, shape=series.shape)\n    elif path.suffix == \".tif\":\n        image = imread(path)\n        names = _get_IJ_channel_names(path)\n    else:\n        raise ValueError(f\"Unsupported file extension {path.suffix}. Must be '.qptiff' or '.tif'.\")\n\n    names = _rename_channels(names, channels_renaming)\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        transformations={\"pixels\": Identity()},\n        c_coords=names,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image})\n</code></pre>"},{"location":"api/io/#sopa.io.hyperion","title":"<code>sopa.io.hyperion(path, image_models_kwargs=None, imread_kwargs=None)</code>","text":"<p>Read Hyperion data as a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the directory containing the Hyperion <code>.tiff</code> images</p> required <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>imread_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>dask_image.imread.imread</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/hyperion.py</code> <pre><code>def hyperion(\n    path: Path, image_models_kwargs: dict | None = None, imread_kwargs: dict | None = None\n) -&gt; SpatialData:\n    \"\"\"Read Hyperion data as a `SpatialData` object\n\n    Args:\n        path: Path to the directory containing the Hyperion `.tiff` images\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        imread_kwargs: Keyword arguments passed to `dask_image.imread.imread`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs, imread_kwargs = _default_image_kwargs(image_models_kwargs, imread_kwargs)\n\n    files = [file for file in Path(path).iterdir() if file.suffix == \".tiff\"]\n\n    names = _get_channel_names_hyperion(files)\n    image = da.concatenate(\n        [imread(file, **imread_kwargs) for file in files],\n        axis=0,\n    )\n    image = (image / image.max(axis=(1, 2)).compute()[:, None, None] * 255).astype(np.uint8)\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    log.info(f\"Found channel names {names}\")\n\n    image_name = Path(path).absolute().stem\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        transformations={\"pixels\": Identity()},\n        c_coords=names,\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image})\n</code></pre>"},{"location":"api/io/#sopa.io.aicsimageio","title":"<code>sopa.io.aicsimageio(path, z_stack=0, image_models_kwargs=None, aics_kwargs=None)</code>","text":"<p>Read an image using AICSImageIO. It supports special formats such as <code>ND2</code>, <code>CZI</code>, <code>LIF</code>, or <code>DV</code>.</p> <p>Extra dependencies</p> <p>To use this reader, you'll need the <code>aicsimageio</code> dependency (<code>pip install aicsimageio</code>). To read <code>.czi</code> images, you'll also need to install <code>aicspylibczi</code> (for instance <code>pip install aicspylibczi</code>).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the image file</p> required <code>z_stack</code> <code>int</code> <p>(Only for 3D images) Index of the stack in the z-axis to use.</p> <code>0</code> <code>image_models_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>spatialdata.models.Image2DModel</code>.</p> <code>None</code> <code>aics_kwargs</code> <code>dict | None</code> <p>Keyword arguments passed to <code>aicsimageio.AICSImage</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A <code>SpatialData</code> object with a 2D-image of shape <code>(C, Y, X)</code></p> Source code in <code>sopa/io/reader/aics.py</code> <pre><code>def aicsimageio(\n    path: Path,\n    z_stack: int = 0,\n    image_models_kwargs: dict | None = None,\n    aics_kwargs: dict | None = None,\n) -&gt; SpatialData:\n    \"\"\"Read an image using [AICSImageIO](https://github.com/AllenCellModeling/aicsimageio). It supports special formats such as `ND2`, `CZI`, `LIF`, or `DV`.\n\n    !!! note \"Extra dependencies\"\n        To use this reader, you'll need the `aicsimageio` dependency (`pip install aicsimageio`). To read `.czi` images, you'll also need to install `aicspylibczi` (for instance `pip install aicspylibczi`).\n\n    Args:\n        path: Path to the image file\n        z_stack: (Only for 3D images) Index of the stack in the z-axis to use.\n        image_models_kwargs: Keyword arguments passed to `spatialdata.models.Image2DModel`.\n        aics_kwargs: Keyword arguments passed to `aicsimageio.AICSImage`.\n\n    Returns:\n        A `SpatialData` object with a 2D-image of shape `(C, Y, X)`\n    \"\"\"\n    image_models_kwargs, _ = _default_image_kwargs(image_models_kwargs, None)\n    aics_kwargs = {} if aics_kwargs is None else aics_kwargs\n\n    try:\n        from aicsimageio import AICSImage\n    except ImportError:\n        raise ImportError(\n            \"You need to install aicsimageio, e.g. by running `pip install aicsimageio`\"\n        )\n\n    xarr: xr.DataArray = AICSImage(path, **aics_kwargs).xarray_dask_data\n\n    assert (\n        len(xarr.coords[\"T\"]) == 1\n    ), f\"Only one time dimension is supported, found {len(xarr.coords['T'])}.\"\n\n    if len(xarr.coords[\"Z\"]) &gt; 1:\n        log.info(f\"3D image found, only reading {z_stack:=}\")\n\n    xarr = xarr.isel(T=0, Z=z_stack).rename({\"C\": \"c\", \"Y\": \"y\", \"X\": \"x\"})\n\n    image = Image2DModel.parse(xarr, c_coords=xarr.coords[\"c\"].values, **image_models_kwargs)\n\n    return SpatialData(images={\"image\": image})\n</code></pre>"},{"location":"api/io/#sopa.io.ome_tif","title":"<code>sopa.io.ome_tif(path, as_image=False)</code>","text":"<p>Read an <code>.ome.tif</code> image. This image should be a 2D image (with possibly multiple channels). Typically, this function can be used to open Xenium IF images.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the <code>.ome.tif</code> image</p> required <code>as_image</code> <code>bool</code> <p>If <code>True</code>, will return a <code>DataArray</code> object</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray | SpatialData</code> <p>A <code>DataArray</code> or a <code>SpatialData</code> object</p> Source code in <code>sopa/io/reader/utils.py</code> <pre><code>def ome_tif(path: Path, as_image: bool = False) -&gt; DataArray | SpatialData:\n    \"\"\"Read an `.ome.tif` image. This image should be a 2D image (with possibly multiple channels).\n    Typically, this function can be used to open Xenium IF images.\n\n    Args:\n        path: Path to the `.ome.tif` image\n        as_image: If `True`, will return a `DataArray` object\n\n    Returns:\n        A `DataArray` or a `SpatialData` object\n    \"\"\"\n    image_models_kwargs, _ = _default_image_kwargs()\n    image_name = Path(path).absolute().name.split(\".\")[0]\n    image: da.Array = imread(path)\n\n    if image.ndim == 4:\n        assert image.shape[0] == 1, \"4D images not supported\"\n        image = da.moveaxis(image[0], 2, 0)\n        log.info(f\"Transformed 4D image into a 3D image of shape (c, y, x) = {image.shape}\")\n    elif image.ndim != 3:\n        raise ValueError(f\"Number of dimensions not supported: {image.ndim}\")\n\n    image = image.rechunk(chunks=image_models_kwargs[\"chunks\"])\n\n    channel_names = _ome_channels_names(path)\n    if len(channel_names) != len(image):\n        channel_names = [str(i) for i in range(len(image))]\n        log.warn(f\"Channel names couldn't be read. Using {channel_names} instead.\")\n\n    image = DataArray(image, dims=[\"c\", \"y\", \"x\"], name=image_name, coords={\"c\": channel_names})\n\n    if as_image:\n        return image\n\n    image = Image2DModel.parse(\n        image,\n        dims=(\"c\", \"y\", \"x\"),\n        c_coords=channel_names,\n        transformations={\"pixels\": Identity()},\n        **image_models_kwargs,\n    )\n\n    return SpatialData(images={image_name: image})\n</code></pre>"},{"location":"api/io/#sopa.io.wsi","title":"<code>sopa.io.wsi(path, chunks=(3, 256, 256), as_image=False, backend='tiffslide')</code>","text":"<p>Read a WSI into a <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the WSI</p> required <code>chunks</code> <code>tuple[int, int, int]</code> <p>Tuple representing the chunksize for the dimensions <code>(C, Y, X)</code>.</p> <code>(3, 256, 256)</code> <code>as_image</code> <code>bool</code> <p>If <code>True</code>, returns a, image instead of a <code>SpatialData</code> object</p> <code>False</code> <code>backend</code> <code>str</code> <p>The library to use as a backend in order to load the WSI. One of: <code>\"openslide\"</code>, <code>\"tiffslide\"</code>.</p> <code>'tiffslide'</code> <p>Returns:</p> Type Description <code>SpatialData | DataTree</code> <p>A <code>SpatialData</code> object with a multiscale 2D-image of shape <code>(C, Y, X)</code>, or just the DataTree if <code>as_image=True</code></p> Source code in <code>sopa/io/reader/wsi.py</code> <pre><code>def wsi(\n    path: str | Path,\n    chunks: tuple[int, int, int] = (3, 256, 256),\n    as_image: bool = False,\n    backend: str = \"tiffslide\",\n) -&gt; SpatialData | DataTree:\n    \"\"\"Read a WSI into a `SpatialData` object\n\n    Args:\n        path: Path to the WSI\n        chunks: Tuple representing the chunksize for the dimensions `(C, Y, X)`.\n        as_image: If `True`, returns a, image instead of a `SpatialData` object\n        backend: The library to use as a backend in order to load the WSI. One of: `\"openslide\"`, `\"tiffslide\"`.\n\n    Returns:\n        A `SpatialData` object with a multiscale 2D-image of shape `(C, Y, X)`, or just the DataTree if `as_image=True`\n    \"\"\"\n    image_name, img, slide, slide_metadata = _open_wsi(path, backend=backend)\n\n    images = {}\n    for level, key in enumerate(list(img.keys())):\n        suffix = key if key != \"0\" else \"\"\n\n        scale_image = DataArray(\n            img[key].transpose(\"S\", f\"Y{suffix}\", f\"X{suffix}\"),\n            dims=(\"c\", \"y\", \"x\"),\n        ).chunk(chunks)\n\n        scale_factor = slide.level_downsamples[level]\n\n        scale_image = Image2DModel.parse(\n            scale_image[:3, :, :],\n            transformations={\"pixels\": _get_scale_transformation(scale_factor)},\n            c_coords=(\"r\", \"g\", \"b\"),\n        )\n        scale_image.coords[\"y\"] = scale_factor * scale_image.coords[\"y\"]\n        scale_image.coords[\"x\"] = scale_factor * scale_image.coords[\"x\"]\n\n        images[f\"scale{key}\"] = scale_image\n\n    multiscale_image = DataTree.from_dict(images)\n    sdata = SpatialData(images={image_name: multiscale_image})\n    sdata[image_name].attrs[\"metadata\"] = slide_metadata\n    sdata[image_name].attrs[\"backend\"] = backend\n    sdata[image_name].name = image_name\n\n    if as_image:\n        return multiscale_image\n\n    return sdata\n</code></pre>"},{"location":"api/io/#sopa.io.uniform","title":"<code>sopa.io.uniform(*_, length=2048, cell_density=0.0001, n_points_per_cell=100, c_coords=['DAPI', 'CK', 'CD3', 'CD20'], genes=['EPCAM', 'CD3E', 'CD20', 'CXCL4', 'CXCL10'], sigma_factor=0.05, pixel_size=0.1, seed=0, include_vertices=False, include_image=True, apply_blur=True, as_output=False)</code>","text":"<p>Generate a dummy dataset composed of cells generated uniformly in a square. It also has transcripts.</p> <p>Parameters:</p> Name Type Description Default <code>length</code> <code>int</code> <p>Size of the square, in pixels</p> <code>2048</code> <code>cell_density</code> <code>float</code> <p>Density of cells per pixel^2</p> <code>0.0001</code> <code>n_points_per_cell</code> <code>int</code> <p>Mean number of transcripts per cell</p> <code>100</code> <code>c_coords</code> <code>list[str]</code> <p>Channel names</p> <code>['DAPI', 'CK', 'CD3', 'CD20']</code> <code>genes</code> <code>int | list[str]</code> <p>Number of different genes, or list of gene names</p> <code>['EPCAM', 'CD3E', 'CD20', 'CXCL4', 'CXCL10']</code> <code>sigma_factor</code> <code>float</code> <p>Factor used to determine <code>sigma</code> for the gaussian blur.</p> <code>0.05</code> <code>pixel_size</code> <code>float</code> <p>Number of microns in one pixel.</p> <code>0.1</code> <code>seed</code> <code>int</code> <p>Numpy random seed</p> <code>0</code> <code>include_vertices</code> <code>bool</code> <p>Whether to include the vertices of the cells (as points) in the spatialdata object</p> <code>False</code> <code>include_image</code> <code>bool</code> <p>Whether to include the image in the spatialdata object</p> <code>True</code> <code>apply_blur</code> <code>bool</code> <p>Whether to apply gaussian blur on the image (without blur, cells are just one pixel)</p> <code>True</code> <code>as_output</code> <code>bool</code> <p>If <code>True</code>, the data will have the same format than an output of Sopa</p> <code>False</code> <p>Returns:</p> Type Description <code>SpatialData</code> <p>A SpatialData object with a 2D image (<code>sdata[\"image\"]</code>), the cells polygon boundaries (<code>sdata[\"cells\"]</code>), the transcripts (<code>sdata[\"transcripts\"]</code>), and optional cell vertices (<code>sdata[\"vertices\"]</code>) if <code>include_vertices</code> is <code>True</code>.</p> Source code in <code>sopa/utils/data.py</code> <pre><code>def uniform(\n    *_,\n    length: int = 2_048,\n    cell_density: float = 1e-4,\n    n_points_per_cell: int = 100,\n    c_coords: list[str] = [\"DAPI\", \"CK\", \"CD3\", \"CD20\"],\n    genes: int | list[str] = [\"EPCAM\", \"CD3E\", \"CD20\", \"CXCL4\", \"CXCL10\"],\n    sigma_factor: float = 0.05,\n    pixel_size: float = 0.1,\n    seed: int = 0,\n    include_vertices: bool = False,\n    include_image: bool = True,\n    apply_blur: bool = True,\n    as_output: bool = False,\n) -&gt; SpatialData:\n    \"\"\"Generate a dummy dataset composed of cells generated uniformly in a square. It also has transcripts.\n\n    Args:\n        length: Size of the square, in pixels\n        cell_density: Density of cells per pixel^2\n        n_points_per_cell: Mean number of transcripts per cell\n        c_coords: Channel names\n        genes: Number of different genes, or list of gene names\n        sigma_factor: Factor used to determine `sigma` for the gaussian blur.\n        pixel_size: Number of microns in one pixel.\n        seed: Numpy random seed\n        include_vertices: Whether to include the vertices of the cells (as points) in the spatialdata object\n        include_image: Whether to include the image in the spatialdata object\n        apply_blur: Whether to apply gaussian blur on the image (without blur, cells are just one pixel)\n        as_output: If `True`, the data will have the same format than an output of Sopa\n\n    Returns:\n        A SpatialData object with a 2D image (`sdata[\"image\"]`), the cells polygon boundaries (`sdata[\"cells\"]`), the transcripts (`sdata[\"transcripts\"]`), and optional cell vertices (`sdata[\"vertices\"]`) if `include_vertices` is `True`.\n    \"\"\"\n    np.random.seed(seed)\n\n    grid_width = max(1, int(length * np.sqrt(cell_density)))\n    dx = length / grid_width\n    sigma = dx * sigma_factor\n    n_cells = grid_width**2\n    radius = int(dx) // 4\n    cell_types_index = np.random.randint(0, max(1, len(c_coords) - 1), n_cells)\n\n    log.info(\n        f\"Image of size ({len(c_coords), length, length}) with {n_cells} cells and {n_points_per_cell} transcripts per cell\"\n    )\n\n    ### Compute cell vertices (xy array)\n    vertices_x = dx / 2 + np.arange(grid_width) * dx\n    x, y = np.meshgrid(vertices_x, vertices_x)\n    xy = np.stack([x.ravel(), y.ravel()], axis=1)\n    xy += np.random.uniform(-dx / 2, dx / 2, size=xy.shape)\n    xy = xy.clip(0, length - 1).astype(int)\n\n    vertices = pd.DataFrame(xy, columns=[\"x\", \"y\"])\n\n    ### Create image\n    images = {}\n\n    if include_image:\n        x_circle, y_circle = circle_coords(radius)\n\n        image = np.zeros((len(c_coords), length, length))\n        for i, (x, y) in enumerate(xy):\n            y_coords = (y + y_circle).clip(0, image.shape[1] - 1)\n            x_coords = (x + x_circle).clip(0, image.shape[2] - 1)\n            image[0, y_coords, x_coords] = 1\n            if len(c_coords) &gt; 1:\n                image[cell_types_index[i] + 1, y_coords, x_coords] = 1\n        if apply_blur:\n            image = gaussian_filter(image, sigma=sigma, axes=(1, 2))\n        image = (image / image.max() * 255).astype(np.uint8)\n        image = da.from_array(image, chunks=(1, 1024, 1024))\n        images[\"image\"] = Image2DModel.parse(image, c_coords=c_coords, dims=[\"c\", \"y\", \"x\"])\n\n    ### Create cell boundaries\n    cells = [Point(vertex).buffer(radius).simplify(tolerance=1) for vertex in xy]\n    bbox = box(0, 0, length - 1, length - 1)\n    cells = [cell.intersection(bbox) for cell in cells]\n    gdf = gpd.GeoDataFrame(geometry=cells)\n    shapes = {\"cellpose_boundaries\" if as_output else \"cells\": ShapesModel.parse(gdf)}\n\n    ### Create transcripts\n    n_genes = n_cells * n_points_per_cell\n    point_cell_index = np.arange(n_cells).repeat(n_points_per_cell)\n    points_coords = radius / 2 * np.random.randn(n_genes, 2) + xy[point_cell_index]\n    points_coords = points_coords.clip(0, length - 1)\n\n    if isinstance(genes, int):\n        gene_names = np.random.choice([chr(97 + i) for i in range(n_genes)], size=n_genes)\n    elif len(genes) and len(genes) &gt;= len(c_coords) - 1:\n        gene_names = np.full(n_genes, \"\", dtype=\"&lt;U5\")\n        for i in range(len(genes)):\n            where_cell_type = np.where(cell_types_index[point_cell_index] == i)[0]\n            probabilities = np.full(len(genes), 0.2 / (len(genes) - 1))\n            probabilities[i] = 0.8\n            gene_names[where_cell_type] = np.random.choice(\n                genes, len(where_cell_type), p=probabilities\n            )\n    else:\n        gene_names = np.random.choice(genes, size=n_genes)\n\n    df = pd.DataFrame(\n        {\n            \"x\": points_coords[:, 0],\n            \"y\": points_coords[:, 1],\n            \"z\": 1,\n            \"genes\": gene_names,\n        }\n    )\n\n    # apply an arbritrary transformation for a more complete test case\n    affine = np.array([[pixel_size, 0, 100], [0, pixel_size, 600], [0, 0, 1]])\n    df[[\"x\", \"y\", \"z\"]] = df[[\"x\", \"y\", \"z\"]] @ affine.T\n    affine = Affine(affine, input_axes=[\"x\", \"y\"], output_axes=[\"x\", \"y\"]).inverse()\n\n    df = dd.from_pandas(df, chunksize=2_000_000)\n\n    points = {\n        \"transcripts\": PointsModel.parse(\n            df, transformations={\"global\": affine, \"microns\": Identity()}\n        )\n    }\n    if include_vertices:\n        points[\"vertices\"] = PointsModel.parse(vertices)\n\n    sdata = SpatialData(images=images, points=points, shapes=shapes)\n\n    _map_transcript_to_cell(sdata, \"cell_id\", sdata[\"transcripts\"], sdata[\"cells\"])\n    sdata[\"transcripts\"][\"cell_id\"] = sdata[\"transcripts\"][\"cell_id\"].astype(int)\n\n    if as_output:\n        _add_table(sdata)\n\n    return sdata\n</code></pre>"},{"location":"api/io/#sopa.io.blobs","title":"<code>sopa.io.blobs(*_, length=1024, n_points=10000, c_coords=['DAPI', 'CK', 'CD3', 'CD20'], **kwargs)</code>","text":"<p>Adapts the blobs dataset from SpatialData for sopa. Please refer to the SpatialData documentation</p> Source code in <code>sopa/utils/data.py</code> <pre><code>def blobs(\n    *_,\n    length: int = 1_024,\n    n_points: int = 10_000,\n    c_coords=[\"DAPI\", \"CK\", \"CD3\", \"CD20\"],\n    **kwargs,\n) -&gt; SpatialData:\n    \"\"\"Adapts the blobs dataset from SpatialData for sopa. Please refer to the SpatialData documentation\"\"\"\n    _blobs = BlobsDataset(\n        length=length, n_points=n_points, c_coords=c_coords, n_channels=len(c_coords), **kwargs\n    )\n\n    image = _blobs._image_blobs(\n        _blobs.transformations,\n        _blobs.length,\n        _blobs.n_channels,\n        _blobs.c_coords,\n    )\n    image.data = (image.data * 255).astype(np.uint8)\n\n    points = _blobs._points_blobs(_blobs.transformations, _blobs.length, _blobs.n_points)\n    genes = pd.Series(np.random.choice(list(\"abcdef\"), size=len(points))).astype(\"category\")\n    points[\"genes\"] = dd.from_pandas(genes, npartitions=points.npartitions)\n\n    return SpatialData(images={\"blob_image\": image}, points={\"blob_transcripts\": points})\n</code></pre>"},{"location":"api/io/#xenium-explorer","title":"Xenium Explorer","text":""},{"location":"api/io/#sopa.io.write","title":"<code>sopa.io.write(path, sdata, image_key=None, shapes_key=None, points_key=None, gene_column=None, pixel_size=0.2125, layer=None, polygon_max_vertices=13, lazy=True, ram_threshold_gb=4, mode=None, save_h5ad=False)</code>","text":"<p>Transform a SpatialData object into inputs for the Xenium Explorer. After running this function, double-click on the <code>experiment.xenium</code> file to open it.</p> <p>Software download</p> <p>Make sure you have the latest version of the Xenium Explorer</p> Note <p>This function will create up to 7 files, depending on the <code>SpatialData</code> object and the arguments:</p> <ul> <li> <p><code>experiment.xenium</code> contains some experiment metadata. Double-click on this file to open the Xenium Explorer. This file can also be created with <code>write_metadata</code>.</p> </li> <li> <p><code>morphology.ome.tif</code> is the primary image. This file can also be created with <code>write_image</code>. Add more images with <code>align</code>.</p> </li> <li> <p><code>analysis.zarr.zip</code> contains the cells categories (or clusters), i.e. <code>adata.obs</code>. This file can also be created with <code>write_cell_categories</code>.</p> </li> <li> <p><code>cell_feature_matrix.zarr.zip</code> contains the cell-by-gene counts. This file can also be created with <code>write_gene_counts</code>.</p> </li> <li> <p><code>cells.zarr.zip</code> contains the cells polygon boundaries. This file can also be created with <code>write_polygons</code>.</p> </li> <li> <p><code>transcripts.zarr.zip</code> contains transcripts locations. This file can also be created with <code>write_transcripts</code>.</p> </li> <li> <p><code>adata.h5ad</code> is the <code>AnnData</code> object from the <code>SpatialData</code>. This is not used by the Explorer, but only saved for convenience.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the directory where files will be saved.</p> required <code>sdata</code> <code>SpatialData</code> <p>SpatialData object.</p> required <code>image_key</code> <code>str | None</code> <p>Name of the image of interest (key of <code>sdata.images</code>).</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Name of the cell shapes (key of <code>sdata.shapes</code>).</p> <code>None</code> <code>points_key</code> <code>str | None</code> <p>Name of the transcripts (key of <code>sdata.points</code>).</p> <code>None</code> <code>gene_column</code> <code>str | None</code> <p>Column name of the points dataframe containing the gene names.</p> <code>None</code> <code>pixel_size</code> <code>float</code> <p>Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.</p> <code>0.2125</code> <code>layer</code> <code>str | None</code> <p>Layer of the AnnData table where the gene counts are saved. If <code>None</code>, uses <code>table.X</code>.</p> <code>None</code> <code>polygon_max_vertices</code> <code>int</code> <p>Maximum number of vertices for the cell polygons.</p> <code>13</code> <code>lazy</code> <code>bool</code> <p>If <code>True</code>, will not load the full images in memory (except if the image memory is below <code>ram_threshold_gb</code>).</p> <code>True</code> <code>ram_threshold_gb</code> <code>int | None</code> <p>Threshold (in gygabytes) from which image can be loaded in memory. If <code>None</code>, the image is never loaded in memory.</p> <code>4</code> <code>mode</code> <code>str</code> <p>string that indicated which files should be created. \"-ib\" means everything except images and boundaries, while \"+tocm\" means only transcripts/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything.</p> <code>None</code> <code>save_h5ad</code> <code>bool</code> <p>Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)</p> <code>False</code> Source code in <code>sopa/io/explorer/converter.py</code> <pre><code>def write(\n    path: str,\n    sdata: SpatialData,\n    image_key: str | None = None,\n    shapes_key: str | None = None,\n    points_key: str | None = None,\n    gene_column: str | None = None,\n    pixel_size: float = 0.2125,\n    layer: str | None = None,\n    polygon_max_vertices: int = 13,\n    lazy: bool = True,\n    ram_threshold_gb: int | None = 4,\n    mode: str = None,\n    save_h5ad: bool = False,\n) -&gt; None:\n    \"\"\"\n    Transform a SpatialData object into inputs for the Xenium Explorer.\n    After running this function, double-click on the `experiment.xenium` file to open it.\n\n    !!! note \"Software download\"\n        Make sure you have the latest version of the [Xenium Explorer](https://www.10xgenomics.com/support/software/xenium-explorer)\n\n    Note:\n        This function will create up to 7 files, depending on the `SpatialData` object and the arguments:\n\n        - `experiment.xenium` contains some experiment metadata. Double-click on this file to open the Xenium Explorer. This file can also be created with [`write_metadata`](./#sopa.io.explorer.write_metadata).\n\n        - `morphology.ome.tif` is the primary image. This file can also be created with [`write_image`](./#sopa.io.explorer.write_image). Add more images with `align`.\n\n        - `analysis.zarr.zip` contains the cells categories (or clusters), i.e. `adata.obs`. This file can also be created with [`write_cell_categories`](./#sopa.io.explorer.write_cell_categories).\n\n        - `cell_feature_matrix.zarr.zip` contains the cell-by-gene counts. This file can also be created with [`write_gene_counts`](./#sopa.io.explorer.write_gene_counts).\n\n        - `cells.zarr.zip` contains the cells polygon boundaries. This file can also be created with [`write_polygons`](./#sopa.io.explorer.write_polygons).\n\n        - `transcripts.zarr.zip` contains transcripts locations. This file can also be created with [`write_transcripts`](./#sopa.io.explorer.write_transcripts).\n\n        - `adata.h5ad` is the `AnnData` object from the `SpatialData`. This is **not** used by the Explorer, but only saved for convenience.\n\n    Args:\n        path: Path to the directory where files will be saved.\n        sdata: SpatialData object.\n        image_key: Name of the image of interest (key of `sdata.images`).\n        shapes_key: Name of the cell shapes (key of `sdata.shapes`).\n        points_key: Name of the transcripts (key of `sdata.points`).\n        gene_column: Column name of the points dataframe containing the gene names.\n        pixel_size: Number of microns in a pixel. Invalid value can lead to inconsistent scales in the Explorer.\n        layer: Layer of the AnnData table where the gene counts are saved. If `None`, uses `table.X`.\n        polygon_max_vertices: Maximum number of vertices for the cell polygons.\n        lazy: If `True`, will not load the full images in memory (except if the image memory is below `ram_threshold_gb`).\n        ram_threshold_gb: Threshold (in gygabytes) from which image can be loaded in memory. If `None`, the image is never loaded in memory.\n        mode: string that indicated which files should be created. \"-ib\" means everything except images and boundaries, while \"+tocm\" means only transcripts/observations/counts/metadata (each letter corresponds to one explorer file). By default, keeps everything.\n        save_h5ad: Whether to save the adata as h5ad in the explorer directory (for convenience only, since h5ad is faster to open than the original .zarr table)\n    \"\"\"\n    path: Path = Path(path)\n    _check_explorer_directory(path)\n\n    image_key, image = get_spatial_image(sdata, image_key, return_key=True)\n\n    ### Saving cell categories and gene counts\n    if SopaKeys.TABLE in sdata.tables:\n        adata = sdata.tables[SopaKeys.TABLE]\n\n        shapes_key = adata.uns[\"spatialdata_attrs\"][\"region\"]\n        geo_df = sdata[shapes_key]\n\n        if _should_save(mode, \"c\"):\n            write_gene_counts(path, adata, layer=layer)\n        if _should_save(mode, \"o\"):\n            write_cell_categories(path, adata)\n\n    ### Saving cell boundaries\n    if shapes_key is None:\n        shapes_key, geo_df = get_boundaries(sdata, return_key=True, warn=True)\n    else:\n        geo_df = sdata[shapes_key]\n\n    if _should_save(mode, \"b\") and geo_df is not None:\n        geo_df = to_intrinsic(sdata, geo_df, image_key)\n\n        if SopaKeys.TABLE in sdata.tables:\n            geo_df = geo_df.loc[adata.obs[adata.uns[\"spatialdata_attrs\"][\"instance_key\"]]]\n\n        write_polygons(path, geo_df.geometry, polygon_max_vertices, pixel_size=pixel_size)\n\n    ### Saving transcripts\n    df = get_element(sdata, \"points\", points_key)\n\n    if _should_save(mode, \"t\") and df is not None:\n        if gene_column is not None:\n            df = to_intrinsic(sdata, df, image_key)\n            write_transcripts(path, df, gene_column, pixel_size=pixel_size)\n        else:\n            log.warn(\"The argument 'gene_column' has to be provided to save the transcripts\")\n\n    ### Saving image\n    if _should_save(mode, \"i\"):\n        write_image(\n            path,\n            sdata[image_key],\n            lazy=lazy,\n            ram_threshold_gb=ram_threshold_gb,\n            pixel_size=pixel_size,\n        )\n\n    ### Saving experiment.xenium file\n    if _should_save(mode, \"m\"):\n        write_metadata(path, image_key, shapes_key, _get_n_obs(sdata, geo_df), pixel_size)\n\n    if save_h5ad and SopaKeys.TABLE in sdata.tables:\n        sdata.tables[SopaKeys.TABLE].write_h5ad(path / FileNames.H5AD)\n\n    log.info(f\"Saved files in the following directory: {path}\")\n    log.info(f\"You can open the experiment with 'open {path / FileNames.METADATA}'\")\n</code></pre>"},{"location":"api/io/#sopa.io.align","title":"<code>sopa.io.align(sdata, image, transformation_matrix_path, image_key=None, overwrite=False)</code>","text":"<p>Add an image to the <code>SpatialData</code> object after alignment with the Xenium Explorer.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>image</code> <code>DataArray</code> <p>A <code>DataArray</code> object. Note that <code>image.name</code> is used as the key for the aligned image.</p> required <code>transformation_matrix_path</code> <code>str</code> <p>Path to the <code>.csv</code> transformation matrix exported from the Xenium Explorer</p> required <code>image_key</code> <code>str</code> <p>Optional name of the image on which it has been aligned. Required if multiple images in the <code>SpatialData</code> object.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the image, if already existing.</p> <code>False</code> Source code in <code>sopa/io/explorer/images.py</code> <pre><code>def align(\n    sdata: SpatialData,\n    image: DataArray,\n    transformation_matrix_path: str,\n    image_key: str = None,\n    overwrite: bool = False,\n):\n    \"\"\"Add an image to the `SpatialData` object after alignment with the Xenium Explorer.\n\n    Args:\n        sdata: A `SpatialData` object\n        image: A `DataArray` object. Note that `image.name` is used as the key for the aligned image.\n        transformation_matrix_path: Path to the `.csv` transformation matrix exported from the Xenium Explorer\n        image_key: Optional name of the image on which it has been aligned. Required if multiple images in the `SpatialData` object.\n        overwrite: Whether to overwrite the image, if already existing.\n    \"\"\"\n    image_name = image.name\n\n    to_pixel = Affine(\n        np.genfromtxt(transformation_matrix_path, delimiter=\",\"),\n        input_axes=(\"x\", \"y\"),\n        output_axes=(\"x\", \"y\"),\n    )\n\n    default_image = get_spatial_image(sdata, image_key)\n    pixel_cs = get_intrinsic_cs(sdata, default_image)\n\n    set_transformation(image, {pixel_cs: to_pixel}, set_all=True)\n\n    log.info(f\"Adding image {image_name}:\\n{image}\")\n    sdata.images[image_name] = image\n\n    if sdata.is_backed():\n        sdata.write_element(image_name, overwrite=overwrite)\n</code></pre>"},{"location":"api/io/#sopa.io.add_explorer_selection","title":"<code>sopa.io.add_explorer_selection(sdata, path, shapes_key, image_key=None, pixel_size=0.2125)</code>","text":"<p>After saving a selection on the Xenium Explorer, it will add all polygons inside <code>sdata.shapes[shapes_key]</code></p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>path</code> <code>str</code> <p>The path to the <code>coordinates.csv</code> selection file</p> required <code>shapes_key</code> <code>str</code> <p>The name to provide to the shapes</p> required <code>image_key</code> <code>str | None</code> <p>The original image name</p> <code>None</code> <code>pixel_size</code> <code>float</code> <p>Number of microns in a pixel. It must be the same value as the one used in <code>sopa.io.write</code></p> <code>0.2125</code> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def add_explorer_selection(\n    sdata: SpatialData,\n    path: str,\n    shapes_key: str,\n    image_key: str | None = None,\n    pixel_size: float = 0.2125,\n):\n    \"\"\"After saving a selection on the Xenium Explorer, it will add all polygons inside `sdata.shapes[shapes_key]`\n\n    Args:\n        sdata: A `SpatialData` object\n        path: The path to the `coordinates.csv` selection file\n        shapes_key: The name to provide to the shapes\n        image_key: The original image name\n        pixel_size: Number of microns in a pixel. It must be the same value as the one used in `sopa.io.write`\n    \"\"\"\n    polys = xenium_explorer_selection(path, pixel_size=pixel_size, return_list=True)\n    image = get_element(sdata, \"images\", image_key)\n\n    transformations = get_transformation(image, get_all=True).copy()\n\n    sdata.shapes[shapes_key] = ShapesModel.parse(\n        gpd.GeoDataFrame(geometry=polys), transformations=transformations\n    )\n</code></pre>"},{"location":"api/io/#sopa.io.int_cell_id","title":"<code>sopa.io.int_cell_id(explorer_cell_id)</code>","text":"<p>Transforms an alphabetical cell id from the Xenium Explorer to an integer ID</p> <p>E.g., int_cell_id('aaaachba-1') = 10000</p> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def int_cell_id(explorer_cell_id: str) -&gt; int:\n    \"\"\"Transforms an alphabetical cell id from the Xenium Explorer to an integer ID\n\n    E.g., int_cell_id('aaaachba-1') = 10000\"\"\"\n    code = explorer_cell_id[:-2] if explorer_cell_id[-2] == \"-\" else explorer_cell_id\n    coefs = [ord(c) - 97 for c in code][::-1]\n    return sum(value * 16**i for i, value in enumerate(coefs))\n</code></pre>"},{"location":"api/io/#sopa.io.str_cell_id","title":"<code>sopa.io.str_cell_id(cell_id)</code>","text":"<p>Transforms an integer cell ID into an Xenium Explorer alphabetical cell id</p> <p>E.g., str_cell_id(10000) = 'aaaachba-1'</p> Source code in <code>sopa/io/explorer/utils.py</code> <pre><code>def str_cell_id(cell_id: int) -&gt; str:\n    \"\"\"Transforms an integer cell ID into an Xenium Explorer alphabetical cell id\n\n    E.g., str_cell_id(10000) = 'aaaachba-1'\"\"\"\n    coefs = []\n    for _ in range(8):\n        cell_id, coef = divmod(cell_id, 16)\n        coefs.append(coef)\n    return \"\".join([chr(97 + coef) for coef in coefs][::-1]) + \"-1\"\n</code></pre>"},{"location":"api/io/#sopa.io.write_image","title":"<code>sopa.io.write_image(path, image, lazy=True, tile_width=TILE_SIZE, n_subscales=5, pixel_size=0.2125, ram_threshold_gb=4, is_dir=True)</code>","text":"<p>Convert an image into a <code>morphology.ome.tif</code> file that can be read by the Xenium Explorer</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the Xenium Explorer directory where the image will be written</p> required <code>image</code> <code>DataTree | DataArray | ndarray</code> <p>Image of shape <code>(C, Y, X)</code></p> required <code>lazy</code> <code>bool</code> <p>If <code>False</code>, the image will not be read in-memory (except if the image size is below <code>ram_threshold_gb</code>). If <code>True</code>, all the images levels are always loaded in-memory.</p> <code>True</code> <code>tile_width</code> <code>int</code> <p>Xenium tile width (do not update).</p> <code>TILE_SIZE</code> <code>n_subscales</code> <code>int</code> <p>Number of sub-scales in the pyramidal image.</p> <code>5</code> <code>pixel_size</code> <code>float</code> <p>Xenium pixel size (do not update).</p> <code>0.2125</code> <code>ram_threshold_gb</code> <code>int | None</code> <p>If an image (of any level of the pyramid) is below this threshold, it will be loaded in-memory.</p> <code>4</code> <code>is_dir</code> <code>bool</code> <p>If <code>False</code>, then <code>path</code> is a path to a single file, not to the Xenium Explorer directory.</p> <code>True</code> Source code in <code>sopa/io/explorer/images.py</code> <pre><code>def write_image(\n    path: str,\n    image: DataTree | DataArray | np.ndarray,\n    lazy: bool = True,\n    tile_width: int = TILE_SIZE,\n    n_subscales: int = 5,\n    pixel_size: float = 0.2125,\n    ram_threshold_gb: int | None = 4,\n    is_dir: bool = True,\n):\n    \"\"\"Convert an image into a `morphology.ome.tif` file that can be read by the Xenium Explorer\n\n    Args:\n        path: Path to the Xenium Explorer directory where the image will be written\n        image: Image of shape `(C, Y, X)`\n        lazy: If `False`, the image will not be read in-memory (except if the image size is below `ram_threshold_gb`). If `True`, all the images levels are always loaded in-memory.\n        tile_width: Xenium tile width (do not update).\n        n_subscales: Number of sub-scales in the pyramidal image.\n        pixel_size: Xenium pixel size (do not update).\n        ram_threshold_gb: If an image (of any level of the pyramid) is below this threshold, it will be loaded in-memory.\n        is_dir: If `False`, then `path` is a path to a single file, not to the Xenium Explorer directory.\n    \"\"\"\n    path = explorer_file_path(path, FileNames.IMAGE, is_dir)\n\n    if isinstance(image, np.ndarray):\n        assert len(image.shape) == 3, \"Can only write channels with shape (C,Y,X)\"\n        log.info(f\"Converting image of shape {image.shape} into a DataArray (with dims: C,Y,X)\")\n        image = DataArray(image, dims=[\"c\", \"y\", \"x\"], name=\"image\")\n\n    image = _to_xenium_explorer_multiscale(image, n_subscales)\n\n    image_writer = MultiscaleImageWriter(image, pixel_size=pixel_size, tile_width=tile_width)\n    image_writer.write(path, lazy=lazy, ram_threshold_gb=ram_threshold_gb)\n</code></pre>"},{"location":"api/io/#sopa.io.save_column_csv","title":"<code>sopa.io.save_column_csv(path, adata, key)</code>","text":"<p>Save one column of the AnnData object as a CSV that can be open interactively in the explorer, under the \"cell\" panel.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path where to write the CSV that will be open in the Xenium Explorer</p> required <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the column to convert</p> required Source code in <code>sopa/io/explorer/table.py</code> <pre><code>def save_column_csv(path: str, adata: AnnData, key: str):\n    \"\"\"Save one column of the AnnData object as a CSV that can be open interactively in the explorer, under the \"cell\" panel.\n\n    Args:\n        path: Path where to write the CSV that will be open in the Xenium Explorer\n        adata: An `AnnData` object\n        key: Key of `adata.obs` containing the column to convert\n    \"\"\"\n    df = pd.DataFrame({\"cell_id\": adata.obs_names, \"group\": adata.obs[key].values})\n    df.to_csv(path, index=None)\n</code></pre>"},{"location":"api/io/#report","title":"Report","text":""},{"location":"api/io/#sopa.io.write_report","title":"<code>sopa.io.write_report(path, sdata)</code>","text":"<p>Create a HTML report (or web report) after running Sopa.</p> Note <p>This report is automatically generated based on a custom python-to-html engine</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the <code>.html</code> report that has to be created</p> required <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object, after running Sopa</p> required Source code in <code>sopa/io/report/generate.py</code> <pre><code>def write_report(path: str, sdata: SpatialData):\n    \"\"\"Create a HTML report (or web report) after running Sopa.\n\n    Note:\n        This report is automatically generated based on a custom python-to-html engine\n\n    Args:\n        path: Path to the `.html` report that has to be created\n        sdata: A `SpatialData` object, after running Sopa\n    \"\"\"\n    sections = SectionBuilder(sdata).compute_sections()\n\n    log.info(f\"Writing report to {path}\")\n    Root(sections).write(path)\n</code></pre>"},{"location":"api/patches/","title":"sopa.patches","text":""},{"location":"api/patches/#sopa.patches.Patches2D","title":"<code>sopa.patches.Patches2D</code>","text":"<p>Compute 2D-patches with overlaps. This can be done on an image or a DataFrame.</p> <p>Attributes:</p> Name Type Description <code>polygons</code> <code>list[Polygon]</code> <p>List of <code>shapely</code> polygons representing the patches</p> <code>bboxes</code> <code>ndarray</code> <p>Array of shape <code>(n_patches, 4)</code> containing the (xmin, ymin, xmax, ymax) coordinates of the patches bounding boxes</p> <code>ilocs</code> <code>ndarray</code> <p>Array of shape <code>(n_patches, 2)</code> containing the (x,y) indices of the patches</p> Source code in <code>sopa/patches/patches.py</code> <pre><code>class Patches2D:\n    \"\"\"\n    Compute 2D-patches with overlaps. This can be done on an image or a DataFrame.\n\n    Attributes:\n        polygons (list[Polygon]): List of `shapely` polygons representing the patches\n        bboxes (np.ndarray): Array of shape `(n_patches, 4)` containing the (xmin, ymin, xmax, ymax) coordinates of the patches bounding boxes\n        ilocs (np.ndarray): Array of shape `(n_patches, 2)` containing the (x,y) indices of the patches\n    \"\"\"\n\n    polygons: list[Polygon]\n    bboxes: np.ndarray\n    ilocs: np.ndarray\n\n    def __init__(\n        self,\n        sdata: SpatialData,\n        element_name: str,\n        patch_width: float | int,\n        patch_overlap: float | int = 50,\n    ):\n        \"\"\"\n        Args:\n            sdata: A `SpatialData` object\n            element_name: Name of the element on with patches will be made (image or points)\n            patch_width: Width of the patches (in the unit of the coordinate system of the element)\n            patch_overlap: Overlap width between the patches\n        \"\"\"\n        self.sdata = sdata\n        self.element_name = element_name\n        self.element = sdata[element_name]\n\n        if isinstance(self.element, DataTree):\n            self.element = get_spatial_image(sdata, element_name)\n\n        if isinstance(self.element, DataArray):\n            xmin, ymin = 0, 0\n            xmax, ymax = len(self.element.coords[\"x\"]), len(self.element.coords[\"y\"])\n            tight, int_coords = False, True\n        elif isinstance(self.element, dd.DataFrame):\n            xmin, ymin = self.element.x.min().compute(), self.element.y.min().compute()\n            xmax, ymax = self.element.x.max().compute(), self.element.y.max().compute()\n            tight, int_coords = True, False\n        else:\n            raise ValueError(f\"Invalid element type: {type(self.element)}\")\n\n        self.patch_x = Patches1D(xmin, xmax, patch_width, patch_overlap, tight, int_coords)\n        self.patch_y = Patches1D(ymin, ymax, patch_width, patch_overlap, tight, int_coords)\n\n        self.roi = None\n        if ROI.KEY in sdata.shapes:\n            geo_df = to_intrinsic(sdata, sdata[ROI.KEY], element_name)\n\n            assert all(\n                isinstance(geom, Polygon) for geom in geo_df.geometry\n            ), f\"All sdata['{ROI.KEY}'] geometries must be polygons\"\n\n            if len(geo_df) == 1:\n                self.roi: Polygon = geo_df.geometry[0]\n            else:\n                self.roi = MultiPolygon(list(geo_df.geometry))\n\n        self._init_patches()\n\n    def _init_patches(self):\n        self.ilocs, self.polygons, self.bboxes = [], [], []\n\n        for i in range(self.patch_x._count * self.patch_y._count):\n            self._try_register_patch(i)\n\n        self.ilocs = np.array(self.ilocs)\n        self.bboxes = np.array(self.bboxes)\n\n    def _try_register_patch(self, i: int):\n        \"\"\"Check that the patch is valid, and, if valid, register it\"\"\"\n        iy, ix = divmod(i, self.patch_x._count)\n        bounds = self._bbox_iloc(ix, iy)\n        patch = box(*bounds)\n\n        if self.roi is not None and not self.roi.intersects(patch):\n            return\n\n        patch = patch if self.roi is None else patch.intersection(self.roi)\n\n        if isinstance(patch, GeometryCollection):\n            geoms = [geom for geom in patch.geoms if isinstance(geom, Polygon)]\n            if not geoms:\n                return\n            patch = max(geoms, key=lambda polygon: polygon.area)\n\n        if not isinstance(patch, Polygon) and not isinstance(patch, MultiPolygon):\n            return\n\n        self.polygons.append(patch)\n        self.ilocs.append((ix, iy))\n        self.bboxes.append(bounds)\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__} object with {len(self)} patches on {self.element_name}\"\n\n    @property\n    def shape(self) -&gt; tuple[int, int]:\n        return (self.patch_y._count, self.patch_x._count)\n\n    def _bbox_iloc(self, ix: int, iy: int) -&gt; list[int]:\n        \"\"\"Coordinates of the rectangle bounding box of the patch at the given indices\n\n        Args:\n            ix: Patch index in the x-axis\n            iy: Patch indes in the y-axis\n\n        Returns:\n            A list `[xmin, ymin, xmax, ymax]` representing the bounding box of the patch\n        \"\"\"\n        xmin, xmax = self.patch_x[ix]\n        ymin, ymax = self.patch_y[iy]\n        return [xmin, ymin, xmax, ymax]\n\n    def __len__(self):\n        \"\"\"Number of patches\"\"\"\n        return len(self.bboxes)\n\n    def write(self, overwrite: bool = True, shapes_key: str | None = None) -&gt; gpd.GeoDataFrame:\n        \"\"\"Save patches in `sdata.shapes[\"sopa_patches\"]` (or by the key specified)\n\n        Args:\n            overwrite: Whether to overwrite patches if existing\n            shapes_key: Optional name of the shapes to be saved. By default, uses \"sopa_patches\".\n\n        Returns:\n            The saved GeoDataFrame\n        \"\"\"\n        shapes_key = SopaKeys.PATCHES if shapes_key is None else shapes_key\n\n        geo_df = gpd.GeoDataFrame(\n            {\n                \"geometry\": self.polygons,\n                SopaKeys.BOUNDS: self.bboxes.tolist(),\n                SopaKeys.PATCHES_ILOCS: self.ilocs.tolist(),\n            }\n        )\n        geo_df = ShapesModel.parse(\n            geo_df, transformations=get_transformation(self.element, get_all=True).copy()\n        )\n\n        self.sdata.shapes[shapes_key] = geo_df\n        if self.sdata.is_backed():\n            self.sdata.write_element(shapes_key, overwrite=overwrite)\n\n        log.info(f\"{len(geo_df)} patches were saved in sdata['{shapes_key}']\")\n\n        return geo_df\n\n    def patchify_transcripts(\n        self,\n        temp_dir: str,\n        cell_key: str = None,\n        unassigned_value: int | str = None,\n        use_prior: bool = False,\n        config: dict = {},\n        config_path: str | None = None,\n        config_name: str = SopaFiles.TOML_CONFIG_FILE,\n        csv_name: str = SopaFiles.TRANSCRIPTS_FILE,\n        min_transcripts_per_patch: int = 4000,\n        shapes_key: str = SopaKeys.CELLPOSE_BOUNDARIES,\n    ) -&gt; list[int]:\n        \"\"\"Creation of patches for the transcripts.\n\n        !!! info \"Prior segmentation usage\"\n            To save assign a prior segmentation to each transcript, you can either use `cell_key` or `use_prior`:\n\n            - If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use `cell_key` to denote the column of the transcript dataframe containing the cell IDs (and optionaly `unassigned_value`).\n            - If you have already run Cellpose with Sopa, use `use_prior` (no need to provide `cell_key` and `unassigned_value`).\n\n        Args:\n            temp_dir: Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.\n            cell_key: Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.\n            unassigned_value: If `cell_key` has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.\n            use_prior: Whether to use Cellpose as a prior segmentation. If `True`, make sure you have already run Cellpose with Sopa, and no need to provide `cell_key` and `unassigned_value`. Note that, if you have MERFISH data, the prior has already been run, so just use `cell_key` and `unassigned_value`.\n            config: Dictionnary of segmentation parameters\n            config_path: Path to the segmentation config file (you can also directly provide the argument via the `config` option)\n            config_name: Name of the config file to be saved in each patch subdirectory\n            csv_name: Name of the CSV file to be saved in each patch subdirectory\n            min_transcripts_per_patch: Minimum number of transcripts for a patch to be considered for segmentation\n\n        Returns:\n            A list of patches indices. Each index correspond to the name of a subdirectory inside `temp_dir`\n        \"\"\"\n        return TranscriptPatches(\n            self, self.element, config_name, csv_name, min_transcripts_per_patch\n        ).write(temp_dir, cell_key, unassigned_value, use_prior, config, config_path, shapes_key)\n\n    def patchify_centroids(\n        self,\n        temp_dir: str,\n        shapes_key: str = SopaKeys.CELLPOSE_BOUNDARIES,\n        csv_name: str = SopaFiles.CENTROIDS_FILE,\n        cell_key: str | None = None,\n        min_cells_per_patch: int = 1,\n    ) -&gt; list[int]:\n        assert isinstance(self.element, dd.DataFrame)\n\n        centroids = to_intrinsic(self.sdata, shapes_key, self.element).geometry.centroid\n        centroids = gpd.GeoDataFrame(geometry=centroids)\n        centroids[cell_key or SopaKeys.DEFAULT_CELL_KEY] = range(1, len(centroids) + 1)\n        centroids[\"x\"] = centroids.geometry.x\n        centroids[\"y\"] = centroids.geometry.y\n        centroids[\"z\"] = 0\n\n        return TranscriptPatches(self, centroids, None, csv_name, min_cells_per_patch).write(\n            temp_dir, shapes_key=shapes_key\n        )\n</code></pre>"},{"location":"api/patches/#sopa.patches.Patches2D.__init__","title":"<code>__init__(sdata, element_name, patch_width, patch_overlap=50)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>element_name</code> <code>str</code> <p>Name of the element on with patches will be made (image or points)</p> required <code>patch_width</code> <code>float | int</code> <p>Width of the patches (in the unit of the coordinate system of the element)</p> required <code>patch_overlap</code> <code>float | int</code> <p>Overlap width between the patches</p> <code>50</code> Source code in <code>sopa/patches/patches.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    element_name: str,\n    patch_width: float | int,\n    patch_overlap: float | int = 50,\n):\n    \"\"\"\n    Args:\n        sdata: A `SpatialData` object\n        element_name: Name of the element on with patches will be made (image or points)\n        patch_width: Width of the patches (in the unit of the coordinate system of the element)\n        patch_overlap: Overlap width between the patches\n    \"\"\"\n    self.sdata = sdata\n    self.element_name = element_name\n    self.element = sdata[element_name]\n\n    if isinstance(self.element, DataTree):\n        self.element = get_spatial_image(sdata, element_name)\n\n    if isinstance(self.element, DataArray):\n        xmin, ymin = 0, 0\n        xmax, ymax = len(self.element.coords[\"x\"]), len(self.element.coords[\"y\"])\n        tight, int_coords = False, True\n    elif isinstance(self.element, dd.DataFrame):\n        xmin, ymin = self.element.x.min().compute(), self.element.y.min().compute()\n        xmax, ymax = self.element.x.max().compute(), self.element.y.max().compute()\n        tight, int_coords = True, False\n    else:\n        raise ValueError(f\"Invalid element type: {type(self.element)}\")\n\n    self.patch_x = Patches1D(xmin, xmax, patch_width, patch_overlap, tight, int_coords)\n    self.patch_y = Patches1D(ymin, ymax, patch_width, patch_overlap, tight, int_coords)\n\n    self.roi = None\n    if ROI.KEY in sdata.shapes:\n        geo_df = to_intrinsic(sdata, sdata[ROI.KEY], element_name)\n\n        assert all(\n            isinstance(geom, Polygon) for geom in geo_df.geometry\n        ), f\"All sdata['{ROI.KEY}'] geometries must be polygons\"\n\n        if len(geo_df) == 1:\n            self.roi: Polygon = geo_df.geometry[0]\n        else:\n            self.roi = MultiPolygon(list(geo_df.geometry))\n\n    self._init_patches()\n</code></pre>"},{"location":"api/patches/#sopa.patches.Patches2D.__len__","title":"<code>__len__()</code>","text":"<p>Number of patches</p> Source code in <code>sopa/patches/patches.py</code> <pre><code>def __len__(self):\n    \"\"\"Number of patches\"\"\"\n    return len(self.bboxes)\n</code></pre>"},{"location":"api/patches/#sopa.patches.Patches2D.patchify_transcripts","title":"<code>patchify_transcripts(temp_dir, cell_key=None, unassigned_value=None, use_prior=False, config={}, config_path=None, config_name=SopaFiles.TOML_CONFIG_FILE, csv_name=SopaFiles.TRANSCRIPTS_FILE, min_transcripts_per_patch=4000, shapes_key=SopaKeys.CELLPOSE_BOUNDARIES)</code>","text":"<p>Creation of patches for the transcripts.</p> <p>Prior segmentation usage</p> <p>To save assign a prior segmentation to each transcript, you can either use <code>cell_key</code> or <code>use_prior</code>:</p> <ul> <li>If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use <code>cell_key</code> to denote the column of the transcript dataframe containing the cell IDs (and optionaly <code>unassigned_value</code>).</li> <li>If you have already run Cellpose with Sopa, use <code>use_prior</code> (no need to provide <code>cell_key</code> and <code>unassigned_value</code>).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>temp_dir</code> <code>str</code> <p>Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.</p> required <code>cell_key</code> <code>str</code> <p>Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.</p> <code>None</code> <code>unassigned_value</code> <code>int | str</code> <p>If <code>cell_key</code> has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.</p> <code>None</code> <code>use_prior</code> <code>bool</code> <p>Whether to use Cellpose as a prior segmentation. If <code>True</code>, make sure you have already run Cellpose with Sopa, and no need to provide <code>cell_key</code> and <code>unassigned_value</code>. Note that, if you have MERFISH data, the prior has already been run, so just use <code>cell_key</code> and <code>unassigned_value</code>.</p> <code>False</code> <code>config</code> <code>dict</code> <p>Dictionnary of segmentation parameters</p> <code>{}</code> <code>config_path</code> <code>str | None</code> <p>Path to the segmentation config file (you can also directly provide the argument via the <code>config</code> option)</p> <code>None</code> <code>config_name</code> <code>str</code> <p>Name of the config file to be saved in each patch subdirectory</p> <code>TOML_CONFIG_FILE</code> <code>csv_name</code> <code>str</code> <p>Name of the CSV file to be saved in each patch subdirectory</p> <code>TRANSCRIPTS_FILE</code> <code>min_transcripts_per_patch</code> <code>int</code> <p>Minimum number of transcripts for a patch to be considered for segmentation</p> <code>4000</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>A list of patches indices. Each index correspond to the name of a subdirectory inside <code>temp_dir</code></p> Source code in <code>sopa/patches/patches.py</code> <pre><code>def patchify_transcripts(\n    self,\n    temp_dir: str,\n    cell_key: str = None,\n    unassigned_value: int | str = None,\n    use_prior: bool = False,\n    config: dict = {},\n    config_path: str | None = None,\n    config_name: str = SopaFiles.TOML_CONFIG_FILE,\n    csv_name: str = SopaFiles.TRANSCRIPTS_FILE,\n    min_transcripts_per_patch: int = 4000,\n    shapes_key: str = SopaKeys.CELLPOSE_BOUNDARIES,\n) -&gt; list[int]:\n    \"\"\"Creation of patches for the transcripts.\n\n    !!! info \"Prior segmentation usage\"\n        To save assign a prior segmentation to each transcript, you can either use `cell_key` or `use_prior`:\n\n        - If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use `cell_key` to denote the column of the transcript dataframe containing the cell IDs (and optionaly `unassigned_value`).\n        - If you have already run Cellpose with Sopa, use `use_prior` (no need to provide `cell_key` and `unassigned_value`).\n\n    Args:\n        temp_dir: Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.\n        cell_key: Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.\n        unassigned_value: If `cell_key` has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.\n        use_prior: Whether to use Cellpose as a prior segmentation. If `True`, make sure you have already run Cellpose with Sopa, and no need to provide `cell_key` and `unassigned_value`. Note that, if you have MERFISH data, the prior has already been run, so just use `cell_key` and `unassigned_value`.\n        config: Dictionnary of segmentation parameters\n        config_path: Path to the segmentation config file (you can also directly provide the argument via the `config` option)\n        config_name: Name of the config file to be saved in each patch subdirectory\n        csv_name: Name of the CSV file to be saved in each patch subdirectory\n        min_transcripts_per_patch: Minimum number of transcripts for a patch to be considered for segmentation\n\n    Returns:\n        A list of patches indices. Each index correspond to the name of a subdirectory inside `temp_dir`\n    \"\"\"\n    return TranscriptPatches(\n        self, self.element, config_name, csv_name, min_transcripts_per_patch\n    ).write(temp_dir, cell_key, unassigned_value, use_prior, config, config_path, shapes_key)\n</code></pre>"},{"location":"api/patches/#sopa.patches.Patches2D.write","title":"<code>write(overwrite=True, shapes_key=None)</code>","text":"<p>Save patches in <code>sdata.shapes[\"sopa_patches\"]</code> (or by the key specified)</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>Whether to overwrite patches if existing</p> <code>True</code> <code>shapes_key</code> <code>str | None</code> <p>Optional name of the shapes to be saved. By default, uses \"sopa_patches\".</p> <code>None</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>The saved GeoDataFrame</p> Source code in <code>sopa/patches/patches.py</code> <pre><code>def write(self, overwrite: bool = True, shapes_key: str | None = None) -&gt; gpd.GeoDataFrame:\n    \"\"\"Save patches in `sdata.shapes[\"sopa_patches\"]` (or by the key specified)\n\n    Args:\n        overwrite: Whether to overwrite patches if existing\n        shapes_key: Optional name of the shapes to be saved. By default, uses \"sopa_patches\".\n\n    Returns:\n        The saved GeoDataFrame\n    \"\"\"\n    shapes_key = SopaKeys.PATCHES if shapes_key is None else shapes_key\n\n    geo_df = gpd.GeoDataFrame(\n        {\n            \"geometry\": self.polygons,\n            SopaKeys.BOUNDS: self.bboxes.tolist(),\n            SopaKeys.PATCHES_ILOCS: self.ilocs.tolist(),\n        }\n    )\n    geo_df = ShapesModel.parse(\n        geo_df, transformations=get_transformation(self.element, get_all=True).copy()\n    )\n\n    self.sdata.shapes[shapes_key] = geo_df\n    if self.sdata.is_backed():\n        self.sdata.write_element(shapes_key, overwrite=overwrite)\n\n    log.info(f\"{len(geo_df)} patches were saved in sdata['{shapes_key}']\")\n\n    return geo_df\n</code></pre>"},{"location":"api/patches/#sopa.patches.infer.infer_wsi_patches","title":"<code>sopa.patches.infer.infer_wsi_patches(sdata, model, patch_width, patch_overlap=0, level=0, magnification=None, image_key=None, batch_size=32, device=None)</code>","text":"<p>Create an image made of patch based predictions of a WSI image.</p> <p>Info</p> <p>The image will be saved into the <code>SpatialData</code> object with the key <code>sopa_{model_name}</code> (see the argument below).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>model</code> <code>Callable | str</code> <p>Callable that takes as an input a tensor of size (batch_size, channels, x, y) and returns a vector for each tile (batch_size, emb_dim), or a string with the name of one of the available models (<code>Resnet50Features</code>, <code>HistoSSLFeatures</code>, or <code>DINOv2Features</code>).</p> required <code>patch_width</code> <code>int</code> <p>Width (pixels) of the patches.</p> required <code>patch_overlap</code> <code>int</code> <p>Width (pixels) of the overlap between the patches.</p> <code>0</code> <code>level</code> <code>int | None</code> <p>Image level on which the processing is performed. Either <code>level</code> or <code>magnification</code> should be provided.</p> <code>0</code> <code>magnification</code> <code>int | None</code> <p>The target magnification on which the processing is performed. If <code>magnification</code> is provided, the <code>level</code> argument will be automatically computed.</p> <code>None</code> <code>image_key</code> <code>str | None</code> <p>Optional image key of the WSI image, unecessary if there is only one image.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Mini-batch size used during inference.</p> <code>32</code> <code>device</code> <code>str</code> <p>Device used for the computer vision model.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray | bool</code> <p>If the processing was successful, returns the <code>DataArray</code> of shape <code>(C,Y,X)</code> containing the model predictions, else <code>False</code></p> Source code in <code>sopa/patches/infer.py</code> <pre><code>def infer_wsi_patches(\n    sdata: SpatialData,\n    model: Callable | str,\n    patch_width: int,\n    patch_overlap: int = 0,\n    level: int | None = 0,\n    magnification: int | None = None,\n    image_key: str | None = None,\n    batch_size: int = 32,\n    device: str = None,\n) -&gt; DataArray | bool:\n    \"\"\"Create an image made of patch based predictions of a WSI image.\n\n    !!! info\n        The image will be saved into the `SpatialData` object with the key `sopa_{model_name}` (see the argument below).\n\n    Args:\n        sdata: A `SpatialData` object\n        model: Callable that takes as an input a tensor of size (batch_size, channels, x, y) and returns a vector for each tile (batch_size, emb_dim), or a string with the name of one of the available models (`Resnet50Features`, `HistoSSLFeatures`, or `DINOv2Features`).\n        patch_width: Width (pixels) of the patches.\n        patch_overlap: Width (pixels) of the overlap between the patches.\n        level: Image level on which the processing is performed. Either `level` or `magnification` should be provided.\n        magnification: The target magnification on which the processing is performed. If `magnification` is provided, the `level` argument will be automatically computed.\n        image_key: Optional image key of the WSI image, unecessary if there is only one image.\n        batch_size: Mini-batch size used during inference.\n        device: Device used for the computer vision model.\n\n    Returns:\n        If the processing was successful, returns the `DataArray` of shape `(C,Y,X)` containing the model predictions, else `False`\n    \"\"\"\n    image_key = get_key(sdata, \"images\", image_key)\n    image = sdata.images[image_key]\n\n    infer = Inference(image, model, patch_width, level, magnification, device)\n    patches = Patches2D(\n        sdata, image_key, infer.patch_width_scale0, infer.downsample * patch_overlap\n    )\n\n    log.info(f\"Processing {len(patches)} patches extracted from level {infer.level}\")\n\n    predictions = []\n    for i in tqdm.tqdm(range(0, len(patches), batch_size)):\n        prediction = infer.infer_bboxes(patches.bboxes[i : i + batch_size])\n        predictions.extend(prediction)\n    predictions = torch.stack(predictions)\n\n    if len(predictions.shape) == 1:\n        predictions = torch.unsqueeze(predictions, 1)\n\n    output_image = np.zeros((predictions.shape[1], *patches.shape), dtype=np.float32)\n    for (loc_x, loc_y), pred in zip(patches.ilocs, predictions):\n        output_image[:, loc_y, loc_x] = pred\n\n    patch_step = infer.patch_width_scale0 - infer.downsample * patch_overlap\n    output_image = DataArray(output_image, dims=(\"c\", \"y\", \"x\"))\n    output_image = Image2DModel.parse(\n        output_image,\n        transformations={infer.cs: Scale([patch_step, patch_step], axes=(\"x\", \"y\"))},\n    )\n\n    output_key = f\"sopa_{infer.model_str}\"\n    sdata.images[output_key] = output_image\n\n    log.info(f\"Patch predictions saved as an image in sdata['{output_key}']\")\n\n    patches.write(shapes_key=SopaKeys.PATCHES_INFERENCE_KEY)\n\n    return sdata[output_key]\n</code></pre>"},{"location":"api/patches/#sopa.patches.cluster.cluster_embeddings","title":"<code>sopa.patches.cluster.cluster_embeddings(sdata, element, method='leiden', key_added='cluster', **method_kwargs)</code>","text":"<p>Cluster the patches embeddings using a clustering method</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>element</code> <code>DataArray | str</code> <p>The <code>DataArray</code> containing the embeddings, or the name of the element</p> required <code>method</code> <code>Callable | str</code> <p>Callable that takes as an input an array of size <code>(n_patches x embedding_size)</code> and returns an array of clusters of size <code>n_patches</code>, or an available method name (<code>leiden</code>)</p> <code>'leiden'</code> <code>key_added</code> <code>str</code> <p>The key containing the clusters to be added to the patches <code>GeoDataFrame</code></p> <code>'cluster'</code> <code>method_kwargs</code> <code>str</code> <p>kwargs provided to the method callable</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>The patches <code>GeoDataFrame</code> with a new column <code>key_added</code> containing the patches clusters</p> Source code in <code>sopa/patches/cluster.py</code> <pre><code>def cluster_embeddings(\n    sdata: SpatialData,\n    element: DataArray | str,\n    method: Callable | str = \"leiden\",\n    key_added: str = \"cluster\",\n    **method_kwargs: str,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Cluster the patches embeddings using a clustering method\n\n    Args:\n        sdata: A `SpatialData` object\n        element: The `DataArray` containing the embeddings, or the name of the element\n        method: Callable that takes as an input an array of size `(n_patches x embedding_size)` and returns an array of clusters of size `n_patches`, or an available method name (`leiden`)\n        key_added: The key containing the clusters to be added to the patches `GeoDataFrame`\n        method_kwargs: kwargs provided to the method callable\n\n    Returns:\n        The patches `GeoDataFrame` with a new column `key_added` containing the patches clusters\n    \"\"\"\n    if isinstance(element, str):\n        element = sdata.images[element]\n\n    if isinstance(method, str):\n        assert (\n            method in METHODS_DICT\n        ), f\"Method {method} is not available. Use one of: {', '.join(METHODS_DICT.keys())}\"\n        method = METHODS_DICT[method]\n\n    gdf_patches = sdata[SopaKeys.PATCHES_INFERENCE_KEY]\n\n    ilocs = np.array(list(gdf_patches.ilocs))\n    embeddings = element.compute().data[:, ilocs[:, 1], ilocs[:, 0]].T\n\n    gdf_patches[key_added] = method(embeddings, **method_kwargs)\n    gdf_patches[key_added] = gdf_patches[key_added].astype(\"category\")\n\n    return gdf_patches\n</code></pre>"},{"location":"api/spatial/","title":"sopa.spatial","text":""},{"location":"api/spatial/#sopa.spatial.sjoin","title":"<code>sopa.spatial.sjoin(sdata, left_element, right_element, how='left', target_coordinate_system=None, **kwargs)</code>","text":"<p>Spatial join of two <code>shapes</code> GeoDataFrames, as in geopandas.sjoin.</p> <p>Shapes are automatically aligned on the same coordinate system (which can be chosen using the <code>target_coordinate_system</code> argument).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>left_element</code> <code>str | GeoDataFrame</code> <p>The name of a GeoDataFrame in <code>sdata</code>, or the GeoDataFrame itself</p> required <code>right_element</code> <code>str | GeoDataFrame</code> <p>The name of a GeoDataFrame in <code>sdata</code>, or the GeoDataFrame itself</p> required <code>how</code> <code>str</code> <p>The GeoPandas type of join. By default, left geometries are retained.</p> <code>'left'</code> <code>target_coordinate_system</code> <code>str | None</code> <p>The name of the coordinate system on which the shapes will be transformed. By default, uses the intrinsic coordinate system of the <code>left_element</code>.</p> <code>None</code> <code>**kwargs</code> <code>int</code> <p>Kwargs provided to the geopandas.sjoin function</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>The joined <code>GeoDataFrame</code></p> Source code in <code>sopa/spatial/utils.py</code> <pre><code>def sjoin(\n    sdata: SpatialData,\n    left_element: str | gpd.GeoDataFrame,\n    right_element: str | gpd.GeoDataFrame,\n    how: str = \"left\",\n    target_coordinate_system: str | None = None,\n    **kwargs: int,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Spatial join of two `shapes` GeoDataFrames, as in [geopandas.sjoin](https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html).\n\n    Shapes are automatically aligned on the same coordinate system (which can be chosen using the `target_coordinate_system` argument).\n\n    Args:\n        sdata: A `SpatialData` object\n        left_element: The name of a GeoDataFrame in `sdata`, or the GeoDataFrame itself\n        right_element: The name of a GeoDataFrame in `sdata`, or the GeoDataFrame itself\n        how: The GeoPandas type of join. By default, left geometries are retained.\n        target_coordinate_system: The name of the coordinate system on which the shapes will be transformed. By default, uses the intrinsic coordinate system of the `left_element`.\n        **kwargs: Kwargs provided to the [geopandas.sjoin](https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html) function\n\n    Returns:\n        The joined `GeoDataFrame`\n    \"\"\"\n    if isinstance(left_element, str):\n        left_element = sdata[left_element]\n    if isinstance(right_element, str):\n        right_element = sdata[right_element]\n\n    if target_coordinate_system is None:\n        target_coordinate_system = get_intrinsic_cs(sdata, left_element)\n\n    left_element = sdata.transform_element_to_coordinate_system(\n        left_element, target_coordinate_system\n    )\n    right_element = sdata.transform_element_to_coordinate_system(\n        right_element, target_coordinate_system\n    )\n\n    return gpd.sjoin(left_element, right_element, how=how, **kwargs)\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.mean_distance","title":"<code>sopa.spatial.mean_distance(adata, group_key, target_group_key=None, ignore_zeros=False)</code>","text":"<p>Mean distance between two groups (typically, between cell-types, or between cell-types and domains)</p> Note <p>The distance is a number of hops, i.e. a distance of 10 between a pDC and a T cell means that there are 10 cells on the closest path from one to the other cell.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>group_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the groups</p> required <code>target_group_key</code> <code>str | None</code> <p>Key of <code>adata.obs</code> containing the target groups (by default, uses <code>group_key</code>)</p> <code>None</code> <code>ignore_zeros</code> <code>bool</code> <p>If <code>True</code>, a cell distance to its own group is 0.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p><code>DataFrame</code> of shape <code>n_groups * n_groups_target</code> of mean hop-distances</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def mean_distance(\n    adata: AnnData, group_key: str, target_group_key: str | None = None, ignore_zeros: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Mean distance between two groups (typically, between cell-types, or between cell-types and domains)\n\n    Note:\n        The distance is a number of hops, i.e. a distance of 10 between a pDC and a T cell means that there are 10 cells on the closest path from one to the other cell.\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        group_key: Key of `adata.obs` containing the groups\n        target_group_key: Key of `adata.obs` containing the target groups (by default, uses `group_key`)\n        ignore_zeros: If `True`, a cell distance to its own group is 0.\n\n    Returns:\n        `DataFrame` of shape `n_groups * n_groups_target` of mean hop-distances\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    target_group_key = group_key if target_group_key is None else target_group_key\n\n    df_distances = cells_to_groups(adata, target_group_key, None, ignore_zeros=ignore_zeros)\n\n    if ignore_zeros:\n        df_distances.replace(0, np.nan, inplace=True)\n\n    df_distances[group_key] = adata.obs[group_key]\n    df_distances = df_distances.groupby(group_key, observed=False).mean()\n    df_distances.columns.name = target_group_key\n\n    return df_distances\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.geometrize_niches","title":"<code>sopa.spatial.geometrize_niches(adata, niche_key, buffer='auto', perc_area_th=0.05)</code>","text":"<p>Converts the niches to shapely polygons, and put into a <code>GeoDataFrame</code>. Note that each niche can appear multiple times, as they can be separated by other niches ; in this case, we call them different \"components\" of the same niche ID.</p> Plot components <p>You can show niches components with GeoPandas <pre><code>gdf = geometrize_niches(adata, niche_key)\ngdf.plot(column=niche_key)\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>buffer</code> <code>int | str</code> <p>Expansion radius applied on components. By default, <code>3 * mean_distance_neighbors</code></p> <code>'auto'</code> <code>perc_area_th</code> <code>float</code> <p>For each niche, components whose area is less than <code>perc_area_th * max_component_area</code> will be removed</p> <code>0.05</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A <code>GeoDataFrame</code> with geometries for each niche component. We also compute the area/perimeter/roundness of each component.</p> Source code in <code>sopa/spatial/morpho.py</code> <pre><code>def geometrize_niches(\n    adata: AnnData | SpatialData,\n    niche_key: str,\n    buffer: int | str = \"auto\",\n    perc_area_th: float = 0.05,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Converts the niches to shapely polygons, and put into a `GeoDataFrame`. Note that each niche can appear multiple times, as they can be separated by other niches ; in this case, we call them different \"components\" of the same niche ID.\n\n    Plot components:\n        You can show niches components with GeoPandas\n        ```py\n        gdf = geometrize_niches(adata, niche_key)\n        gdf.plot(column=niche_key)\n        ```\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        niche_key: Key of `adata.obs` containing the niches\n        buffer: Expansion radius applied on components. By default, `3 * mean_distance_neighbors`\n        perc_area_th: For each niche, components whose area is less than `perc_area_th * max_component_area` will be removed\n\n    Returns:\n        A `GeoDataFrame` with geometries for each niche component. We also compute the area/perimeter/roundness of each component.\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    _check_has_delaunay(adata)\n    data = {\"geometry\": [], niche_key: []}\n\n    delaunay = Delaunay(adata.obsm[\"spatial\"])\n    connectivities = adata.obsp[\"spatial_connectivities\"]\n    values = adata.obs[niche_key].values\n\n    keep = (\n        (connectivities[delaunay.simplices[:, 0], delaunay.simplices[:, 1]].A1 == 1)\n        &amp; (connectivities[delaunay.simplices[:, 0], delaunay.simplices[:, 2]].A1 == 1)\n        &amp; (connectivities[delaunay.simplices[:, 1], delaunay.simplices[:, 2]].A1 == 1)\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 1]])\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 2]])\n        &amp; (values[delaunay.simplices[:, 0]] == values[delaunay.simplices[:, 2]])\n    )  # Keep simplices that are in the original Delaunay graph, and which are not in between different value categories\n\n    neighbors = np.where(np.isin(delaunay.neighbors, np.where(~keep)[0]), -1, delaunay.neighbors)\n\n    simplices_to_visit = set(np.where(keep)[0])\n\n    while simplices_to_visit:\n        component = Component(adata, delaunay, neighbors)\n        component.visit(simplices_to_visit)\n\n        data[\"geometry\"].append(component.polygon)\n        data[niche_key].append(values[component.first_vertex_index()])\n\n    gdf = gpd.GeoDataFrame(data)\n\n    if buffer is not None and buffer != 0:\n        gdf = _clean_components(adata, gdf, niche_key, buffer)\n\n    gdf[SopaKeys.GEOMETRY_LENGTH] = gdf.length\n    gdf[SopaKeys.GEOMETRY_AREA] = gdf.area\n    gdf[SopaKeys.GEOMETRY_ROUNDNESS] = (\n        4 * np.pi * gdf[SopaKeys.GEOMETRY_AREA] / gdf[SopaKeys.GEOMETRY_LENGTH] ** 2\n    )\n\n    # Remove minor components (compared to the largest component of its corresponding niche)\n    gdf = gdf[gdf.area &gt;= gdf[niche_key].map(gdf.groupby(niche_key).area.max() * perc_area_th)]\n\n    return gdf\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.niches_geometry_stats","title":"<code>sopa.spatial.niches_geometry_stats(adata, niche_key, aggregation='min', key_added_suffix='_distance_to_niche_', **geometrize_niches_kwargs)</code>","text":"<p>Computes statistics over niches geometries</p> Details <ul> <li><code>n_components</code>: Number of connected component of a niche (a component is a group of neighbor cells with the same niche attribute)</li> <li><code>length</code>: Mean distance of the exterior/boundary of the components of a niche</li> <li><code>area</code>: Mean area of the components of a niche</li> <li><code>roundness</code>: Float value between 0 and 1. The higher the value, the closer to a circle. Computed via <code>4 * pi * area / length**2</code></li> <li><code>mean_distance_to_niche_X</code>: mean distance to the niche (between the two closest points of the niches)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>aggregation</code> <code>str | list[str]</code> <p>Aggregation mode. Either one string such as <code>\"min\"</code>, or a list such as <code>[\"mean\", \"min\"]</code>.</p> <code>'min'</code> <code>key_added_suffix</code> <code>str</code> <p>Suffix added in the DataFrame columns. Defaults to \"distance_to_niche\".</p> <code>'_distance_to_niche_'</code> <code>geometrize_niches_kwargs</code> <code>str</code> <p>Kwargs to the <code>sopa.spatial.geometrize_niches</code> function</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A <code>DataFrame</code> of shape <code>n_niches * n_statistics</code></p> Source code in <code>sopa/spatial/morpho.py</code> <pre><code>def niches_geometry_stats(\n    adata: AnnData | SpatialData,\n    niche_key: str,\n    aggregation: str | list[str] = \"min\",\n    key_added_suffix: str = \"_distance_to_niche_\",\n    **geometrize_niches_kwargs: str,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Computes statistics over niches geometries\n\n    Details:\n        - `n_components`: Number of connected component of a niche (a component is a group of neighbor cells with the same niche attribute)\n        - `length`: Mean distance of the exterior/boundary of the components of a niche\n        - `area`: Mean area of the components of a niche\n        - `roundness`: Float value between 0 and 1. The higher the value, the closer to a circle. Computed via `4 * pi * area / length**2`\n        - `mean_distance_to_niche_X`: mean distance to the niche (between the two closest points of the niches)\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        niche_key: Key of `adata.obs` containing the niches\n        aggregation: Aggregation mode. Either one string such as `\"min\"`, or a list such as `[\"mean\", \"min\"]`.\n        key_added_suffix: Suffix added in the DataFrame columns. Defaults to \"_distance_to_niche_\".\n        geometrize_niches_kwargs: Kwargs to the `sopa.spatial.geometrize_niches` function\n\n    Returns:\n        A `DataFrame` of shape `n_niches * n_statistics`\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    gdf = geometrize_niches(adata, niche_key, **geometrize_niches_kwargs)\n    value_counts = gdf[niche_key].value_counts()\n\n    assert len(gdf), \"No niche geometry found, stats can't be computed\"\n\n    log.info(f\"Computing pairwise distances between {len(gdf)} components\")\n    pairwise_distances: pd.DataFrame = gdf.geometry.apply(lambda g: gdf.distance(g))\n    pairwise_distances[niche_key] = gdf[niche_key]\n\n    if isinstance(aggregation, str):\n        aggregation = [aggregation]\n\n    for aggr in aggregation:\n        df = pairwise_distances.groupby(niche_key).aggregate(aggr).T\n        df.columns = [f\"{aggr}{key_added_suffix}{c}\" for c in df.columns]\n        gdf[df.columns] = df\n\n    df_stats: pd.DataFrame = gdf.groupby(niche_key)[gdf.columns[2:]].mean()\n    df_stats.insert(0, SopaKeys.GEOMETRY_COUNT, value_counts)\n\n    return df_stats\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.cells_to_groups","title":"<code>sopa.spatial.cells_to_groups(adata, group_key, key_added_prefix=None, ignore_zeros=False)</code>","text":"<p>Compute the hop-distance between each cell and a cell category/group.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object, or a <code>SpatialData object</code></p> required <code>group_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the groups</p> required <code>key_added_prefix</code> <code>str | None</code> <p>Prefix to the key added in <code>adata.obsm</code>. If <code>None</code>, will return the <code>DataFrame</code> instead of saving it.</p> <code>None</code> <code>ignore_zeros</code> <code>bool</code> <p>If <code>True</code>, a cell distance to its own group is 0.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame | None</code> <p>A <code>Dataframe</code> of shape <code>n_obs * n_groups</code>, or <code>None</code> if <code>key_added_prefix</code> was provided (in this case, the dataframe is saved in <code>\"{key_added_prefix}{group_key}\"</code>)</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def cells_to_groups(\n    adata: AnnData,\n    group_key: str,\n    key_added_prefix: str | None = None,\n    ignore_zeros: bool = False,\n) -&gt; pd.DataFrame | None:\n    \"\"\"Compute the hop-distance between each cell and a cell category/group.\n\n    Args:\n        adata: An `AnnData` object, or a `SpatialData object`\n        group_key: Key of `adata.obs` containing the groups\n        key_added_prefix: Prefix to the key added in `adata.obsm`. If `None`, will return the `DataFrame` instead of saving it.\n        ignore_zeros: If `True`, a cell distance to its own group is 0.\n\n    Returns:\n        A `Dataframe` of shape `n_obs * n_groups`, or `None` if `key_added_prefix` was provided (in this case, the dataframe is saved in `\"{key_added_prefix}{group_key}\"`)\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    _check_has_delaunay(adata)\n\n    distances_to_groups = {}\n\n    if not adata.obs[group_key].dtype.name == \"category\":\n        log.info(f\"Converting adata.obs['{group_key}'] to category\")\n        adata.obs[group_key] = adata.obs[group_key].astype(\"category\")\n\n    for group_id in tqdm(adata.obs[group_key].cat.categories):\n        group_nodes = np.where(adata.obs[group_key] == group_id)[0]\n\n        distances = np.full(adata.n_obs, np.nan)\n\n        if not ignore_zeros:\n            distances[group_nodes] = 0\n            visited = set(group_nodes)\n        else:\n            visited = set()\n\n        queue = group_nodes\n        current_distance = 0\n\n        while len(queue):\n            distances[queue] = current_distance\n\n            neighbors = set(adata.obsp[\"spatial_connectivities\"][queue].indices)\n            queue = np.array(list(neighbors - visited))\n            visited |= neighbors\n\n            current_distance += 1\n\n        distances_to_groups[group_id] = distances\n\n    df_distances = pd.DataFrame(distances_to_groups, index=adata.obs_names)\n\n    if key_added_prefix is None:\n        return df_distances\n    adata.obsm[f\"{key_added_prefix}{group_key}\"] = df_distances\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.spatial_neighbors","title":"<code>sopa.spatial.spatial_neighbors(adata, radius, library_key=None, percentile=None, set_diag=False)</code>","text":"<p>Create a Delaunay graph from spatial coordinates. This function comes from squidpy.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData | SpatialData</code> <p>AnnData object</p> required <code>radius</code> <code>tuple[float, float] | None</code> <p>tuple that prunes the final graph to only contain edges in interval <code>[min(radius), max(radius)]</code>. If <code>None</code>, all edges are kept.</p> required <code>library_key</code> <code>str | None</code> <p>Optional batch key in adata.obs</p> <code>None</code> <code>percentile</code> <code>float | None</code> <p>Percentile of the distances to use as threshold.</p> <code>None</code> <code>set_diag</code> <code>bool</code> <p>Whether to set the diagonal of the spatial connectivities to <code>1.0</code>.</p> <code>False</code> Source code in <code>sopa/spatial/_build.py</code> <pre><code>def spatial_neighbors(\n    adata: AnnData | SpatialData,\n    radius: tuple[float, float] | None,\n    library_key: str | None = None,\n    percentile: float | None = None,\n    set_diag: bool = False,\n):\n    \"\"\"Create a Delaunay graph from spatial coordinates. This function comes from [squidpy](https://squidpy.readthedocs.io/en/latest/api/squidpy.gr.spatial_neighbors.html#squidpy.gr.spatial_neighbors).\n\n    Args:\n        adata: AnnData object\n        radius: tuple that prunes the final graph to only contain edges in interval `[min(radius), max(radius)]`. If `None`, all edges are kept.\n        library_key: Optional batch key in adata.obs\n        percentile: Percentile of the distances to use as threshold.\n        set_diag: Whether to set the diagonal of the spatial connectivities to `1.0`.\n    \"\"\"\n    if isinstance(adata, SpatialData):\n        adata = adata.tables[SopaKeys.TABLE]\n\n    assert (\n        radius is None or len(radius) == 2\n    ), \"Radius is expected to be a tuple (min_radius, max_radius)\"\n\n    log.info(\"Computing delaunay graph\")\n\n    if library_key is not None:\n        assert adata.obs[library_key].dtype == \"category\"\n        libs = adata.obs[library_key].cat.categories\n        make_index_unique(adata.obs_names)\n    else:\n        libs = [None]\n\n    _build_fun = partial(\n        _spatial_neighbor,\n        set_diag=set_diag,\n        radius=radius,\n        percentile=percentile,\n    )\n\n    if library_key is not None:\n        mats: list[tuple[spmatrix, spmatrix]] = []\n        ixs = []  # type: ignore[var-annotated]\n        for lib in libs:\n            ixs.extend(np.where(adata.obs[library_key] == lib)[0])\n            mats.append(_build_fun(adata[adata.obs[library_key] == lib]))\n        ixs = np.argsort(ixs)  # type: ignore[assignment] # invert\n        Adj = block_diag([m[0] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n        Dst = block_diag([m[1] for m in mats], format=\"csr\")[ixs, :][:, ixs]\n    else:\n        Adj, Dst = _build_fun(adata)\n\n    adata.obsp[\"spatial_connectivities\"] = Adj\n    adata.obsp[\"spatial_distances\"] = Dst\n</code></pre>"},{"location":"api/spatial/#sopa.spatial.prepare_network","title":"<code>sopa.spatial.prepare_network(adata, cell_type_key, niche_key, clip_weight=3, node_colors=('#5c7dc4', '#f05541'), node_sizes=(1.3, 5))</code>","text":"<p>Create a dataframe representing weights between cell-types and/or niches. This can be later use to plot a cell-type/niche represention of a whole slide using the netgraph library.</p> <p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An <code>AnnData</code> object</p> required <code>cell_type_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the cell types</p> required <code>niche_key</code> <code>str</code> <p>Key of <code>adata.obs</code> containing the niches</p> required <code>clip_weight</code> <code>float</code> <p>Maximum weight</p> <code>3</code> <code>node_colors</code> <code>tuple[str]</code> <p>Tuple of (cell-type color, niche color)</p> <code>('#5c7dc4', '#f05541')</code> <code>node_sizes</code> <code>float</code> <p>Tuple of (cell-type size, niche size)</p> <code>(1.3, 5)</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict, dict, dict]</code> <p>A DataFrame of weights between cell-types and/or niches, and three dict for netgraph display</p> Source code in <code>sopa/spatial/distance.py</code> <pre><code>def prepare_network(\n    adata: AnnData,\n    cell_type_key: str,\n    niche_key: str,\n    clip_weight: float = 3,\n    node_colors: tuple[str] = (\"#5c7dc4\", \"#f05541\"),\n    node_sizes: float = (1.3, 5),\n) -&gt; tuple[pd.DataFrame, dict, dict, dict]:\n    \"\"\"Create a dataframe representing weights between cell-types and/or niches.\n    This can be later use to plot a cell-type/niche represention of a whole slide\n    using the netgraph library.\n\n    Args:\n        adata: An `AnnData` object\n        cell_type_key: Key of `adata.obs` containing the cell types\n        niche_key: Key of `adata.obs` containing the niches\n        clip_weight: Maximum weight\n        node_colors: Tuple of (cell-type color, niche color)\n        node_sizes: Tuple of (cell-type size, niche size)\n\n    Returns:\n        A DataFrame of weights between cell-types and/or niches, and three dict for netgraph display\n    \"\"\"\n    node_color, node_size, node_shape = {}, {}, {}\n\n    log.info(\"Computing all distances for the 4 pairs of categories\")\n    weights = mean_distance(adata, cell_type_key)\n    top_right = mean_distance(adata, cell_type_key, niche_key)\n    bottom_left = mean_distance(adata, niche_key, cell_type_key)\n    bottom_right = mean_distance(adata, niche_key, niche_key)\n\n    for pop in weights.index:\n        node_color[pop] = node_colors[0]\n        node_size[pop] = node_sizes[0]\n        node_shape[pop] = \"o\"\n\n    for niche in bottom_right.index:\n        node_color[niche] = node_colors[1]\n        node_size[niche] = node_sizes[1]\n        node_shape[niche] = \"h\"\n\n    # assemble dataframe per-block\n    bottom_left[bottom_right.columns] = bottom_right\n    weights[top_right.columns] = top_right\n    weights = pd.concat([weights, bottom_left], axis=0).copy()\n\n    # convert distances to symmetric weights\n    weights = 1 / weights\n    np.fill_diagonal(weights.values, 0)\n    weights = weights.clip(0, clip_weight)\n    weights = (weights.T + weights) / 2\n\n    return weights, node_color, node_size, node_shape\n</code></pre>"},{"location":"api/segmentation/aggregate/","title":"sopa.segmentation.aggregate","text":""},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.overlay_segmentation","title":"<code>sopa.segmentation.aggregate.overlay_segmentation(sdata, shapes_key, gene_column=None, area_ratio_threshold=0.25, image_key=None, save_table=False)</code>","text":"<p>Overlay a segmentation on top of an existing segmentation</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>shapes_key</code> <code>str</code> <p>The key of the new shapes to be added</p> required <code>gene_column</code> <code>str | None</code> <p>Key of the points dataframe containing the genes names</p> <code>None</code> <code>area_ratio_threshold</code> <code>float</code> <p>Threshold between 0 and 1. For each original cell overlapping with a new cell, we compute the overlap-area/cell-area, if above the threshold the cell is removed.</p> <code>0.25</code> <code>image_key</code> <code>str | None</code> <p>Optional key of the original image</p> <code>None</code> <code>save_table</code> <code>bool</code> <p>Whether to save the new table on-disk or not</p> <code>False</code> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def overlay_segmentation(\n    sdata: SpatialData,\n    shapes_key: str,\n    gene_column: str | None = None,\n    area_ratio_threshold: float = 0.25,\n    image_key: str | None = None,\n    save_table: bool = False,\n):\n    \"\"\"Overlay a segmentation on top of an existing segmentation\n\n    Args:\n        sdata: A `SpatialData` object\n        shapes_key: The key of the new shapes to be added\n        gene_column: Key of the points dataframe containing the genes names\n        area_ratio_threshold: Threshold between 0 and 1. For each original cell overlapping with a new cell, we compute the overlap-area/cell-area, if above the threshold the cell is removed.\n        image_key: Optional key of the original image\n        save_table: Whether to save the new table on-disk or not\n    \"\"\"\n    average_intensities = False\n\n    if \"table\" in sdata.tables and SopaKeys.UNS_KEY in sdata.tables[\"table\"].uns:\n        sopa_attrs = sdata.tables[\"table\"].uns[SopaKeys.UNS_KEY]\n\n        if sopa_attrs[SopaKeys.UNS_HAS_TRANSCRIPTS]:\n            assert gene_column is not None, \"Need 'gene_column' argument to count transcripts\"\n        else:\n            gene_column = gene_column\n        average_intensities = sopa_attrs[SopaKeys.UNS_HAS_INTENSITIES]\n\n    aggr = Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\n    aggr.overlay_segmentation(\n        gene_column=gene_column,\n        average_intensities=average_intensities,\n        area_ratio_threshold=area_ratio_threshold,\n        save_table=save_table,\n    )\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.average_channels","title":"<code>sopa.segmentation.aggregate.average_channels(sdata, image_key=None, shapes_key=None, expand_radius_ratio=0)</code>","text":"<p>Average channel intensities per cell.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>image_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the image. If only one <code>images</code> element, this does not have to be provided.</p> <code>None</code> <code>shapes_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the cell boundaries. If only one <code>shapes</code> element, this does not have to be provided.</p> <code>None</code> <code>expand_radius_ratio</code> <code>float</code> <p>Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code>. This help better aggregate boundary stainings.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy <code>ndarray</code> of shape <code>(n_cells, n_channels)</code></p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def average_channels(\n    sdata: SpatialData,\n    image_key: str = None,\n    shapes_key: str = None,\n    expand_radius_ratio: float = 0,\n) -&gt; np.ndarray:\n    \"\"\"Average channel intensities per cell.\n\n    Args:\n        sdata: A `SpatialData` object\n        image_key: Key of `sdata` containing the image. If only one `images` element, this does not have to be provided.\n        shapes_key: Key of `sdata` containing the cell boundaries. If only one `shapes` element, this does not have to be provided.\n        expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius`. This help better aggregate boundary stainings.\n\n    Returns:\n        A numpy `ndarray` of shape `(n_cells, n_channels)`\n    \"\"\"\n    image = get_spatial_image(sdata, image_key)\n\n    geo_df = get_element(sdata, \"shapes\", shapes_key)\n    geo_df = to_intrinsic(sdata, geo_df, image)\n\n    expand_radius = expand_radius_ratio * np.mean(np.sqrt(geo_df.area / np.pi))\n\n    if expand_radius &gt; 0:\n        geo_df = geo_df.buffer(expand_radius)\n\n    log.info(\n        f\"Averaging channels intensity over {len(geo_df)} cells with expansion {expand_radius}\"\n    )\n    return _average_channels_aligned(image, geo_df)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate._average_channels_aligned","title":"<code>sopa.segmentation.aggregate._average_channels_aligned(image, geo_df)</code>","text":"<p>Average channel intensities per cell. The image and cells have to be aligned, i.e. be on the same coordinate system.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>DataArray</code> <p>A <code>DataArray</code> of shape <code>(n_channels, y, x)</code></p> required <code>geo_df</code> <code>GeoDataFrame | list[Polygon]</code> <p>A <code>GeoDataFrame</code> whose geometries are cell boundaries (polygons)</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy <code>ndarray</code> of shape <code>(n_cells, n_channels)</code></p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def _average_channels_aligned(\n    image: DataArray, geo_df: gpd.GeoDataFrame | list[Polygon]\n) -&gt; np.ndarray:\n    \"\"\"Average channel intensities per cell. The image and cells have to be aligned, i.e. be on the same coordinate system.\n\n    Args:\n        image: A `DataArray` of shape `(n_channels, y, x)`\n        geo_df: A `GeoDataFrame` whose geometries are cell boundaries (polygons)\n\n    Returns:\n        A numpy `ndarray` of shape `(n_cells, n_channels)`\n    \"\"\"\n    cells = geo_df if isinstance(geo_df, list) else list(geo_df.geometry)\n    tree = shapely.STRtree(cells)\n\n    intensities = np.zeros((len(cells), len(image.coords[\"c\"])))\n    areas = np.zeros(len(cells))\n\n    chunk_sizes = image.data.chunks\n    offsets_y = np.cumsum(np.pad(chunk_sizes[1], (1, 0), \"constant\"))\n    offsets_x = np.cumsum(np.pad(chunk_sizes[2], (1, 0), \"constant\"))\n\n    def _average_chunk_inside_cells(chunk, iy, ix):\n        ymin, ymax = offsets_y[iy], offsets_y[iy + 1]\n        xmin, xmax = offsets_x[ix], offsets_x[ix + 1]\n\n        patch = box(xmin, ymin, xmax, ymax)\n        intersections = tree.query(patch, predicate=\"intersects\")\n\n        for index in intersections:\n            cell = cells[index]\n            bounds = shapes.pixel_outer_bounds(cell.bounds)\n\n            sub_image = chunk[\n                :,\n                max(bounds[1] - ymin, 0) : bounds[3] - ymin,\n                max(bounds[0] - xmin, 0) : bounds[2] - xmin,\n            ]\n\n            if sub_image.shape[1] == 0 or sub_image.shape[2] == 0:\n                continue\n\n            mask = shapes.rasterize(cell, sub_image.shape[1:], bounds)\n\n            intensities[index] += np.sum(sub_image * mask, axis=(1, 2))\n            areas[index] += np.sum(mask)\n\n    with ProgressBar():\n        tasks = [\n            dask.delayed(_average_chunk_inside_cells)(chunk, iy, ix)\n            for iy, row in enumerate(image.chunk({\"c\": -1}).data.to_delayed()[0])\n            for ix, chunk in enumerate(row)\n        ]\n        dask.compute(tasks)\n\n    return intensities / areas[:, None].clip(1)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.count_transcripts","title":"<code>sopa.segmentation.aggregate.count_transcripts(sdata, gene_column, shapes_key=None, points_key=None, geo_df=None)</code>","text":"<p>Counts transcripts per cell.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>gene_column</code> <code>str</code> <p>Column of the transcript dataframe containing the gene names</p> required <code>shapes_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the cell boundaries. If only one <code>shapes</code> element, this does not have to be provided.</p> <code>None</code> <code>points_key</code> <code>str</code> <p>Key of <code>sdata</code> containing the transcripts. If only one <code>points</code> element, this does not have to be provided.</p> <code>None</code> <code>geo_df</code> <code>GeoDataFrame</code> <p>If the cell boundaries are not yet in <code>sdata</code>, a <code>GeoDataFrame</code> can be directly provided for cell boundaries</p> <code>None</code> <p>Returns:</p> Type Description <code>AnnData</code> <p>An <code>AnnData</code> object of shape <code>(n_cells, n_genes)</code> with the counts per cell</p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def count_transcripts(\n    sdata: SpatialData,\n    gene_column: str,\n    shapes_key: str = None,\n    points_key: str = None,\n    geo_df: gpd.GeoDataFrame = None,\n) -&gt; AnnData:\n    \"\"\"Counts transcripts per cell.\n\n    Args:\n        sdata: A `SpatialData` object\n        gene_column: Column of the transcript dataframe containing the gene names\n        shapes_key: Key of `sdata` containing the cell boundaries. If only one `shapes` element, this does not have to be provided.\n        points_key: Key of `sdata` containing the transcripts. If only one `points` element, this does not have to be provided.\n        geo_df: If the cell boundaries are not yet in `sdata`, a `GeoDataFrame` can be directly provided for cell boundaries\n\n    Returns:\n        An `AnnData` object of shape `(n_cells, n_genes)` with the counts per cell\n    \"\"\"\n    points_key, points = get_item(sdata, \"points\", points_key)\n\n    if geo_df is None:\n        geo_df = get_element(sdata, \"shapes\", shapes_key)\n        geo_df = to_intrinsic(sdata, geo_df, points_key)\n\n    log.info(f\"Aggregating transcripts over {len(geo_df)} cells\")\n    return _count_transcripts_aligned(geo_df, points, gene_column)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate._count_transcripts_aligned","title":"<code>sopa.segmentation.aggregate._count_transcripts_aligned(geo_df, points, value_key)</code>","text":"<p>Count transcripts per cell. The cells and points have to be aligned (i.e., in the same coordinate system)</p> <p>Parameters:</p> Name Type Description Default <code>geo_df</code> <code>GeoDataFrame</code> <p>Cells geometries</p> required <code>points</code> <code>DataFrame</code> <p>Transcripts dataframe</p> required <code>value_key</code> <code>str</code> <p>Key of <code>points</code> containing the genes names</p> required <p>Returns:</p> Type Description <code>AnnData</code> <p>An <code>AnnData</code> object of shape <code>(n_cells, n_genes)</code> with the counts per cell</p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def _count_transcripts_aligned(\n    geo_df: gpd.GeoDataFrame, points: dd.DataFrame, value_key: str\n) -&gt; AnnData:\n    \"\"\"Count transcripts per cell. The cells and points have to be aligned (i.e., in the same coordinate system)\n\n    Args:\n        geo_df: Cells geometries\n        points: Transcripts dataframe\n        value_key: Key of `points` containing the genes names\n\n    Returns:\n        An `AnnData` object of shape `(n_cells, n_genes)` with the counts per cell\n    \"\"\"\n    points[value_key] = points[value_key].astype(\"category\").cat.as_known()\n    gene_names = points[value_key].cat.categories.astype(str)\n\n    X = coo_matrix((len(geo_df), len(gene_names)), dtype=int)\n    adata = AnnData(X=X, var=pd.DataFrame(index=gene_names))\n    adata.obs_names = geo_df.index.astype(str)\n\n    geo_df = geo_df.reset_index()\n\n    X_partitions = []\n\n    with ProgressBar():\n        points.map_partitions(\n            partial(_add_coo, X_partitions, geo_df, gene_column=value_key, gene_names=gene_names),\n            meta=(),\n        ).compute()\n\n    for X_partition in X_partitions:\n        adata.X += X_partition\n\n    adata.X = adata.X.tocsr()\n    return adata\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.Aggregator","title":"<code>sopa.segmentation.aggregate.Aggregator</code>","text":"<p>Perform transcript count and channel averaging over a <code>SpatialData</code> object</p> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>class Aggregator:\n    \"\"\"Perform transcript count and channel averaging over a `SpatialData` object\"\"\"\n\n    def __init__(\n        self,\n        sdata: SpatialData,\n        overwrite: bool = True,\n        image_key: str | None = None,\n        shapes_key: str | None = None,\n    ):\n        \"\"\"\n        Args:\n            sdata: A `SpatialData` object\n            overwrite: If `True`, will overwrite `sdata.table` if already existing\n            image_key: Key of `sdata` with the image to be averaged. If only one image, this does not have to be provided.\n            shapes_key: Key of `sdata` with the shapes corresponding to the cells boundaries\n        \"\"\"\n        self.sdata = sdata\n        self.overwrite = overwrite\n\n        self.image_key, self.image = get_spatial_image(sdata, image_key, return_key=True)\n\n        if shapes_key is None:\n            self.shapes_key, self.geo_df = get_boundaries(sdata, return_key=True)\n        else:\n            self.shapes_key = shapes_key\n            self.geo_df = self.sdata[shapes_key]\n\n        self.table = None\n        self._had_table = False\n        if SopaKeys.TABLE in self.sdata.tables:\n            table = self.sdata.tables[SopaKeys.TABLE]\n            if len(self.geo_df) == table.n_obs:\n                log.info(\"Using existing table for aggregation\")\n                self.table = table\n                self._had_table = True\n\n    def overlay_segmentation(\n        self,\n        gene_column: str | None = None,\n        average_intensities: bool = True,\n        area_ratio_threshold: float = 0.25,\n        save_table: bool = True,\n    ):\n        old_table: AnnData = self.sdata.tables[SopaKeys.TABLE]\n        self.sdata.tables[SopaKeys.OLD_TABLE] = old_table\n        del self.sdata.tables[SopaKeys.TABLE]\n\n        old_shapes_key = old_table.uns[\"spatialdata_attrs\"][\"region\"]\n        instance_key = old_table.uns[\"spatialdata_attrs\"][\"instance_key\"]\n\n        if isinstance(old_shapes_key, list):\n            assert (\n                len(old_shapes_key) == 1\n            ), \"Can't overlap segmentation on multi-region SpatialData object\"\n            old_shapes_key = old_shapes_key[0]\n\n        old_geo_df = self.sdata[old_shapes_key]\n        geo_df = to_intrinsic(self.sdata, self.geo_df, old_geo_df)\n\n        geo_df.index.name = \"index_right\"  # to reuse the index name later\n        gdf_join = gpd.sjoin(old_geo_df, geo_df)\n        gdf_join[\"geometry_right\"] = gdf_join[\"index_right\"].map(lambda i: geo_df.geometry.iloc[i])\n        gdf_join[\"overlap_ratio\"] = gdf_join.apply(_overlap_area_ratio, axis=1)\n        gdf_join: gpd.GeoDataFrame = gdf_join[gdf_join.overlap_ratio &gt;= area_ratio_threshold]\n\n        table_crop = old_table[~np.isin(old_table.obs[instance_key], gdf_join.index)].copy()\n        table_crop.obs[SopaKeys.CELL_OVERLAY_KEY] = False\n\n        self.compute_table(\n            gene_column=gene_column, average_intensities=average_intensities, save_table=False\n        )\n        self.table.obs[SopaKeys.CELL_OVERLAY_KEY] = True\n\n        self.table = anndata.concat(\n            [table_crop, self.table], uns_merge=\"first\", join=\"outer\", fill_value=0\n        )\n        _fillna(self.table.obs)\n\n        self.shapes_key = f\"{old_shapes_key}+{self.shapes_key}\"\n        geo_df_cropped = old_geo_df.loc[~old_geo_df.index.isin(gdf_join.index)]\n        self.geo_df = pd.concat([geo_df_cropped, geo_df], join=\"outer\", axis=0)\n        self.geo_df.attrs = old_geo_df.attrs\n\n        self.standardized_table(save_table=save_table)\n\n    def standardized_table(self, save_table: bool = True):\n        self.table.obs_names = list(map(str_cell_id, range(self.table.n_obs)))\n\n        self.geo_df.index = list(self.table.obs_names)\n        self.sdata.shapes[self.shapes_key] = self.geo_df\n        if self.sdata.is_backed():\n            self.sdata.delete_element_from_disk(self.shapes_key)\n            self.sdata.write_element(self.shapes_key)\n\n        self.table.obsm[\"spatial\"] = np.array(\n            [[centroid.x, centroid.y] for centroid in self.geo_df.centroid]\n        )\n        self.table.obs[SopaKeys.REGION_KEY] = pd.Series(\n            self.shapes_key, index=self.table.obs_names, dtype=\"category\"\n        )\n        self.table.obs[SopaKeys.SLIDE_KEY] = pd.Series(\n            self.image_key, index=self.table.obs_names, dtype=\"category\"\n        )\n        self.table.obs[SopaKeys.INSTANCE_KEY] = self.geo_df.index\n\n        self.table.obs[SopaKeys.AREA_OBS] = self.geo_df.area.values\n\n        if \"spatialdata_attrs\" in self.table.uns:\n            del self.table.uns[\"spatialdata_attrs\"]\n\n        self.table = TableModel.parse(\n            self.table,\n            region_key=SopaKeys.REGION_KEY,\n            region=self.shapes_key,\n            instance_key=SopaKeys.INSTANCE_KEY,\n        )\n\n        self.sdata.tables[SopaKeys.TABLE] = self.table\n\n        if save_table and self.sdata.is_backed():\n            if self._had_table:\n                self.sdata.delete_element_from_disk(SopaKeys.TABLE)\n            self.sdata.write_element(SopaKeys.TABLE)\n\n    def filter_cells(self, where_filter: np.ndarray):\n        log.info(f\"Filtering {where_filter.sum()} cells\")\n\n        self.geo_df = self.geo_df[~where_filter]\n\n        self.sdata.shapes[self.shapes_key] = self.geo_df\n\n        if self.table is not None:\n            self.table = self.table[~where_filter]\n\n    def update_table(self, *args, **kwargs):\n        log.warn(\"'update_table' is deprecated, use 'compute_table' instead\")\n        self.compute_table(*args, **kwargs)\n\n    def compute_table(\n        self,\n        gene_column: str | None = None,\n        average_intensities: bool = True,\n        expand_radius_ratio: float = 0,\n        min_transcripts: int = 0,\n        min_intensity_ratio: float = 0,\n        save_table: bool = True,\n    ):\n        \"\"\"Perform aggregation and update the spatialdata table\n\n        Args:\n            gene_column: Column key of the transcript dataframe containing the gene names\n            average_intensities: Whether to average the channels intensities inside cells polygons\n            expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius` for channels averaging **only**. This help better aggregate boundary stainings\n            min_transcripts: Minimum amount of transcript to keep a cell\n            min_intensity_ratio: Cells whose mean channel intensity is less than `min_intensity_ratio * quantile_90` will be filtered\n            save_table: Whether the table should be saved on disk or not\n        \"\"\"\n        does_count = (\n            self.table is not None and isinstance(self.table.X, csr_matrix)\n        ) or gene_column is not None\n\n        assert (\n            average_intensities or does_count\n        ), \"You must choose at least one aggregation: transcripts or fluorescence intensities\"\n\n        if gene_column is not None:\n            if self.table is not None:\n                log.warn(\"sdata.table is already existing. Transcripts are not count again.\")\n            else:\n                self.table = count_transcripts(self.sdata, gene_column, shapes_key=self.shapes_key)\n\n        if does_count and min_transcripts &gt; 0:\n            self.filter_cells(self.table.X.sum(axis=1) &lt; min_transcripts)\n\n        if average_intensities:\n            mean_intensities = average_channels(\n                self.sdata,\n                image_key=self.image_key,\n                shapes_key=self.shapes_key,\n                expand_radius_ratio=expand_radius_ratio,\n            )\n\n            if min_intensity_ratio &gt; 0:\n                means = mean_intensities.mean(axis=1)\n                intensity_threshold = min_intensity_ratio * np.quantile(means, 0.9)\n                where_filter = means &lt; intensity_threshold\n                self.filter_cells(where_filter)\n                mean_intensities = mean_intensities[~where_filter]\n\n            if not does_count:\n                self.table = AnnData(\n                    mean_intensities,\n                    dtype=mean_intensities.dtype,\n                    var=pd.DataFrame(index=self.image.coords[\"c\"].values.astype(str)),\n                    obs=pd.DataFrame(index=self.geo_df.index),\n                )\n            else:\n                self.table.obsm[SopaKeys.INTENSITIES_OBSM] = pd.DataFrame(\n                    mean_intensities,\n                    columns=self.image.coords[\"c\"].values.astype(str),\n                    index=self.table.obs_names,\n                )\n\n        self.table.uns[SopaKeys.UNS_KEY] = {\n            \"version\": sopa.__version__,\n            SopaKeys.UNS_HAS_TRANSCRIPTS: does_count,\n            SopaKeys.UNS_HAS_INTENSITIES: average_intensities,\n        }\n\n        self.standardized_table(save_table=save_table)\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.Aggregator.__init__","title":"<code>__init__(sdata, overwrite=True, image_key=None, shapes_key=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>overwrite</code> <code>bool</code> <p>If <code>True</code>, will overwrite <code>sdata.table</code> if already existing</p> <code>True</code> <code>image_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the image to be averaged. If only one image, this does not have to be provided.</p> <code>None</code> <code>shapes_key</code> <code>str | None</code> <p>Key of <code>sdata</code> with the shapes corresponding to the cells boundaries</p> <code>None</code> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    overwrite: bool = True,\n    image_key: str | None = None,\n    shapes_key: str | None = None,\n):\n    \"\"\"\n    Args:\n        sdata: A `SpatialData` object\n        overwrite: If `True`, will overwrite `sdata.table` if already existing\n        image_key: Key of `sdata` with the image to be averaged. If only one image, this does not have to be provided.\n        shapes_key: Key of `sdata` with the shapes corresponding to the cells boundaries\n    \"\"\"\n    self.sdata = sdata\n    self.overwrite = overwrite\n\n    self.image_key, self.image = get_spatial_image(sdata, image_key, return_key=True)\n\n    if shapes_key is None:\n        self.shapes_key, self.geo_df = get_boundaries(sdata, return_key=True)\n    else:\n        self.shapes_key = shapes_key\n        self.geo_df = self.sdata[shapes_key]\n\n    self.table = None\n    self._had_table = False\n    if SopaKeys.TABLE in self.sdata.tables:\n        table = self.sdata.tables[SopaKeys.TABLE]\n        if len(self.geo_df) == table.n_obs:\n            log.info(\"Using existing table for aggregation\")\n            self.table = table\n            self._had_table = True\n</code></pre>"},{"location":"api/segmentation/aggregate/#sopa.segmentation.aggregate.Aggregator.compute_table","title":"<code>compute_table(gene_column=None, average_intensities=True, expand_radius_ratio=0, min_transcripts=0, min_intensity_ratio=0, save_table=True)</code>","text":"<p>Perform aggregation and update the spatialdata table</p> <p>Parameters:</p> Name Type Description Default <code>gene_column</code> <code>str | None</code> <p>Column key of the transcript dataframe containing the gene names</p> <code>None</code> <code>average_intensities</code> <code>bool</code> <p>Whether to average the channels intensities inside cells polygons</p> <code>True</code> <code>expand_radius_ratio</code> <code>float</code> <p>Cells polygons will be expanded by <code>expand_radius_ratio * mean_radius</code> for channels averaging only. This help better aggregate boundary stainings</p> <code>0</code> <code>min_transcripts</code> <code>int</code> <p>Minimum amount of transcript to keep a cell</p> <code>0</code> <code>min_intensity_ratio</code> <code>float</code> <p>Cells whose mean channel intensity is less than <code>min_intensity_ratio * quantile_90</code> will be filtered</p> <code>0</code> <code>save_table</code> <code>bool</code> <p>Whether the table should be saved on disk or not</p> <code>True</code> Source code in <code>sopa/segmentation/aggregate.py</code> <pre><code>def compute_table(\n    self,\n    gene_column: str | None = None,\n    average_intensities: bool = True,\n    expand_radius_ratio: float = 0,\n    min_transcripts: int = 0,\n    min_intensity_ratio: float = 0,\n    save_table: bool = True,\n):\n    \"\"\"Perform aggregation and update the spatialdata table\n\n    Args:\n        gene_column: Column key of the transcript dataframe containing the gene names\n        average_intensities: Whether to average the channels intensities inside cells polygons\n        expand_radius_ratio: Cells polygons will be expanded by `expand_radius_ratio * mean_radius` for channels averaging **only**. This help better aggregate boundary stainings\n        min_transcripts: Minimum amount of transcript to keep a cell\n        min_intensity_ratio: Cells whose mean channel intensity is less than `min_intensity_ratio * quantile_90` will be filtered\n        save_table: Whether the table should be saved on disk or not\n    \"\"\"\n    does_count = (\n        self.table is not None and isinstance(self.table.X, csr_matrix)\n    ) or gene_column is not None\n\n    assert (\n        average_intensities or does_count\n    ), \"You must choose at least one aggregation: transcripts or fluorescence intensities\"\n\n    if gene_column is not None:\n        if self.table is not None:\n            log.warn(\"sdata.table is already existing. Transcripts are not count again.\")\n        else:\n            self.table = count_transcripts(self.sdata, gene_column, shapes_key=self.shapes_key)\n\n    if does_count and min_transcripts &gt; 0:\n        self.filter_cells(self.table.X.sum(axis=1) &lt; min_transcripts)\n\n    if average_intensities:\n        mean_intensities = average_channels(\n            self.sdata,\n            image_key=self.image_key,\n            shapes_key=self.shapes_key,\n            expand_radius_ratio=expand_radius_ratio,\n        )\n\n        if min_intensity_ratio &gt; 0:\n            means = mean_intensities.mean(axis=1)\n            intensity_threshold = min_intensity_ratio * np.quantile(means, 0.9)\n            where_filter = means &lt; intensity_threshold\n            self.filter_cells(where_filter)\n            mean_intensities = mean_intensities[~where_filter]\n\n        if not does_count:\n            self.table = AnnData(\n                mean_intensities,\n                dtype=mean_intensities.dtype,\n                var=pd.DataFrame(index=self.image.coords[\"c\"].values.astype(str)),\n                obs=pd.DataFrame(index=self.geo_df.index),\n            )\n        else:\n            self.table.obsm[SopaKeys.INTENSITIES_OBSM] = pd.DataFrame(\n                mean_intensities,\n                columns=self.image.coords[\"c\"].values.astype(str),\n                index=self.table.obs_names,\n            )\n\n    self.table.uns[SopaKeys.UNS_KEY] = {\n        \"version\": sopa.__version__,\n        SopaKeys.UNS_HAS_TRANSCRIPTS: does_count,\n        SopaKeys.UNS_HAS_INTENSITIES: average_intensities,\n    }\n\n    self.standardized_table(save_table=save_table)\n</code></pre>"},{"location":"api/segmentation/methods/","title":"sopa.segmentation.methods","text":""},{"location":"api/segmentation/methods/#sopa.segmentation.methods.cellpose_patch","title":"<code>sopa.segmentation.methods.cellpose_patch(diameter, channels, model_type='cyto3', pretrained_model=False, cellpose_model_kwargs=None, **cellpose_eval_kwargs)</code>","text":"<p>Creation of a callable that runs Cellpose segmentation on a patch</p> <p>Parameters:</p> Name Type Description Default <code>diameter</code> <code>float</code> <p>Cellpose diameter parameter</p> required <code>channels</code> <code>list[str]</code> <p>List of channel names</p> required <code>model_type</code> <code>str</code> <p>Cellpose model type</p> <code>'cyto3'</code> <code>pretrained_model</code> <code>str | bool</code> <p>Path to the pretrained model to be loaded</p> <code>False</code> <code>cellpose_model_kwargs</code> <code>dict | None</code> <p>Kwargs to be provided to the <code>cellpose.models.CellposeModel</code> object</p> <code>None</code> <code>**cellpose_eval_kwargs</code> <code>int</code> <p>Kwargs to be provided to <code>model.eval</code> (where <code>model</code> is a <code>cellpose.models.CellposeModel</code> object)</p> <code>{}</code> <p>Returns:</p> Type Description <code>Callable</code> <p>A <code>callable</code> whose input is an image of shape <code>(C, Y, X)</code> and output is a cell mask of shape <code>(Y, X)</code>. Each mask value <code>&gt;0</code> represent a unique cell ID</p> Source code in <code>sopa/segmentation/methods.py</code> <pre><code>def cellpose_patch(\n    diameter: float,\n    channels: list[str],\n    model_type: str = \"cyto3\",\n    pretrained_model: str | bool = False,\n    cellpose_model_kwargs: dict | None = None,\n    **cellpose_eval_kwargs: int,\n) -&gt; Callable:\n    \"\"\"Creation of a callable that runs Cellpose segmentation on a patch\n\n    Args:\n        diameter: Cellpose diameter parameter\n        channels: List of channel names\n        model_type: Cellpose model type\n        pretrained_model: Path to the pretrained model to be loaded\n        cellpose_model_kwargs: Kwargs to be provided to the `cellpose.models.CellposeModel` object\n        **cellpose_eval_kwargs: Kwargs to be provided to `model.eval` (where `model` is a `cellpose.models.CellposeModel` object)\n\n    Returns:\n        A `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID\n    \"\"\"\n    try:\n        from cellpose import models\n    except ImportError:\n        raise ImportError(\n            \"To use cellpose, you need its corresponding sopa extra: `pip install 'sopa[cellpose]'` (normal mode) or `pip install -e '.[cellpose]'` (if using snakemake)\"\n        )\n\n    cellpose_model_kwargs = cellpose_model_kwargs or {}\n\n    model = models.CellposeModel(\n        model_type=model_type, pretrained_model=pretrained_model, **cellpose_model_kwargs\n    )\n\n    if isinstance(channels, str) or len(channels) == 1:\n        channels = [0, 0]  # gray scale\n    elif len(channels) == 2:\n        channels = [1, 2]\n    else:\n        raise ValueError(f\"Provide 1 or 2 channels. Found {len(channels)}\")\n\n    def _(patch: np.ndarray):\n        mask, *_ = model.eval(patch, diameter=diameter, channels=channels, **cellpose_eval_kwargs)\n        return mask\n\n    return _\n</code></pre>"},{"location":"api/segmentation/patching/","title":"sopa.segmentation.patching","text":""},{"location":"api/segmentation/patching/#sopa.segmentation.Patches2D","title":"<code>sopa.segmentation.Patches2D</code>","text":"<p>Compute 2D-patches with overlaps. This can be done on an image or a DataFrame.</p> <p>Attributes:</p> Name Type Description <code>polygons</code> <code>list[Polygon]</code> <p>List of <code>shapely</code> polygons representing the patches</p> <code>bboxes</code> <code>ndarray</code> <p>Array of shape <code>(n_patches, 4)</code> containing the (xmin, ymin, xmax, ymax) coordinates of the patches bounding boxes</p> <code>ilocs</code> <code>ndarray</code> <p>Array of shape <code>(n_patches, 2)</code> containing the (x,y) indices of the patches</p> Source code in <code>sopa/patches/patches.py</code> <pre><code>class Patches2D:\n    \"\"\"\n    Compute 2D-patches with overlaps. This can be done on an image or a DataFrame.\n\n    Attributes:\n        polygons (list[Polygon]): List of `shapely` polygons representing the patches\n        bboxes (np.ndarray): Array of shape `(n_patches, 4)` containing the (xmin, ymin, xmax, ymax) coordinates of the patches bounding boxes\n        ilocs (np.ndarray): Array of shape `(n_patches, 2)` containing the (x,y) indices of the patches\n    \"\"\"\n\n    polygons: list[Polygon]\n    bboxes: np.ndarray\n    ilocs: np.ndarray\n\n    def __init__(\n        self,\n        sdata: SpatialData,\n        element_name: str,\n        patch_width: float | int,\n        patch_overlap: float | int = 50,\n    ):\n        \"\"\"\n        Args:\n            sdata: A `SpatialData` object\n            element_name: Name of the element on with patches will be made (image or points)\n            patch_width: Width of the patches (in the unit of the coordinate system of the element)\n            patch_overlap: Overlap width between the patches\n        \"\"\"\n        self.sdata = sdata\n        self.element_name = element_name\n        self.element = sdata[element_name]\n\n        if isinstance(self.element, DataTree):\n            self.element = get_spatial_image(sdata, element_name)\n\n        if isinstance(self.element, DataArray):\n            xmin, ymin = 0, 0\n            xmax, ymax = len(self.element.coords[\"x\"]), len(self.element.coords[\"y\"])\n            tight, int_coords = False, True\n        elif isinstance(self.element, dd.DataFrame):\n            xmin, ymin = self.element.x.min().compute(), self.element.y.min().compute()\n            xmax, ymax = self.element.x.max().compute(), self.element.y.max().compute()\n            tight, int_coords = True, False\n        else:\n            raise ValueError(f\"Invalid element type: {type(self.element)}\")\n\n        self.patch_x = Patches1D(xmin, xmax, patch_width, patch_overlap, tight, int_coords)\n        self.patch_y = Patches1D(ymin, ymax, patch_width, patch_overlap, tight, int_coords)\n\n        self.roi = None\n        if ROI.KEY in sdata.shapes:\n            geo_df = to_intrinsic(sdata, sdata[ROI.KEY], element_name)\n\n            assert all(\n                isinstance(geom, Polygon) for geom in geo_df.geometry\n            ), f\"All sdata['{ROI.KEY}'] geometries must be polygons\"\n\n            if len(geo_df) == 1:\n                self.roi: Polygon = geo_df.geometry[0]\n            else:\n                self.roi = MultiPolygon(list(geo_df.geometry))\n\n        self._init_patches()\n\n    def _init_patches(self):\n        self.ilocs, self.polygons, self.bboxes = [], [], []\n\n        for i in range(self.patch_x._count * self.patch_y._count):\n            self._try_register_patch(i)\n\n        self.ilocs = np.array(self.ilocs)\n        self.bboxes = np.array(self.bboxes)\n\n    def _try_register_patch(self, i: int):\n        \"\"\"Check that the patch is valid, and, if valid, register it\"\"\"\n        iy, ix = divmod(i, self.patch_x._count)\n        bounds = self._bbox_iloc(ix, iy)\n        patch = box(*bounds)\n\n        if self.roi is not None and not self.roi.intersects(patch):\n            return\n\n        patch = patch if self.roi is None else patch.intersection(self.roi)\n\n        if isinstance(patch, GeometryCollection):\n            geoms = [geom for geom in patch.geoms if isinstance(geom, Polygon)]\n            if not geoms:\n                return\n            patch = max(geoms, key=lambda polygon: polygon.area)\n\n        if not isinstance(patch, Polygon) and not isinstance(patch, MultiPolygon):\n            return\n\n        self.polygons.append(patch)\n        self.ilocs.append((ix, iy))\n        self.bboxes.append(bounds)\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__} object with {len(self)} patches on {self.element_name}\"\n\n    @property\n    def shape(self) -&gt; tuple[int, int]:\n        return (self.patch_y._count, self.patch_x._count)\n\n    def _bbox_iloc(self, ix: int, iy: int) -&gt; list[int]:\n        \"\"\"Coordinates of the rectangle bounding box of the patch at the given indices\n\n        Args:\n            ix: Patch index in the x-axis\n            iy: Patch indes in the y-axis\n\n        Returns:\n            A list `[xmin, ymin, xmax, ymax]` representing the bounding box of the patch\n        \"\"\"\n        xmin, xmax = self.patch_x[ix]\n        ymin, ymax = self.patch_y[iy]\n        return [xmin, ymin, xmax, ymax]\n\n    def __len__(self):\n        \"\"\"Number of patches\"\"\"\n        return len(self.bboxes)\n\n    def write(self, overwrite: bool = True, shapes_key: str | None = None) -&gt; gpd.GeoDataFrame:\n        \"\"\"Save patches in `sdata.shapes[\"sopa_patches\"]` (or by the key specified)\n\n        Args:\n            overwrite: Whether to overwrite patches if existing\n            shapes_key: Optional name of the shapes to be saved. By default, uses \"sopa_patches\".\n\n        Returns:\n            The saved GeoDataFrame\n        \"\"\"\n        shapes_key = SopaKeys.PATCHES if shapes_key is None else shapes_key\n\n        geo_df = gpd.GeoDataFrame(\n            {\n                \"geometry\": self.polygons,\n                SopaKeys.BOUNDS: self.bboxes.tolist(),\n                SopaKeys.PATCHES_ILOCS: self.ilocs.tolist(),\n            }\n        )\n        geo_df = ShapesModel.parse(\n            geo_df, transformations=get_transformation(self.element, get_all=True).copy()\n        )\n\n        self.sdata.shapes[shapes_key] = geo_df\n        if self.sdata.is_backed():\n            self.sdata.write_element(shapes_key, overwrite=overwrite)\n\n        log.info(f\"{len(geo_df)} patches were saved in sdata['{shapes_key}']\")\n\n        return geo_df\n\n    def patchify_transcripts(\n        self,\n        temp_dir: str,\n        cell_key: str = None,\n        unassigned_value: int | str = None,\n        use_prior: bool = False,\n        config: dict = {},\n        config_path: str | None = None,\n        config_name: str = SopaFiles.TOML_CONFIG_FILE,\n        csv_name: str = SopaFiles.TRANSCRIPTS_FILE,\n        min_transcripts_per_patch: int = 4000,\n        shapes_key: str = SopaKeys.CELLPOSE_BOUNDARIES,\n    ) -&gt; list[int]:\n        \"\"\"Creation of patches for the transcripts.\n\n        !!! info \"Prior segmentation usage\"\n            To save assign a prior segmentation to each transcript, you can either use `cell_key` or `use_prior`:\n\n            - If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use `cell_key` to denote the column of the transcript dataframe containing the cell IDs (and optionaly `unassigned_value`).\n            - If you have already run Cellpose with Sopa, use `use_prior` (no need to provide `cell_key` and `unassigned_value`).\n\n        Args:\n            temp_dir: Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.\n            cell_key: Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.\n            unassigned_value: If `cell_key` has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.\n            use_prior: Whether to use Cellpose as a prior segmentation. If `True`, make sure you have already run Cellpose with Sopa, and no need to provide `cell_key` and `unassigned_value`. Note that, if you have MERFISH data, the prior has already been run, so just use `cell_key` and `unassigned_value`.\n            config: Dictionnary of segmentation parameters\n            config_path: Path to the segmentation config file (you can also directly provide the argument via the `config` option)\n            config_name: Name of the config file to be saved in each patch subdirectory\n            csv_name: Name of the CSV file to be saved in each patch subdirectory\n            min_transcripts_per_patch: Minimum number of transcripts for a patch to be considered for segmentation\n\n        Returns:\n            A list of patches indices. Each index correspond to the name of a subdirectory inside `temp_dir`\n        \"\"\"\n        return TranscriptPatches(\n            self, self.element, config_name, csv_name, min_transcripts_per_patch\n        ).write(temp_dir, cell_key, unassigned_value, use_prior, config, config_path, shapes_key)\n\n    def patchify_centroids(\n        self,\n        temp_dir: str,\n        shapes_key: str = SopaKeys.CELLPOSE_BOUNDARIES,\n        csv_name: str = SopaFiles.CENTROIDS_FILE,\n        cell_key: str | None = None,\n        min_cells_per_patch: int = 1,\n    ) -&gt; list[int]:\n        assert isinstance(self.element, dd.DataFrame)\n\n        centroids = to_intrinsic(self.sdata, shapes_key, self.element).geometry.centroid\n        centroids = gpd.GeoDataFrame(geometry=centroids)\n        centroids[cell_key or SopaKeys.DEFAULT_CELL_KEY] = range(1, len(centroids) + 1)\n        centroids[\"x\"] = centroids.geometry.x\n        centroids[\"y\"] = centroids.geometry.y\n        centroids[\"z\"] = 0\n\n        return TranscriptPatches(self, centroids, None, csv_name, min_cells_per_patch).write(\n            temp_dir, shapes_key=shapes_key\n        )\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.Patches2D.__init__","title":"<code>__init__(sdata, element_name, patch_width, patch_overlap=50)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>element_name</code> <code>str</code> <p>Name of the element on with patches will be made (image or points)</p> required <code>patch_width</code> <code>float | int</code> <p>Width of the patches (in the unit of the coordinate system of the element)</p> required <code>patch_overlap</code> <code>float | int</code> <p>Overlap width between the patches</p> <code>50</code> Source code in <code>sopa/patches/patches.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    element_name: str,\n    patch_width: float | int,\n    patch_overlap: float | int = 50,\n):\n    \"\"\"\n    Args:\n        sdata: A `SpatialData` object\n        element_name: Name of the element on with patches will be made (image or points)\n        patch_width: Width of the patches (in the unit of the coordinate system of the element)\n        patch_overlap: Overlap width between the patches\n    \"\"\"\n    self.sdata = sdata\n    self.element_name = element_name\n    self.element = sdata[element_name]\n\n    if isinstance(self.element, DataTree):\n        self.element = get_spatial_image(sdata, element_name)\n\n    if isinstance(self.element, DataArray):\n        xmin, ymin = 0, 0\n        xmax, ymax = len(self.element.coords[\"x\"]), len(self.element.coords[\"y\"])\n        tight, int_coords = False, True\n    elif isinstance(self.element, dd.DataFrame):\n        xmin, ymin = self.element.x.min().compute(), self.element.y.min().compute()\n        xmax, ymax = self.element.x.max().compute(), self.element.y.max().compute()\n        tight, int_coords = True, False\n    else:\n        raise ValueError(f\"Invalid element type: {type(self.element)}\")\n\n    self.patch_x = Patches1D(xmin, xmax, patch_width, patch_overlap, tight, int_coords)\n    self.patch_y = Patches1D(ymin, ymax, patch_width, patch_overlap, tight, int_coords)\n\n    self.roi = None\n    if ROI.KEY in sdata.shapes:\n        geo_df = to_intrinsic(sdata, sdata[ROI.KEY], element_name)\n\n        assert all(\n            isinstance(geom, Polygon) for geom in geo_df.geometry\n        ), f\"All sdata['{ROI.KEY}'] geometries must be polygons\"\n\n        if len(geo_df) == 1:\n            self.roi: Polygon = geo_df.geometry[0]\n        else:\n            self.roi = MultiPolygon(list(geo_df.geometry))\n\n    self._init_patches()\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.Patches2D.__len__","title":"<code>__len__()</code>","text":"<p>Number of patches</p> Source code in <code>sopa/patches/patches.py</code> <pre><code>def __len__(self):\n    \"\"\"Number of patches\"\"\"\n    return len(self.bboxes)\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.Patches2D.patchify_transcripts","title":"<code>patchify_transcripts(temp_dir, cell_key=None, unassigned_value=None, use_prior=False, config={}, config_path=None, config_name=SopaFiles.TOML_CONFIG_FILE, csv_name=SopaFiles.TRANSCRIPTS_FILE, min_transcripts_per_patch=4000, shapes_key=SopaKeys.CELLPOSE_BOUNDARIES)</code>","text":"<p>Creation of patches for the transcripts.</p> <p>Prior segmentation usage</p> <p>To save assign a prior segmentation to each transcript, you can either use <code>cell_key</code> or <code>use_prior</code>:</p> <ul> <li>If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use <code>cell_key</code> to denote the column of the transcript dataframe containing the cell IDs (and optionaly <code>unassigned_value</code>).</li> <li>If you have already run Cellpose with Sopa, use <code>use_prior</code> (no need to provide <code>cell_key</code> and <code>unassigned_value</code>).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>temp_dir</code> <code>str</code> <p>Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.</p> required <code>cell_key</code> <code>str</code> <p>Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.</p> <code>None</code> <code>unassigned_value</code> <code>int | str</code> <p>If <code>cell_key</code> has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.</p> <code>None</code> <code>use_prior</code> <code>bool</code> <p>Whether to use Cellpose as a prior segmentation. If <code>True</code>, make sure you have already run Cellpose with Sopa, and no need to provide <code>cell_key</code> and <code>unassigned_value</code>. Note that, if you have MERFISH data, the prior has already been run, so just use <code>cell_key</code> and <code>unassigned_value</code>.</p> <code>False</code> <code>config</code> <code>dict</code> <p>Dictionnary of segmentation parameters</p> <code>{}</code> <code>config_path</code> <code>str | None</code> <p>Path to the segmentation config file (you can also directly provide the argument via the <code>config</code> option)</p> <code>None</code> <code>config_name</code> <code>str</code> <p>Name of the config file to be saved in each patch subdirectory</p> <code>TOML_CONFIG_FILE</code> <code>csv_name</code> <code>str</code> <p>Name of the CSV file to be saved in each patch subdirectory</p> <code>TRANSCRIPTS_FILE</code> <code>min_transcripts_per_patch</code> <code>int</code> <p>Minimum number of transcripts for a patch to be considered for segmentation</p> <code>4000</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>A list of patches indices. Each index correspond to the name of a subdirectory inside <code>temp_dir</code></p> Source code in <code>sopa/patches/patches.py</code> <pre><code>def patchify_transcripts(\n    self,\n    temp_dir: str,\n    cell_key: str = None,\n    unassigned_value: int | str = None,\n    use_prior: bool = False,\n    config: dict = {},\n    config_path: str | None = None,\n    config_name: str = SopaFiles.TOML_CONFIG_FILE,\n    csv_name: str = SopaFiles.TRANSCRIPTS_FILE,\n    min_transcripts_per_patch: int = 4000,\n    shapes_key: str = SopaKeys.CELLPOSE_BOUNDARIES,\n) -&gt; list[int]:\n    \"\"\"Creation of patches for the transcripts.\n\n    !!! info \"Prior segmentation usage\"\n        To save assign a prior segmentation to each transcript, you can either use `cell_key` or `use_prior`:\n\n        - If a segmentation has already been performed (for example an existing 10X-Genomics segmentation), use `cell_key` to denote the column of the transcript dataframe containing the cell IDs (and optionaly `unassigned_value`).\n        - If you have already run Cellpose with Sopa, use `use_prior` (no need to provide `cell_key` and `unassigned_value`).\n\n    Args:\n        temp_dir: Temporary directory where each patch will be stored. Note that each patch will have its own subdirectory.\n        cell_key: Optional key of the transcript dataframe containing the cell IDs. This is useful if a prior segmentation has been run, assigning each transcript to a cell.\n        unassigned_value: If `cell_key` has been provided, this corresponds to the value given in the 'cell ID' column for transcript that are not inside any cell.\n        use_prior: Whether to use Cellpose as a prior segmentation. If `True`, make sure you have already run Cellpose with Sopa, and no need to provide `cell_key` and `unassigned_value`. Note that, if you have MERFISH data, the prior has already been run, so just use `cell_key` and `unassigned_value`.\n        config: Dictionnary of segmentation parameters\n        config_path: Path to the segmentation config file (you can also directly provide the argument via the `config` option)\n        config_name: Name of the config file to be saved in each patch subdirectory\n        csv_name: Name of the CSV file to be saved in each patch subdirectory\n        min_transcripts_per_patch: Minimum number of transcripts for a patch to be considered for segmentation\n\n    Returns:\n        A list of patches indices. Each index correspond to the name of a subdirectory inside `temp_dir`\n    \"\"\"\n    return TranscriptPatches(\n        self, self.element, config_name, csv_name, min_transcripts_per_patch\n    ).write(temp_dir, cell_key, unassigned_value, use_prior, config, config_path, shapes_key)\n</code></pre>"},{"location":"api/segmentation/patching/#sopa.segmentation.Patches2D.write","title":"<code>write(overwrite=True, shapes_key=None)</code>","text":"<p>Save patches in <code>sdata.shapes[\"sopa_patches\"]</code> (or by the key specified)</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>Whether to overwrite patches if existing</p> <code>True</code> <code>shapes_key</code> <code>str | None</code> <p>Optional name of the shapes to be saved. By default, uses \"sopa_patches\".</p> <code>None</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>The saved GeoDataFrame</p> Source code in <code>sopa/patches/patches.py</code> <pre><code>def write(self, overwrite: bool = True, shapes_key: str | None = None) -&gt; gpd.GeoDataFrame:\n    \"\"\"Save patches in `sdata.shapes[\"sopa_patches\"]` (or by the key specified)\n\n    Args:\n        overwrite: Whether to overwrite patches if existing\n        shapes_key: Optional name of the shapes to be saved. By default, uses \"sopa_patches\".\n\n    Returns:\n        The saved GeoDataFrame\n    \"\"\"\n    shapes_key = SopaKeys.PATCHES if shapes_key is None else shapes_key\n\n    geo_df = gpd.GeoDataFrame(\n        {\n            \"geometry\": self.polygons,\n            SopaKeys.BOUNDS: self.bboxes.tolist(),\n            SopaKeys.PATCHES_ILOCS: self.ilocs.tolist(),\n        }\n    )\n    geo_df = ShapesModel.parse(\n        geo_df, transformations=get_transformation(self.element, get_all=True).copy()\n    )\n\n    self.sdata.shapes[shapes_key] = geo_df\n    if self.sdata.is_backed():\n        self.sdata.write_element(shapes_key, overwrite=overwrite)\n\n    log.info(f\"{len(geo_df)} patches were saved in sdata['{shapes_key}']\")\n\n    return geo_df\n</code></pre>"},{"location":"api/segmentation/shapes/","title":"sopa.segmentation.shapes","text":""},{"location":"api/segmentation/shapes/#sopa.segmentation.shapes.solve_conflicts","title":"<code>sopa.segmentation.shapes.solve_conflicts(cells, threshold=0.5, patch_indices=None, return_indices=False)</code>","text":"<p>Resolve segmentation conflicts (i.e. overlap) after running segmentation on patches</p> <p>Parameters:</p> Name Type Description Default <code>cells</code> <code>list[Polygon]</code> <p>List of cell polygons</p> required <code>threshold</code> <code>float</code> <p>When two cells are overlapping, we look at the area of intersection over the area of the smallest cell. If this value is higher than the <code>threshold</code>, the cells are merged</p> <code>0.5</code> <code>patch_indices</code> <code>ndarray | None</code> <p>Patch from which each cell belongs.</p> <code>None</code> <code>return_indices</code> <code>bool</code> <p>If <code>True</code>, returns also the cells indices. Merged cells have an index of -1.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray[Polygon] | tuple[ndarray[Polygon], ndarray]</code> <p>Array of resolved cells polygons. If <code>return_indices</code>, it also returns an array of cell indices.</p> Source code in <code>sopa/segmentation/shapes.py</code> <pre><code>def solve_conflicts(\n    cells: list[Polygon],\n    threshold: float = 0.5,\n    patch_indices: np.ndarray | None = None,\n    return_indices: bool = False,\n) -&gt; np.ndarray[Polygon] | tuple[np.ndarray[Polygon], np.ndarray]:\n    \"\"\"Resolve segmentation conflicts (i.e. overlap) after running segmentation on patches\n\n    Args:\n        cells: List of cell polygons\n        threshold: When two cells are overlapping, we look at the area of intersection over the area of the smallest cell. If this value is higher than the `threshold`, the cells are merged\n        patch_indices: Patch from which each cell belongs.\n        return_indices: If `True`, returns also the cells indices. Merged cells have an index of -1.\n\n    Returns:\n        Array of resolved cells polygons. If `return_indices`, it also returns an array of cell indices.\n    \"\"\"\n    cells = list(cells)\n    n_cells = len(cells)\n    resolved_indices = np.arange(n_cells)\n\n    assert n_cells &gt; 0, \"No cells was segmented, cannot continue\"\n\n    tree = shapely.STRtree(cells)\n    conflicts = tree.query(cells, predicate=\"intersects\")\n\n    if patch_indices is not None:\n        conflicts = conflicts[:, patch_indices[conflicts[0]] != patch_indices[conflicts[1]]].T\n    else:\n        conflicts = conflicts[:, conflicts[0] != conflicts[1]].T\n\n    for i1, i2 in tqdm(conflicts, desc=\"Resolving conflicts\"):\n        resolved_i1: int = resolved_indices[i1]\n        resolved_i2: int = resolved_indices[i2]\n        cell1, cell2 = cells[resolved_i1], cells[resolved_i2]\n\n        intersection = cell1.intersection(cell2).area\n        if intersection &gt;= threshold * min(cell1.area, cell2.area):\n            cell = _ensure_polygon(cell1.union(cell2))\n\n            resolved_indices[np.isin(resolved_indices, [resolved_i1, resolved_i2])] = len(cells)\n            cells.append(cell)\n\n    unique_indices = np.unique(resolved_indices)\n    unique_cells = np.array(cells)[unique_indices]\n\n    if return_indices:\n        return unique_cells, np.where(unique_indices &lt; n_cells, unique_indices, -1)\n\n    return unique_cells\n</code></pre>"},{"location":"api/segmentation/shapes/#sopa.segmentation.shapes.geometrize","title":"<code>sopa.segmentation.shapes.geometrize(mask, tolerance=None, smooth_radius_ratio=0.1)</code>","text":"<p>Convert a cells mask to multiple <code>shapely</code> geometries. Inspired from https://github.com/Vizgen/vizgen-postprocessing</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>A cell mask. Non-null values correspond to cell ids</p> required <code>tolerance</code> <code>float | None</code> <p>Tolerance parameter used by <code>shapely</code> during simplification. By default, define the tolerance automatically.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Polygon]</code> <p>List of <code>shapely</code> polygons representing each cell ID of the mask</p> Source code in <code>sopa/segmentation/shapes.py</code> <pre><code>def geometrize(\n    mask: np.ndarray, tolerance: float | None = None, smooth_radius_ratio: float = 0.1\n) -&gt; list[Polygon]:\n    \"\"\"Convert a cells mask to multiple `shapely` geometries. Inspired from https://github.com/Vizgen/vizgen-postprocessing\n\n    Args:\n        mask: A cell mask. Non-null values correspond to cell ids\n        tolerance: Tolerance parameter used by `shapely` during simplification. By default, define the tolerance automatically.\n\n    Returns:\n        List of `shapely` polygons representing each cell ID of the mask\n    \"\"\"\n    max_cells = mask.max()\n\n    if max_cells == 0:\n        log.warn(\"No cell was returned by the segmentation\")\n        return []\n\n    cells = [_contours((mask == cell_id).astype(\"uint8\")) for cell_id in range(1, max_cells + 1)]\n\n    mean_radius = np.sqrt(np.array([cell.area for cell in cells]) / np.pi).mean()\n    smooth_radius = mean_radius * smooth_radius_ratio\n\n    if tolerance is None:\n        tolerance = _default_tolerance(mean_radius)\n\n    cells = [_smoothen_cell(cell, smooth_radius, tolerance) for cell in cells]\n    cells = [cell for cell in cells if cell is not None]\n\n    log.info(\n        f\"Percentage of non-geometrized cells: {(max_cells - len(cells)) / max_cells:.2%} (usually due to segmentation artefacts)\"\n    )\n\n    return cells\n</code></pre>"},{"location":"api/segmentation/shapes/#sopa.segmentation.shapes.rasterize","title":"<code>sopa.segmentation.shapes.rasterize(cell, shape, xy_min=[0, 0])</code>","text":"<p>Transform a cell polygon into a numpy array with value 1 where the polygon touches a pixel, else 0.</p> <p>Parameters:</p> Name Type Description Default <code>cell</code> <code>Polygon</code> <p>Cell polygon to rasterize.</p> required <code>shape</code> <code>tuple[int, int]</code> <p>Image shape as a tuple (y, x).</p> required <code>xy_min</code> <code>tuple[int, int]</code> <p>Tuple containing the origin of the image [x0, y0].</p> <code>[0, 0]</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The mask array.</p> Source code in <code>sopa/segmentation/shapes.py</code> <pre><code>def rasterize(\n    cell: Polygon, shape: tuple[int, int], xy_min: tuple[int, int] = [0, 0]\n) -&gt; np.ndarray:\n    \"\"\"Transform a cell polygon into a numpy array with value 1 where the polygon touches a pixel, else 0.\n\n    Args:\n        cell: Cell polygon to rasterize.\n        shape: Image shape as a tuple (y, x).\n        xy_min: Tuple containing the origin of the image [x0, y0].\n\n    Returns:\n        The mask array.\n    \"\"\"\n    import cv2\n\n    xmin, ymin, xmax, ymax = [xy_min[0], xy_min[1], xy_min[0] + shape[1], xy_min[1] + shape[0]]\n\n    cell_translated = shapely.affinity.translate(cell, -xmin, -ymin)\n\n    coords = np.array(cell_translated.exterior.coords)[None, :].astype(np.int32)\n    return cv2.fillPoly(np.zeros((ymax - ymin, xmax - xmin), dtype=np.int8), coords, color=1)\n</code></pre>"},{"location":"api/segmentation/stainings/","title":"sopa.segmentation.stainings","text":""},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation","title":"<code>sopa.segmentation.stainings.StainingSegmentation</code>","text":"Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>class StainingSegmentation:\n    def __init__(\n        self,\n        sdata: SpatialData,\n        method: Callable,\n        channels: list[str] | str,\n        image_key: str | None = None,\n        min_area: float = 0,\n        clip_limit: float = 0.2,\n        gaussian_sigma: float = 1,\n    ):\n        \"\"\"Generalized staining-based segmentation\n\n        !!! note \"Sequential segmentation (slower)\"\n            ```python\n            from sopa.segmentation.stainings import StainingSegmentation\n\n            method = ... # custom callable that runs segmentation on each patch\n\n            segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n            segmentation.write_patches_cells(\"./temp_dir\")\n\n            cells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\n            StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n            ```\n\n        !!! note \"Parallel segmentation (faster)\"\n            ```python\n            from sopa.segmentation.stainings import StainingSegmentation\n\n            method = ... # custom callable that runs segmentation on each patch\n\n            segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n\n            # Run all this in a parallel manner, e.g. on different jobs\n            for i in range(len(sdata['sopa_patches'])):\n                segmentation.write_patch_cells(\"./temp_dir\", i)\n\n            cells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\n            StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n            ```\n\n        Args:\n            sdata: A `SpatialData` object\n            method: A segmentation `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID. Such callables can be found in `sopa.segmentation.methods`.\n            channels: One or a list of channel names used for segmentation. If only one channel is provided, the image given to the `method` will be of shape `(1, Y, X)`.\n            image_key: Optional key of `sdata` containing the image (no needed if there is only one image)\n            min_area: Minimum area (in pixels^2) for a cell to be kept\n            clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)\n            gaussian_sigma: Parameter for scipy gaussian_filter (applied before running cellpose)\n        \"\"\"\n        self.sdata = sdata\n        self.method = method\n        self.channels = [channels] if isinstance(channels, str) else channels\n\n        self.min_area = min_area\n        self.clip_limit = clip_limit\n        self.gaussian_sigma = gaussian_sigma\n\n        self.image_key, self.image = get_spatial_image(sdata, key=image_key, return_key=True)\n\n        image_channels = self.image.coords[\"c\"].values\n        assert np.isin(\n            channels, image_channels\n        ).all(), f\"Channel names must be a subset of: {', '.join(image_channels)}\"\n\n    def _run_patch(self, patch: Polygon) -&gt; list[Polygon]:\n        \"\"\"Run segmentation on one patch\n\n        Args:\n            patch: Patch, represented as a `shapely` polygon\n\n        Returns:\n            A list of cells, represented as polygons\n        \"\"\"\n        bounds = [int(x) for x in patch.bounds]\n\n        image = self.image.sel(\n            c=self.channels,\n            x=slice(bounds[0], bounds[2]),\n            y=slice(bounds[1], bounds[3]),\n        ).values\n\n        image = gaussian_filter(image, sigma=self.gaussian_sigma)\n        image = exposure.equalize_adapthist(image, clip_limit=self.clip_limit)\n\n        if patch.area &lt; box(*bounds).area:\n            image = image * shapes.rasterize(patch, image.shape[1:], bounds)\n\n        cells = shapes.geometrize(self.method(image))\n\n        if self.min_area &gt; 0:\n            cells = [cell for cell in cells if cell.area &gt;= self.min_area]\n\n        return [affinity.translate(cell, *bounds[:2]) for cell in cells]\n\n    def write_patch_cells(self, patch_dir: str, patch_index: int):\n        \"\"\"Run segmentation on one patch, and save the result in a dedicated directory\n\n        Args:\n            patch_dir: Directory inside which segmentation results will be saved\n            patch_index: Index of the patch on which to run segmentation. NB: the number of patches is `len(sdata['sopa_patches'])`\n        \"\"\"\n        patch = self.sdata[SopaKeys.PATCHES].geometry[patch_index]\n\n        cells = self._run_patch(patch)\n        gdf = gpd.GeoDataFrame(geometry=cells)\n\n        patch_dir: Path = Path(patch_dir)\n        patch_dir.mkdir(parents=True, exist_ok=True)\n        patch_file = patch_dir / f\"{patch_index}.parquet\"\n\n        gdf.to_parquet(patch_file)\n\n    def write_patches_cells(self, patch_dir: str):\n        log.warn(\n            \"Running segmentation in a sequential manner. This is not recommended on large images because it can be extremely slow (see https://github.com/gustaveroussy/sopa/discussions/36 for more details)\"\n        )\n        for patch_index in tqdm(range(len(self.sdata[SopaKeys.PATCHES])), desc=\"Run all patches\"):\n            self.write_patch_cells(patch_dir, patch_index)\n\n    @classmethod\n    def read_patches_cells(cls, patch_dir: str | list[str]) -&gt; list[Polygon]:\n        \"\"\"Read all patch segmentation results after running `write_patch_cells` on all patches\n\n        Args:\n            patch_dir: Directory provided when running `write_patch_cells` containing the `.parquet` files. For multi-step segmentation, provide a list of directories (one per step).\n\n        Returns:\n            A list of cells represented as `shapely` polygons\n        \"\"\"\n        cells = []\n\n        files = [f for f in Path(patch_dir).iterdir() if f.suffix == \".parquet\"]\n        for file in tqdm(files, desc=\"Reading patches\"):\n            cells += list(gpd.read_parquet(file).geometry)\n\n        log.info(f\"Found {len(cells)} total cells\")\n        return cells\n\n    @classmethod\n    def add_shapes(cls, sdata: SpatialData, cells: list[Polygon], image_key: str, shapes_key: str):\n        \"\"\"Adding `shapely` polygon to the `SpatialData` object\n\n        Args:\n            sdata: A `SpatialData` object\n            cells: List of polygons after segmentation\n            image_key: Key of the image on which segmentation has been run\n            shapes_key: Name to provide to the geodataframe to be created\n        \"\"\"\n        image = get_spatial_image(sdata, image_key)\n\n        geo_df = gpd.GeoDataFrame({\"geometry\": cells})\n        geo_df.index = image_key + geo_df.index.astype(str)\n\n        geo_df = ShapesModel.parse(\n            geo_df, transformations=get_transformation(image, get_all=True).copy()\n        )\n        sdata.shapes[shapes_key] = geo_df\n\n        if sdata.is_backed():\n            sdata.write_element(shapes_key, overwrite=True)\n\n        log.info(f\"Added {len(geo_df)} cell boundaries in sdata['{shapes_key}']\")\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.__init__","title":"<code>__init__(sdata, method, channels, image_key=None, min_area=0, clip_limit=0.2, gaussian_sigma=1)</code>","text":"<p>Generalized staining-based segmentation</p> <p>Sequential segmentation (slower)</p> <pre><code>from sopa.segmentation.stainings import StainingSegmentation\n\nmethod = ... # custom callable that runs segmentation on each patch\n\nsegmentation = StainingSegmentation(sdata, method, \"DAPI\")\nsegmentation.write_patches_cells(\"./temp_dir\")\n\ncells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\nStainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n</code></pre> <p>Parallel segmentation (faster)</p> <pre><code>from sopa.segmentation.stainings import StainingSegmentation\n\nmethod = ... # custom callable that runs segmentation on each patch\n\nsegmentation = StainingSegmentation(sdata, method, \"DAPI\")\n\n# Run all this in a parallel manner, e.g. on different jobs\nfor i in range(len(sdata['sopa_patches'])):\n    segmentation.write_patch_cells(\"./temp_dir\", i)\n\ncells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\nStainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>method</code> <code>Callable</code> <p>A segmentation <code>callable</code> whose input is an image of shape <code>(C, Y, X)</code> and output is a cell mask of shape <code>(Y, X)</code>. Each mask value <code>&gt;0</code> represent a unique cell ID. Such callables can be found in <code>sopa.segmentation.methods</code>.</p> required <code>channels</code> <code>list[str] | str</code> <p>One or a list of channel names used for segmentation. If only one channel is provided, the image given to the <code>method</code> will be of shape <code>(1, Y, X)</code>.</p> required <code>image_key</code> <code>str | None</code> <p>Optional key of <code>sdata</code> containing the image (no needed if there is only one image)</p> <code>None</code> <code>min_area</code> <code>float</code> <p>Minimum area (in pixels^2) for a cell to be kept</p> <code>0</code> <code>clip_limit</code> <code>float</code> <p>Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)</p> <code>0.2</code> <code>gaussian_sigma</code> <code>float</code> <p>Parameter for scipy gaussian_filter (applied before running cellpose)</p> <code>1</code> Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>def __init__(\n    self,\n    sdata: SpatialData,\n    method: Callable,\n    channels: list[str] | str,\n    image_key: str | None = None,\n    min_area: float = 0,\n    clip_limit: float = 0.2,\n    gaussian_sigma: float = 1,\n):\n    \"\"\"Generalized staining-based segmentation\n\n    !!! note \"Sequential segmentation (slower)\"\n        ```python\n        from sopa.segmentation.stainings import StainingSegmentation\n\n        method = ... # custom callable that runs segmentation on each patch\n\n        segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n        segmentation.write_patches_cells(\"./temp_dir\")\n\n        cells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\n        StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n        ```\n\n    !!! note \"Parallel segmentation (faster)\"\n        ```python\n        from sopa.segmentation.stainings import StainingSegmentation\n\n        method = ... # custom callable that runs segmentation on each patch\n\n        segmentation = StainingSegmentation(sdata, method, \"DAPI\")\n\n        # Run all this in a parallel manner, e.g. on different jobs\n        for i in range(len(sdata['sopa_patches'])):\n            segmentation.write_patch_cells(\"./temp_dir\", i)\n\n        cells = StainingSegmentation.read_patches_cells(\"./temp_dir\")\n        StainingSegmentation.add_shapes(sdata, cells, image_key, \"method_name\")\n        ```\n\n    Args:\n        sdata: A `SpatialData` object\n        method: A segmentation `callable` whose input is an image of shape `(C, Y, X)` and output is a cell mask of shape `(Y, X)`. Each mask value `&gt;0` represent a unique cell ID. Such callables can be found in `sopa.segmentation.methods`.\n        channels: One or a list of channel names used for segmentation. If only one channel is provided, the image given to the `method` will be of shape `(1, Y, X)`.\n        image_key: Optional key of `sdata` containing the image (no needed if there is only one image)\n        min_area: Minimum area (in pixels^2) for a cell to be kept\n        clip_limit: Parameter for skimage.exposure.equalize_adapthist (applied before running cellpose)\n        gaussian_sigma: Parameter for scipy gaussian_filter (applied before running cellpose)\n    \"\"\"\n    self.sdata = sdata\n    self.method = method\n    self.channels = [channels] if isinstance(channels, str) else channels\n\n    self.min_area = min_area\n    self.clip_limit = clip_limit\n    self.gaussian_sigma = gaussian_sigma\n\n    self.image_key, self.image = get_spatial_image(sdata, key=image_key, return_key=True)\n\n    image_channels = self.image.coords[\"c\"].values\n    assert np.isin(\n        channels, image_channels\n    ).all(), f\"Channel names must be a subset of: {', '.join(image_channels)}\"\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.add_shapes","title":"<code>add_shapes(sdata, cells, image_key, shapes_key)</code>  <code>classmethod</code>","text":"<p>Adding <code>shapely</code> polygon to the <code>SpatialData</code> object</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>cells</code> <code>list[Polygon]</code> <p>List of polygons after segmentation</p> required <code>image_key</code> <code>str</code> <p>Key of the image on which segmentation has been run</p> required <code>shapes_key</code> <code>str</code> <p>Name to provide to the geodataframe to be created</p> required Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>@classmethod\ndef add_shapes(cls, sdata: SpatialData, cells: list[Polygon], image_key: str, shapes_key: str):\n    \"\"\"Adding `shapely` polygon to the `SpatialData` object\n\n    Args:\n        sdata: A `SpatialData` object\n        cells: List of polygons after segmentation\n        image_key: Key of the image on which segmentation has been run\n        shapes_key: Name to provide to the geodataframe to be created\n    \"\"\"\n    image = get_spatial_image(sdata, image_key)\n\n    geo_df = gpd.GeoDataFrame({\"geometry\": cells})\n    geo_df.index = image_key + geo_df.index.astype(str)\n\n    geo_df = ShapesModel.parse(\n        geo_df, transformations=get_transformation(image, get_all=True).copy()\n    )\n    sdata.shapes[shapes_key] = geo_df\n\n    if sdata.is_backed():\n        sdata.write_element(shapes_key, overwrite=True)\n\n    log.info(f\"Added {len(geo_df)} cell boundaries in sdata['{shapes_key}']\")\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.read_patches_cells","title":"<code>read_patches_cells(patch_dir)</code>  <code>classmethod</code>","text":"<p>Read all patch segmentation results after running <code>write_patch_cells</code> on all patches</p> <p>Parameters:</p> Name Type Description Default <code>patch_dir</code> <code>str | list[str]</code> <p>Directory provided when running <code>write_patch_cells</code> containing the <code>.parquet</code> files. For multi-step segmentation, provide a list of directories (one per step).</p> required <p>Returns:</p> Type Description <code>list[Polygon]</code> <p>A list of cells represented as <code>shapely</code> polygons</p> Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>@classmethod\ndef read_patches_cells(cls, patch_dir: str | list[str]) -&gt; list[Polygon]:\n    \"\"\"Read all patch segmentation results after running `write_patch_cells` on all patches\n\n    Args:\n        patch_dir: Directory provided when running `write_patch_cells` containing the `.parquet` files. For multi-step segmentation, provide a list of directories (one per step).\n\n    Returns:\n        A list of cells represented as `shapely` polygons\n    \"\"\"\n    cells = []\n\n    files = [f for f in Path(patch_dir).iterdir() if f.suffix == \".parquet\"]\n    for file in tqdm(files, desc=\"Reading patches\"):\n        cells += list(gpd.read_parquet(file).geometry)\n\n    log.info(f\"Found {len(cells)} total cells\")\n    return cells\n</code></pre>"},{"location":"api/segmentation/stainings/#sopa.segmentation.stainings.StainingSegmentation.write_patch_cells","title":"<code>write_patch_cells(patch_dir, patch_index)</code>","text":"<p>Run segmentation on one patch, and save the result in a dedicated directory</p> <p>Parameters:</p> Name Type Description Default <code>patch_dir</code> <code>str</code> <p>Directory inside which segmentation results will be saved</p> required <code>patch_index</code> <code>int</code> <p>Index of the patch on which to run segmentation. NB: the number of patches is <code>len(sdata['sopa_patches'])</code></p> required Source code in <code>sopa/segmentation/stainings.py</code> <pre><code>def write_patch_cells(self, patch_dir: str, patch_index: int):\n    \"\"\"Run segmentation on one patch, and save the result in a dedicated directory\n\n    Args:\n        patch_dir: Directory inside which segmentation results will be saved\n        patch_index: Index of the patch on which to run segmentation. NB: the number of patches is `len(sdata['sopa_patches'])`\n    \"\"\"\n    patch = self.sdata[SopaKeys.PATCHES].geometry[patch_index]\n\n    cells = self._run_patch(patch)\n    gdf = gpd.GeoDataFrame(geometry=cells)\n\n    patch_dir: Path = Path(patch_dir)\n    patch_dir.mkdir(parents=True, exist_ok=True)\n    patch_file = patch_dir / f\"{patch_index}.parquet\"\n\n    gdf.to_parquet(patch_file)\n</code></pre>"},{"location":"api/segmentation/tissue/","title":"sopa.segmentation.tissue","text":""},{"location":"api/segmentation/tissue/#sopa.segmentation.tissue.hsv_otsu","title":"<code>sopa.segmentation.tissue.hsv_otsu(sdata, image_key=None, level=-1, blur_k=5, open_k=5, close_k=5, drop_threshold=0.01)</code>","text":"<p>Perform WSI tissue segmentation. The resulting ROIs are saved as shapes.</p> <p>Info</p> <p>This segmentation method first transforms the image from RBG color space to HSV and then on the basis of the saturation channel, it performs the rest of the steps. As a preprocessing step, a median blurring is applied with an element of size <code>blur_k</code> before the otsu. Then a morphological opening and closing are applied as a prostprocessing step with square elements of size <code>open_k</code> and <code>close_k</code>. Lastly, the connected components with size less than <code>drop_threshold * number_of_pixel_of_the_image</code> are removed, and the rest are converted into polygons.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object representing an H&amp;E image</p> required <code>image_key</code> <code>str | None</code> <p>Optional key of the H&amp;E image</p> <code>None</code> <code>level</code> <code>int</code> <p>Level of the multiscale image on which the segmentation will be performed</p> <code>-1</code> <code>blur_k</code> <code>int</code> <p>The kernel size of the median bluring operation</p> <code>5</code> <code>open_k</code> <code>int</code> <p>The kernel size of the morphological openning operation</p> <code>5</code> <code>close_k</code> <code>int</code> <p>The kernel size of the morphological closing operation</p> <code>5</code> <code>drop_threshold</code> <code>int</code> <p>Segments that cover less area than <code>drop_threshold</code>*100% of the number of pixels of the image will be removed</p> <code>0.01</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if tissue segmentation was successful, else <code>False</code> if no polygon was output.</p> Source code in <code>sopa/segmentation/tissue.py</code> <pre><code>def hsv_otsu(\n    sdata: SpatialData,\n    image_key: str | None = None,\n    level: int = -1,\n    blur_k: int = 5,\n    open_k: int = 5,\n    close_k: int = 5,\n    drop_threshold: int = 0.01,\n) -&gt; bool:\n    \"\"\"Perform WSI tissue segmentation. The resulting ROIs are saved as shapes.\n\n    !!! info\n        This segmentation method first transforms the image from RBG color space to HSV and then\n        on the basis of the saturation channel, it performs the rest of the steps.\n        As a preprocessing step, a median blurring is applied with an element of size `blur_k`\n        before the otsu. Then a morphological opening and closing are applied as a prostprocessing\n        step with square elements of size `open_k` and `close_k`. Lastly, the connected components\n        with size less than `drop_threshold * number_of_pixel_of_the_image` are removed, and the\n        rest are converted into polygons.\n\n    Args:\n        sdata: A `SpatialData` object representing an H&amp;E image\n        image_key: Optional key of the H&amp;E image\n        level: Level of the multiscale image on which the segmentation will be performed\n        blur_k: The kernel size of the median bluring operation\n        open_k: The kernel size of the morphological openning operation\n        close_k: The kernel size of the morphological closing operation\n        drop_threshold: Segments that cover less area than `drop_threshold`*100% of the number of pixels of the image will be removed\n\n    Returns:\n        `True` if tissue segmentation was successful, else `False` if no polygon was output.\n    \"\"\"\n    import cv2\n\n    image_key, image = get_item(sdata, \"images\", image_key)\n\n    if level == 0 or not isinstance(image, DataTree):\n        log.warn(\"Running hsv_otsu on the full image can be slow. We recommend using a DataTree\")\n\n    if isinstance(image, DataTree):\n        level_keys = list(image.keys())\n        image: xr.DataArray = next(iter(image[level_keys[level]].values()))\n\n    thumbnail = np.array(image.transpose(\"y\", \"x\", \"c\"))\n    thumbnail_hsv = cv2.cvtColor(thumbnail, cv2.COLOR_RGB2HSV)\n    thumbnail_hsv_blurred = cv2.medianBlur(thumbnail_hsv[:, :, 1], blur_k)\n    _, mask = cv2.threshold(thumbnail_hsv_blurred, 0, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY)\n\n    mask_open = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((open_k, open_k), np.uint8))\n    mask_open_close = cv2.morphologyEx(\n        mask_open, cv2.MORPH_CLOSE, np.ones((close_k, close_k), np.uint8)\n    )\n\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_open_close, 4, cv2.CV_32S)\n\n    contours = []\n    for i in range(1, num_labels):\n        if stats[i, 4] &gt; drop_threshold * np.prod(mask_open_close.shape):\n            cc = cv2.findContours(\n                np.array(labels == i, dtype=\"uint8\"),\n                cv2.RETR_TREE,\n                cv2.CHAIN_APPROX_NONE,\n            )[0][0]\n            c_closed = np.array(list(cc) + [cc[0]])\n            contours.extend([c_closed.squeeze()])\n\n    polygons = [Polygon(contour) for contour in contours]\n\n    if not len(polygons):\n        log.warn(\n            \"No polygon has been found after tissue segmentation. Check that there is some tissue in the image, or consider updating the segmentation parameters.\"\n        )\n        return False\n\n    _save_tissue_segmentation(sdata, polygons, image_key, image)\n    return True\n</code></pre>"},{"location":"api/segmentation/transcripts/","title":"sopa.segmentation.transcripts","text":""},{"location":"api/segmentation/transcripts/#sopa.segmentation.transcripts.resolve","title":"<code>sopa.segmentation.transcripts.resolve(sdata, temp_dir, gene_column, patches_dirs=None, min_area=0, shapes_key=SopaKeys.BAYSOR_BOUNDARIES)</code>","text":"<p>Concatenate all the per-patch segmentation runs and resolve the conflicts. Resulting cells boundaries are saved in the <code>SpatialData</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>temp_dir</code> <code>str</code> <p>Temporary directory used to store all the patches subdirectories (one subdirectory for one patch and for one segmentation run)</p> required <code>gene_column</code> <code>str</code> <p>Column of the transcript dataframe containing the genes names</p> required <code>patches_dirs</code> <code>list[str] | None</code> <p>Optional list of subdirectories inside <code>temp_dir</code> to be read. By default, read all.</p> <code>None</code> <code>min_area</code> <code>float</code> <p>Minimum area (in microns^2) for a cell to be kept</p> <code>0</code> Source code in <code>sopa/segmentation/transcripts.py</code> <pre><code>def resolve(\n    sdata: SpatialData,\n    temp_dir: str,\n    gene_column: str,\n    patches_dirs: list[str] | None = None,\n    min_area: float = 0,\n    shapes_key: str = SopaKeys.BAYSOR_BOUNDARIES,\n):\n    \"\"\"Concatenate all the per-patch segmentation runs and resolve the conflicts. Resulting cells boundaries are saved in the `SpatialData` object.\n\n    Args:\n        sdata: A `SpatialData` object\n        temp_dir: Temporary directory used to store all the patches subdirectories (one subdirectory for one patch and for one segmentation run)\n        gene_column: Column of the transcript dataframe containing the genes names\n        patches_dirs: Optional list of subdirectories inside `temp_dir` to be read. By default, read all.\n        min_area: Minimum area (in microns^2) for a cell to be kept\n    \"\"\"\n    if min_area &gt; 0:\n        log.info(f\"Cells whose area is less than {min_area} microns^2 will be removed\")\n\n    patches_cells, adatas = _read_all_segmented_patches(temp_dir, min_area, patches_dirs)\n    geo_df, cells_indices, new_ids = _resolve_patches(patches_cells, adatas)\n\n    image_key = get_key(sdata, \"images\")\n    points = get_element(sdata, \"points\")\n    transformations = get_transformation(points, get_all=True).copy()\n\n    geo_df = ShapesModel.parse(geo_df, transformations=transformations)\n\n    table_conflicts = []\n    if len(new_ids):\n        new_cells = geo_df.geometry[cells_indices == -1]\n        geo_df_new = gpd.GeoDataFrame({\"geometry\": new_cells})\n        geo_df_new = ShapesModel.parse(geo_df_new, transformations=transformations)\n\n        log.info(\"Aggregating transcripts on merged cells\")\n        table_conflicts = aggregate.count_transcripts(sdata, gene_column, geo_df=geo_df_new)\n        table_conflicts.obs_names = new_ids\n        table_conflicts = [table_conflicts]\n\n    valid_ids = set(list(geo_df.index))\n    table = anndata.concat(\n        [adata[list(valid_ids &amp; set(list(adata.obs_names)))] for adata in adatas] + table_conflicts,\n        join=\"outer\",\n    )\n    table.obs.dropna(axis=\"columns\", inplace=True)\n\n    geo_df = geo_df.loc[table.obs_names]\n\n    table.obsm[\"spatial\"] = np.array([[centroid.x, centroid.y] for centroid in geo_df.centroid])\n    table.obs[SopaKeys.REGION_KEY] = pd.Series(shapes_key, index=table.obs_names, dtype=\"category\")\n    table.obs[SopaKeys.SLIDE_KEY] = pd.Series(image_key, index=table.obs_names, dtype=\"category\")\n    table.obs[SopaKeys.INSTANCE_KEY] = geo_df.index\n\n    table = TableModel.parse(\n        table,\n        region_key=SopaKeys.REGION_KEY,\n        region=shapes_key,\n        instance_key=SopaKeys.INSTANCE_KEY,\n    )\n\n    sdata.shapes[shapes_key] = geo_df\n    sdata.tables[SopaKeys.TABLE] = table\n\n    if sdata.is_backed():\n        sdata.write_element(shapes_key, overwrite=True)\n        sdata.write_element(SopaKeys.TABLE, overwrite=True)\n\n    log.info(\n        f\"Added sdata.tables['{SopaKeys.TABLE}'], and {len(geo_df)} cell boundaries to sdata['{shapes_key}']\"\n    )\n</code></pre>"},{"location":"api/utils/image/","title":"sopa.utils.image","text":""},{"location":"api/utils/image/#sopa.utils.image.scale_dtype","title":"<code>sopa.utils.image.scale_dtype(arr, dtype)</code>","text":"<p>Change the dtype of an array but keep the scale compared to the type maximum value.</p> <p>Example</p> <p>For an array of dtype <code>uint8</code> being transformed to <code>np.uint16</code>, the value <code>255</code> will become <code>65535</code></p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>A <code>numpy</code> array</p> required <code>dtype</code> <code>dtype</code> <p>Target <code>numpy</code> data type</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A scaled <code>numpy</code> array with the dtype provided.</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def scale_dtype(arr: np.ndarray, dtype: np.dtype) -&gt; np.ndarray:\n    \"\"\"Change the dtype of an array but keep the scale compared to the type maximum value.\n\n    !!! note \"Example\"\n        For an array of dtype `uint8` being transformed to `np.uint16`, the value `255` will become `65535`\n\n    Args:\n        arr: A `numpy` array\n        dtype: Target `numpy` data type\n\n    Returns:\n        A scaled `numpy` array with the dtype provided.\n    \"\"\"\n    _check_integer_dtype(arr.dtype)\n    _check_integer_dtype(dtype)\n\n    if arr.dtype == dtype:\n        return arr\n\n    factor = np.iinfo(dtype).max / np.iinfo(arr.dtype).max\n    return (arr * factor).astype(dtype)\n</code></pre>"},{"location":"api/utils/image/#sopa.utils.image.resize","title":"<code>sopa.utils.image.resize(xarr, scale_factor)</code>","text":"<p>Resize a xarray image</p> <p>Parameters:</p> Name Type Description Default <code>xarr</code> <code>DataArray</code> <p>A <code>xarray</code> array</p> required <code>scale_factor</code> <code>float</code> <p>Scale factor of resizing, e.g. <code>2</code> will decrease the width by 2</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Resized dask array</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def resize(xarr: xr.DataArray, scale_factor: float) -&gt; da.Array:\n    \"\"\"Resize a xarray image\n\n    Args:\n        xarr: A `xarray` array\n        scale_factor: Scale factor of resizing, e.g. `2` will decrease the width by 2\n\n    Returns:\n        Resized dask array\n    \"\"\"\n    resize_dims = [dim in [\"x\", \"y\"] for dim in xarr.dims]\n    transform = np.diag([scale_factor if resize_dim else 1 for resize_dim in resize_dims])\n    output_shape = [\n        size // scale_factor if resize_dim else size\n        for size, resize_dim in zip(xarr.shape, resize_dims)\n    ]\n\n    return dask_image.ndinterp.affine_transform(\n        xarr.data, matrix=transform, output_shape=output_shape\n    )\n</code></pre>"},{"location":"api/utils/image/#sopa.utils.image.resize_numpy","title":"<code>sopa.utils.image.resize_numpy(arr, scale_factor, dims, output_shape)</code>","text":"<p>Resize a numpy image</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>a <code>numpy</code> array</p> required <code>scale_factor</code> <code>float</code> <p>Scale factor of resizing, e.g. <code>2</code> will decrease the width by 2</p> required <code>dims</code> <code>list[str]</code> <p>List of dimension names. Only <code>\"x\"</code> and <code>\"y\"</code> are resized.</p> required <code>output_shape</code> <code>list[int]</code> <p>Size of the output array</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Resized array</p> Source code in <code>sopa/utils/image.py</code> <pre><code>def resize_numpy(\n    arr: np.ndarray, scale_factor: float, dims: list[str], output_shape: list[int]\n) -&gt; np.ndarray:\n    \"\"\"Resize a numpy image\n\n    Args:\n        arr: a `numpy` array\n        scale_factor: Scale factor of resizing, e.g. `2` will decrease the width by 2\n        dims: List of dimension names. Only `\"x\"` and `\"y\"` are resized.\n        output_shape: Size of the output array\n\n    Returns:\n        Resized array\n    \"\"\"\n    resize_dims = [dim in [\"x\", \"y\"] for dim in dims]\n    transform = np.diag([scale_factor if resize_dim else 1 for resize_dim in resize_dims])\n\n    return dask_image.ndinterp.affine_transform(\n        arr, matrix=transform, output_shape=output_shape\n    ).compute()\n</code></pre>"},{"location":"api/utils/polygon_crop/","title":"sopa.utils.polygon_crop","text":""},{"location":"api/utils/polygon_crop/#sopa.utils.polygon_crop.polygon_selection","title":"<code>sopa.utils.polygon_crop.polygon_selection(sdata, intermediate_image=None, intermediate_polygon=None, channels=None, scale_factor=10, margin_ratio=0.1)</code>","text":"<p>Crop an image based on a user-defined polygon (interactive mode).</p> <p>Parameters:</p> Name Type Description Default <code>sdata</code> <code>SpatialData</code> <p>A <code>SpatialData</code> object</p> required <code>intermediate_image</code> <code>str | None</code> <p>Path to the intermediate image, with a <code>.zip</code> extension. Use this only if the interactive mode is not available</p> <code>None</code> <code>intermediate_polygon</code> <code>str | None</code> <p>Path to the intermediate polygon, with a <code>.zip</code> extension. Use this locally, after downloading the <code>intermediate_image</code></p> <code>None</code> <code>channels</code> <code>list[str] | None</code> <p>List of channel names to be displayed. Optional if there are already only 1 or 3 channels.</p> <code>None</code> <code>scale_factor</code> <code>float</code> <p>Resize the image by this value (high value for a lower memory usage)</p> <code>10</code> <code>margin_ratio</code> <code>float</code> <p>Ratio of the image margin on the display (compared to the image size)</p> <code>0.1</code> Source code in <code>sopa/utils/polygon_crop.py</code> <pre><code>def polygon_selection(\n    sdata: SpatialData,\n    intermediate_image: str | None = None,\n    intermediate_polygon: str | None = None,\n    channels: list[str] | None = None,\n    scale_factor: float = 10,\n    margin_ratio: float = 0.1,\n):\n    \"\"\"Crop an image based on a user-defined polygon (interactive mode).\n\n    Args:\n        sdata: A `SpatialData` object\n        intermediate_image: Path to the intermediate image, with a `.zip` extension. Use this only if the interactive mode is not available\n        intermediate_polygon: Path to the intermediate polygon, with a `.zip` extension. Use this locally, after downloading the `intermediate_image`\n        channels: List of channel names to be displayed. Optional if there are already only 1 or 3 channels.\n        scale_factor: Resize the image by this value (high value for a lower memory usage)\n        margin_ratio: Ratio of the image margin on the display (compared to the image size)\n    \"\"\"\n    if intermediate_polygon is None:\n        image_key, image = _prepare(sdata, channels, scale_factor)\n\n        if intermediate_image is not None:\n            log.info(f\"Resized image will be saved to {intermediate_image}\")\n            with zarr.ZipStore(intermediate_image, mode=\"w\") as store:\n                g = zarr.group(store=store)\n                g.attrs.put({ROI.SCALE_FACTOR: scale_factor, ROI.IMAGE_KEY: image_key})\n                g.array(ROI.IMAGE_ARRAY_KEY, image, dtype=image.dtype, chunks=image.shape)\n            return\n\n        polygon = _draw_polygon(image, scale_factor, margin_ratio)\n    else:\n        log.info(f\"Reading polygon at path {intermediate_polygon}\")\n        z = zarr.open(intermediate_polygon, mode=\"r\")\n        polygon = Polygon(z[ROI.POLYGON_ARRAY_KEY][:])\n        image_key = z.attrs[ROI.IMAGE_KEY]\n\n        image = get_spatial_image(sdata, image_key)\n\n    geo_df = gpd.GeoDataFrame(geometry=[polygon])\n\n    geo_df = ShapesModel.parse(\n        geo_df, transformations=get_transformation(sdata[image_key], get_all=True).copy()\n    )\n    sdata.shapes[ROI.KEY] = geo_df\n    if sdata.is_backed():\n        sdata.write_element(ROI.KEY, overwrite=True)\n\n    log.info(f\"Polygon saved in sdata['{ROI.KEY}']\")\n</code></pre>"},{"location":"tutorials/advanced_segmentation/","title":"Advanced segmentation","text":"<p>The Sopa CLI and pipeline are based on Cellpose for staining-based segmentation. Yet, if desired, one can implement another staining-based segmentation algorithm or use a multi-step segmentation process on multiple channels.</p>"},{"location":"tutorials/advanced_segmentation/#multi-step-segmentation","title":"Multi-step segmentation","text":"<p>Multi-step segmentation consists of running multiple times Cellpose over the whole slides with different parameters. For instance, we can first run a nucleus segmentation using DAPI, then another round using DAPI and a membrane staining, and finally, DAPI and cell boundary staining. This can make the segmentation more robust. Note that the results of the multiple steps are combined into one final segmentation.</p> <p>Warning</p> <p>Here, we only detail the multi-step segmentation. For the rest of the CLI usage, refer to our CLI usage tutorial, and only replace the \"Run segmentation\" section with the instructions below.</p> <p>First, generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels, and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Now, we can run Cellpose on each of the four patches and for each \"segmentation step\" we want. In this toy example, we run 3 steps with (i) DAPI + CK, (ii) DAPI + CD3, and (iii) DAPI + CD20.</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. Mainly, this will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p> <p>To automatically get the number of patches, you can either open the <code>tuto.zarr/.sopa_cache/patches_file_image</code> file or compute <code>len(sdata['sopa_patches'])</code> in Python.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n\nsopa segmentation cellpose tuto.zarr \\\n    --channels DAPI --channels CD20 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20 \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n</code></pre> <p>Note</p> <p>In the above commands, the <code>--diameter</code> and <code>--min-area</code> parameters are specific to the data type we work on. For your own data, consider using the default parameters from one of our config files. Here, <code>min-area</code> is in pixels^2.</p> <p>At this stage, you executed 12 times Cellpose (3 steps on each of the 4 patches). Now, we need to resolve the conflict, i.e., merge the three segmentations into one. Note that we gave the paths to the temporary boundaries we made above. <pre><code>sopa resolve cellpose tuto.zarr \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CK \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD3 \\\n    --patch-dir tuto.zarr/.sopa_cache/cellpose_CD20\n</code></pre></p> <p>Congrats, you have now merged the results of a three-step segmentation! You can now refer to our normal CLI usage tutorial for all the other tasks.</p>"},{"location":"tutorials/advanced_segmentation/#custom-staining-based-segmentation","title":"Custom staining-based segmentation","text":"<p>You can plug your segmentation model into Sopa to benefit from all the other functionalities. In particular, it will scale the segmentation since Sopa will run on small patches.</p>"},{"location":"tutorials/advanced_segmentation/#1-define-your-segmentation-function","title":"1. Define your segmentation function","text":"<p>You need a Python function as described below:</p> <ul> <li> <p>The function input is an image of shape <code>(C, Y, X)</code> (<code>C</code> is the number of desired channels; it can be one if you want DAPI only)</p> </li> <li> <p>The function output is a mask of shape <code>(Y, X)</code>. This mask should contain positive values representing the segmented cells, and contain <code>0</code> outside of the cells. For instance, if 4 cells are segmented, the mask should contain the values 1, 2, 3, and eventually 0 (where there is no cell).</p> </li> </ul> <p>If you want to use our API, you can find a detailed example of custom segmentation here. Else, if you want to use the CLI, continue below.</p> <p>This function should be wrapped into a \"method builder\". The purpose is that you can provide arguments to the method builder that your desired function can then use. For instance, this is a dummy method builder whose segmentation function only creates one cell:</p> <pre><code>def dummy_method(**method_kwargs):\n    \"\"\"A method builder (i.e. it returns a segmentation function).\n    Kwargs can be provided and used in the below function\"\"\"\n\n    def segmentation_function(image: np.ndarray) -&gt; np.ndarray:\n        \"\"\"A dummy example of a custom segmentation method\n        that creates one cell (with a padding of 10 pixels).\n\n        Args:\n            image: An image of shape `(C, Y, X)`\n\n        Returns:\n            A mask of shape `(Y, X)` containing one cell\n        \"\"\"\n        mask = np.zeros(image.shape[1:], dtype=int)\n\n        # one cell, corresponding to value 1\n        mask[10:-10, 10:-10] = 1  # squared shaped\n\n        return mask\n\n    return segmentation_function\n</code></pre>"},{"location":"tutorials/advanced_segmentation/#2-setup","title":"2. Setup","text":"<p>To use the CLI, you'll need to clone the repository. Also, we recommend installing Sopa in dev mode, allowing you to update your segmentation function without re-installing everything. For instance:</p> <pre><code>git clone https://github.com/gustaveroussy/sopa.git\ncd sopa\n\n# create an empty conda env\nconda create --name sopa python=3.10\nconda activate sopa\n\n# install the extras you want\npip install -e \".[cellpose,baysor,tangram]\"\n</code></pre>"},{"location":"tutorials/advanced_segmentation/#3-run-your-custom-segmentation","title":"3. Run your custom segmentation","text":"<p>Warning</p> <p>Here, we only detail the multi-step segmentation. For the rest of the CLI usage, refer to our CLI usage tutorial, and only replace the \"Run segmentation\" section with the instructions below.</p> <p>Similarly to the tutorial for Cellpose, first start by generating patches:</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Then, call the CLI by providing the name of your method builder, i.e. replace <code>&lt;BUILDER_NAME&gt;</code> in the following commands:</p> <p>Note</p> <p>The process below is similar to the one of the Cellpose tutorial in the CLI usage tutorial.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 0\n</code></pre> <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 1\n</code></pre> <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 2\n</code></pre> <pre><code>sopa segmentation generic-staining tuto.zarr \\\n    --method-name &lt;BUILDER_NAME&gt; \\\n    --channels DAPI \\\n    --patch-index 3\n</code></pre> <p>And, to resolve the conflicts:</p> <pre><code>sopa resolve generic tuto.zarr --method-name &lt;BUILDER_NAME&gt;\n</code></pre> <p>Finally, aggregate the results:</p> <pre><code>sopa aggregate tuto.zarr --method-name &lt;BUILDER_NAME&gt; --gene-column genes --average-intensities\n</code></pre> <p>Congrats, you have now run your custom segmentation method! You can now refer to our normal CLI usage tutorial for all the other tasks.</p>"},{"location":"tutorials/align/","title":"Align images (e.g. H&E)","text":"<p>If you have an H&amp;E image or immunofluorescence data that you want to align on the main image, this can be done with the Xenium Explorer, even if you don't work on Xenium data.</p>"},{"location":"tutorials/align/#image-conversion","title":"Image conversion","text":"<p>Convert your image with QuPath as written in this 10x genomics webpage.</p> <p>If you are not familiar with QuPath, you can also use our API to write the image: <pre><code>import sopa.io\n\nimage = sopa.io.ome_tif(\"path/to/your/image.tif\") # or use a different reader\nsopa.io.write_image(\"where/to/save/image.ome.tif\", image, is_dir=False)\n</code></pre></p> <p>Xenium users</p> <p>If using the Xenium machine, then you don't need conversion; the images provided by the Xenium machine already have the correct format.</p>"},{"location":"tutorials/align/#open-your-data-in-the-xenium-explorer","title":"Open your data in the Xenium Explorer","text":"<p>If not done yet, convert your <code>SpatialData</code> object to the Xenium Explorer's inputs. This can be done as detailed in this tutorial.</p> <p>Double-click on the <code>experiment.xenium</code> file, or select it from the Xenium Explorer interface. It will display the data in the explorer.</p>"},{"location":"tutorials/align/#keypoint-placement","title":"Keypoint placement","text":"<p>Warning</p> <p>Make sure your Xenium Explorer version is at least <code>1.3.0</code></p> <p>On the Xenium Explorer, under the \"Images\" panel, click \"Add image\" and follow the instructions on the screen.</p> <p> </p> <p>Afterwards, the explorer will automatically align the images based on the key points you selected on both images.</p>"},{"location":"tutorials/align/#optional-update-the-spatialdata-object","title":"(Optional) Update the <code>SpatialData</code> object","text":"<p>After alignment, export the transformation matrix as a <code>.csv</code> file. For that, select your aligned image under the \"Images\" panel and click on \"Download Alignment File\":</p> <p> </p> <p>Then, select only the \"Transformation Matrix\" box and download it:</p> <p> </p> <p>Then, use the CLI to update your <code>SpatialData</code> object. You'll need the path to the <code>.zarr</code> directory corresponding to your <code>SpatialData</code> object (<code>SDATA_PATH</code>), the path to the <code>.ome.tif</code> image that you converted above (<code>IMAGE_PATH</code>), and the <code>.csv</code> transformation matrix that you exported from the Xenium Explorer (<code>TRANSFORMATION_MATRIX_PATH</code>):</p> <pre><code>sopa explorer add-aligned &lt;SDATA_PATH&gt; &lt;IMAGE_PATH&gt; &lt;TRANSFORMATION_MATRIX_PATH&gt;\n</code></pre>"},{"location":"tutorials/api_usage/","title":"API usage","text":"In\u00a0[1]: Copied! <pre>import spatialdata\nimport sopa.segmentation\nimport sopa.io\n</pre> import spatialdata import sopa.segmentation import sopa.io In\u00a0[2]: Copied! <pre># The line below creates a toy dataset for this tutorial\n# To load your own data, such as MERSCOPE data, you can do `sdata = sopa.io.merscope(\"/path/to/region_0\")`\n# For more details, see https://gustaveroussy.github.io/sopa/api/io/\nsdata = sopa.io.uniform()\n\nsdata\n</pre> # The line below creates a toy dataset for this tutorial # To load your own data, such as MERSCOPE data, you can do `sdata = sopa.io.merscope(\"/path/to/region_0\")` # For more details, see https://gustaveroussy.github.io/sopa/api/io/ sdata = sopa.io.uniform()  sdata <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 100 transcripts per cell\n</pre> Out[2]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 4) (3D points)\n\u2514\u2500\u2500 Shapes\n      \u2514\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), cells (Shapes)\n\u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Before starting, we create the variables below that denotes the names of the image and transcripts that we want to use, as displayed in the <code>SpatialData</code> object above:</p> In\u00a0[3]: Copied! <pre>image_key = \"image\"\npoints_key = \"transcripts\" # (ignore this for multiplex imaging)\ngene_column = \"genes\" # (optional) column of sdata[points_key] containing the gene names\n</pre> image_key = \"image\" points_key = \"transcripts\" # (ignore this for multiplex imaging) gene_column = \"genes\" # (optional) column of sdata[points_key] containing the gene names <p>First, we generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> In\u00a0[16]: Copied! <pre>patches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50)\npatches.write();\n</pre> patches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50) patches.write(); <pre>[INFO] (sopa.segmentation.patching) 4 patches were saved in sdata['sopa_patches']\n</pre> <p>The following channels are available for segmentation. Choose one or two channels used by Cellpose.</p> In\u00a0[17]: Copied! <pre>from sopa._sdata import get_spatial_image\n\nprint(get_spatial_image(sdata, image_key).c.values)\n</pre> from sopa._sdata import get_spatial_image  print(get_spatial_image(sdata, image_key).c.values) <pre>['DAPI' 'CK' 'CD3' 'CD20']\n</pre> <p>Then, we initialize the Cellpose model. Here, we run segmentation using DAPI only, and we set the cell diameter to be about <code>35</code> pixels:</p> In\u00a0[18]: Copied! <pre>channels = [\"DAPI\"]\n\nmethod = sopa.segmentation.methods.cellpose_patch(diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6)\nsegmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500)\n\n# The cellpose boundaries will be temporary saved here. You can choose a different path\ncellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\"\n</pre> channels = [\"DAPI\"]  method = sopa.segmentation.methods.cellpose_patch(diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6) segmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500)  # The cellpose boundaries will be temporary saved here. You can choose a different path cellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\" In\u00a0[\u00a0]: Copied! <pre>segmentation.write_patches_cells(cellpose_temp_dir)\n</pre> segmentation.write_patches_cells(cellpose_temp_dir) In\u00a0[7]: Copied! <pre># parallelize this for loop yourself (or use the Snakemake pipeline)\nfor patch_index in range(len(sdata['sopa_patches'])):\n    segmentation.write_patch_cells(cellpose_temp_dir, patch_index)\n</pre> # parallelize this for loop yourself (or use the Snakemake pipeline) for patch_index in range(len(sdata['sopa_patches'])):     segmentation.write_patch_cells(cellpose_temp_dir, patch_index) <pre>[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 0.71% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 0.00% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 1.00% (usually due to segmentation artefacts)\n[INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 1.37% (usually due to segmentation artefacts)\n</pre> <p>At this stage, you executed 4 times Cellpose (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches:</p> In\u00a0[20]: Copied! <pre>cells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir)\ncells = sopa.segmentation.shapes.solve_conflicts(cells)\n\nshapes_key = \"cellpose_boundaries\" # name of the key given to the cells in sdata.shapes\n\nsopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key)\n</pre> cells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir) cells = sopa.segmentation.shapes.solve_conflicts(cells)  shapes_key = \"cellpose_boundaries\" # name of the key given to the cells in sdata.shapes  sopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key) <pre>Reading patches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 434.64it/s]\n[INFO] (sopa.segmentation.stainings) Found 388 total cells\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 72/72 [00:00&lt;00:00, 7784.85it/s]\n[INFO] (sopa.segmentation.stainings) Added 367 cell boundaries in sdata['cellpose_boundaries']\n</pre> In\u00a0[4]: Copied! <pre>shapes_key = \"baysor_boundaries\" # the name that we will give to the baysor \"shapes\"\n</pre> shapes_key = \"baysor_boundaries\" # the name that we will give to the baysor \"shapes\" <p>Baysor needs a config to be executed. You can find official config examples here.</p> <p>You can also reuse the Baysor parameter we have defined for each machine, as in our Snakemake config files. Note that, our Snakemake config is a <code>.yaml</code> file, but the Baysor config should still be a <code>.toml</code> file.</p> <p>For this tutorial, we will use the config below. Instead of a dictionnary, you can also have a <code>.toml</code> file and provide <code>config_path</code> to the <code>patchify_transcripts</code> function.</p> In\u00a0[23]: Copied! <pre>config = {\n    \"data\": {\n        \"force_2d\": True,\n        \"min_molecules_per_cell\": 10,\n        \"x\": \"x\",\n        \"y\": \"y\",\n        \"z\": \"z\",\n        \"gene\": \"genes\",\n        \"min_molecules_per_gene\": 0,\n        \"min_molecules_per_segment\": 3,\n        \"confidence_nn_id\": 6\n    },\n    \"segmentation\": {\n        \"scale\": 3,  # Important parameter: typical cell diameter, in microns (see our configs)\n        \"scale_std\": \"25%\",\n        \"prior_segmentation_confidence\": 0,\n        \"estimate_scale_from_centers\": False,\n        \"n_clusters\": 4,\n        \"iters\": 500,\n        \"n_cells_init\": 0,\n        \"nuclei_genes\": \"\",\n        \"cyto_genes\": \"\",\n        \"new_component_weight\": 0.2,\n        \"new_component_fraction\": 0.3\n    }\n}\n</pre> config = {     \"data\": {         \"force_2d\": True,         \"min_molecules_per_cell\": 10,         \"x\": \"x\",         \"y\": \"y\",         \"z\": \"z\",         \"gene\": \"genes\",         \"min_molecules_per_gene\": 0,         \"min_molecules_per_segment\": 3,         \"confidence_nn_id\": 6     },     \"segmentation\": {         \"scale\": 3,  # Important parameter: typical cell diameter, in microns (see our configs)         \"scale_std\": \"25%\",         \"prior_segmentation_confidence\": 0,         \"estimate_scale_from_centers\": False,         \"n_clusters\": 4,         \"iters\": 500,         \"n_cells_init\": 0,         \"nuclei_genes\": \"\",         \"cyto_genes\": \"\",         \"new_component_weight\": 0.2,         \"new_component_fraction\": 0.3     } } <p>Then, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of 3000 microns and an overlap of 50 microns. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 1 patch.</p> In\u00a0[24]: Copied! <pre># The cellpose boundaries will be temporary saved here. You can choose a different path\nbaysor_temp_dir = \"tuto.zarr/.sopa_cache/baysor\"\n\npatches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=3000, patch_overlap=50)\nvalid_indices = patches.patchify_transcripts(baysor_temp_dir, config=config)\n</pre> # The cellpose boundaries will be temporary saved here. You can choose a different path baysor_temp_dir = \"tuto.zarr/.sopa_cache/baysor\"  patches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=3000, patch_overlap=50) valid_indices = patches.patchify_transcripts(baysor_temp_dir, config=config) <pre>[INFO] (sopa.patches.patches) Writing sub-CSV for transcript segmentation\n</pre> <pre>[########################################] | 100% Completed | 211.89 ms\n</pre> <pre>[INFO] (sopa.patches.patches) Patches saved in directory tuto.zarr/.sopa_cache/baysor\n</pre> <p>Now, we can run Baysor on each individual patch. It's up to you to choose the way to parallelize it: for instance, if you have a Slurm cluster, you can run one job per patch.</p> <p>Below, we run segmentation on each patch, and save the results in a temporary directory (here, <code>tuto.zarr/.sopa_cache/baysor</code>). On this example, we performed a \"for-loop\", so you should paralellize this yourself using multiple jobs or multi-threading (see this discussion for more details). Note that you can also use our Snakemake pipeline that will handle the parallelization for you.</p> <p>NB: depending on you Baysor installation, you may need to update the <code>baysor_executable_path</code> variable to locate the Baysor binary executable</p> In\u00a0[25]: Copied! <pre>import subprocess\n\nbaysor_executable_path = \"~/.julia/bin/baysor\"\n</pre> import subprocess  baysor_executable_path = \"~/.julia/bin/baysor\" In\u00a0[\u00a0]: Copied! <pre>for patch_index in valid_indices:\n    command = f\"\"\"\n    cd {baysor_temp_dir}/{patch_index}\n    {baysor_executable_path} run --save-polygons GeoJSON -c config.toml transcripts.csv\n    \"\"\"\n    subprocess.run(command, shell=True)\n</pre> for patch_index in valid_indices:     command = f\"\"\"     cd {baysor_temp_dir}/{patch_index}     {baysor_executable_path} run --save-polygons GeoJSON -c config.toml transcripts.csv     \"\"\"     subprocess.run(command, shell=True) <p>At this stage, you executed Baysor on each patch. Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches (although, for this tutorial, there is one patch so there is no conflict):</p> In\u00a0[27]: Copied! <pre>from sopa.segmentation.transcripts import resolve\n\nresolve(sdata, baysor_temp_dir, gene_column, min_area=10)\n</pre> from sopa.segmentation.transcripts import resolve  resolve(sdata, baysor_temp_dir, gene_column, min_area=10) <pre>[INFO] (sopa.segmentation.transcripts) Cells whose area is less than 10 microns^2 will be removed\nReading transcript-segmentation outputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 21.16it/s]\nResolving conflicts: 0it [00:00, ?it/s]\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:92: UserWarning: Key `baysor_boundaries` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:112: UserWarning: Key `table` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n[INFO] (sopa.segmentation.transcripts) Added sdata.tables['table'], and 373 cell boundaries to sdata['baysor_boundaries']\n</pre> In\u00a0[28]: Copied! <pre>aggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\n\naggregator.compute_table(gene_column=gene_column, average_intensities=True)\n</pre> aggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)  aggregator.compute_table(gene_column=gene_column, average_intensities=True) <pre>[INFO] (sopa.segmentation.aggregate) Using existing table for aggregation\n[WARNING] (sopa.segmentation.aggregate) sdata.table is already existing. Transcripts are not count again.\n[INFO] (sopa.segmentation.aggregate) Averaging channels intensity over 373 cells with expansion 0.0\n</pre> <pre>[########################################] | 100% Completed | 234.10 ms\n</pre> <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:92: UserWarning: Key `baysor_boundaries` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:112: UserWarning: Key `table` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> In\u00a0[29]: Copied! <pre>sdata\n</pre> sdata Out[29]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 4) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'baysor_boundaries': GeoDataFrame shape: (373, 1) (2D shapes)\n\u2502     \u2514\u2500\u2500 'cells': GeoDataFrame shape: (400, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (373, 5)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), baysor_boundaries (Shapes), cells (Shapes)\n\u25b8 'microns', with elements:\n        transcripts (Points), baysor_boundaries (Shapes)</pre> <p>Now, <code>sdata.tables[\"table\"]</code> is an <code>AnnData</code> object.</p> <ul> <li>If you count the transcripts, then <code>adata.X</code> are the raw counts</li> <li>If you average the channel intensities, then <code>adata.X</code> are the channels intensities</li> <li>If you both count the transcript and average the intensities, then <code>adata.X</code> are the raw counts, and <code>adata.obsm[\"intensities\"]</code> are the channels intensities</li> </ul> In\u00a0[6]: Copied! <pre>from sopa.annotation.tangram import tangram_annotate\nimport anndata\n</pre> from sopa.annotation.tangram import tangram_annotate import anndata In\u00a0[\u00a0]: Copied! <pre>adata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")\n\ntangram_annotate(sdata, adata_reference, \"cell_type\")\n</pre> adata_reference = anndata.read_h5ad(\"adata_reference.h5ad\")  tangram_annotate(sdata, adata_reference, \"cell_type\") In\u00a0[23]: Copied! <pre>from sopa.annotation import higher_z_score\n\nmarker_cell_dict = {\n    \"CK\": \"Tumoral cell\",\n    \"CD20\": \"B cell\",\n    \"CD3\": \"T cell\"\n}\n\nhigher_z_score(sdata.tables[\"table\"], marker_cell_dict)\n</pre> from sopa.annotation import higher_z_score  marker_cell_dict = {     \"CK\": \"Tumoral cell\",     \"CD20\": \"B cell\",     \"CD3\": \"T cell\" }  higher_z_score(sdata.tables[\"table\"], marker_cell_dict) <pre>[INFO] (sopa.annotation.fluorescence) Annotation counts: cell_type\nTumoral cell    128\nT cell          121\nB cell          118\nName: count, dtype: int64\n</pre> In\u00a0[24]: Copied! <pre>sopa.io.write_report(\"report.html\", sdata)\n</pre> sopa.io.write_report(\"report.html\", sdata) <pre>[INFO] (sopa.io.report.generate) Writing general_section\n[INFO] (sopa.io.report.generate) Writing cell_section\n[INFO] (sopa.io.report.generate) Writing channel_section\n[INFO] (sopa.io.report.generate) Writing transcripts_section\n[INFO] (sopa.io.report.generate) Writing representation_section\n[INFO] (sopa.io.report.generate) Computing UMAP on 367 cells\n/Users/quentinblampey/mambaforge/envs/sopa/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:394: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n[INFO] (sopa.io.report.generate) Writing report to report.html\n</pre> In\u00a0[25]: Copied! <pre>sopa.io.write(\"tuto.explorer\", sdata, image_key, points_key=points_key, gene_column=gene_column)\n</pre> sopa.io.write(\"tuto.explorer\", sdata, image_key, points_key=points_key, gene_column=gene_column) <pre>[INFO] (sopa.io.explorer.table) Writing table with 5 columns\n[INFO] (sopa.io.explorer.table) Writing 3 cell categories: region, slide, cell_type\n[INFO] (sopa.io.explorer.shapes) Writing 367 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 10000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre> <p>If you have downloaded the Xenium Explorer, you can now open the results in the explorer: <code>open tuto.explorer/experiment.xenium</code> (if using a Unix operating system), or double-click on the latter file.</p> In\u00a0[20]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[31]: Copied! <pre>sdata\\\n    .pl.render_points(size=0.01, color=\"r\", alpha=0.5)\\\n    .pl.render_images()\\\n    .pl.render_shapes(shapes_key, outline=True, fill_alpha=0, outline_color=\"w\")\\\n    .pl.show(\"global\")\n</pre> sdata\\     .pl.render_points(size=0.01, color=\"r\", alpha=0.5)\\     .pl.render_images()\\     .pl.render_shapes(shapes_key, outline=True, fill_alpha=0, outline_color=\"w\")\\     .pl.show(\"global\") <pre>INFO     Value for parameter 'color' appears to be a color, using it as such.                                      \n</pre> <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:102: UserWarning: Key `transcripts` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata_plot/pl/render.py:320: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = ax.scatter(\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> In\u00a0[\u00a0]: Copied! <pre>sdata.write(\"tuto.zarr\")\n</pre> sdata.write(\"tuto.zarr\") <p>You can then open the data with <code>spatialdata</code>:</p> In\u00a0[\u00a0]: Copied! <pre>import spatialdata\n\nspatialdata.read_zarr(\"tuto.zarr\")\n</pre> import spatialdata  spatialdata.read_zarr(\"tuto.zarr\")"},{"location":"tutorials/api_usage/#create-a-spatialdata-object","title":"Create a <code>SpatialData</code> object\u00b6","text":"<p>For this tutorial, we use a generated dataset. You can expect a total runtime of a few minutes.</p> <p>To load your own data, see the commented lines below, or read the <code>sopa.io</code> API.</p>"},{"location":"tutorials/api_usage/#segmentation","title":"Segmentation\u00b6","text":""},{"location":"tutorials/api_usage/#option-1-cellpose","title":"Option 1: Cellpose\u00b6","text":""},{"location":"tutorials/api_usage/#sequential-running","title":"Sequential running\u00b6","text":"<p>If desired, you can run Cellpose sequentially, as in the lines below, but this is slower than the \"Parallel running\" section below.</p>"},{"location":"tutorials/api_usage/#parallel-running","title":"Parallel running\u00b6","text":"<p>Here, we show how to run Cellpose in parallel for all the patches. It's up to you to choose the way to parallelize it: for instance, if you have a Slurm cluster, you can run one job per patch.</p> <p>Below, we run segmentation on each patch, and save the results in a temporary directory (here, <code>tuto.zarr/.sopa_cache</code>). On this example, we performed a \"for-loop\", so you should paralellize this yourself using multiple jobs or multi-threading (see this discussion for more details). Note that you can also use our Snakemake pipeline that will handle the parallelization for you.</p>"},{"location":"tutorials/api_usage/#resolving-conflicts","title":"Resolving conflicts\u00b6","text":""},{"location":"tutorials/api_usage/#option-2-baysor","title":"Option 2: Baysor\u00b6","text":""},{"location":"tutorials/api_usage/#aggregate","title":"Aggregate\u00b6","text":"<p>This mandatory step turns the data into an <code>AnnData</code> object. We can count the transcript inside each cell, and/or average each channel intensity inside each cell boundary.</p> <p>NB: Baysor already counts the transcripts inside each cell to create a cell-by-gene table, so you don't need to provide <code>gene_column</code></p>"},{"location":"tutorials/api_usage/#annotation","title":"Annotation\u00b6","text":""},{"location":"tutorials/api_usage/#option-1-transcript-based-tangram","title":"Option 1: Transcript-based (Tangram)\u00b6","text":"<p>Tangram is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference <code>AnnData</code> object is stored in a file called <code>adata_reference.h5ad</code> (preferably, keep raw counts), and the cell type is in <code>adata.obs[\"cell_type\"]</code>. Then, you can annotate your spatial data as follows:</p>"},{"location":"tutorials/api_usage/#option-2-staining-based","title":"Option 2: Staining-based\u00b6","text":"<p>For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells:</p>"},{"location":"tutorials/api_usage/#pipeline-report","title":"Pipeline report\u00b6","text":"<p>You can optionally create an HTML report of the pipeline run (in the example below, we save it under <code>report.html</code>). It contains some quality controls for your data.</p>"},{"location":"tutorials/api_usage/#visualization","title":"Visualization\u00b6","text":""},{"location":"tutorials/api_usage/#with-the-xenium-explorer","title":"With the Xenium Explorer\u00b6","text":"<p>The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely here. Sopa allows the conversion to the Xenium Explorer, whatever the type of spatial data you worked on. It will create some files under a new <code>tuto.explorer</code> directory:</p>"},{"location":"tutorials/api_usage/#with-spatialdata-plot","title":"With <code>spatialdata-plot</code>\u00b6","text":"<p><code>spatialdata-plot</code> library is a static plotting library for <code>SpatialData</code> objects</p>"},{"location":"tutorials/api_usage/#save-your-spatialdata-object","title":"Save your <code>SpatialData</code> object\u00b6","text":"<p>You can save your <code>SpatialData</code> object for later use. This will create a <code>.zarr</code> directory.</p>"},{"location":"tutorials/api_usage/#further-analyses","title":"Further analyses\u00b6","text":"<ul> <li>You can read this tutorial on spatial statistic and geometric analysis.</li> <li>You can use Squidpy which operates on both the <code>SpatialData</code> object or the <code>AnnData</code> object, or use other tools of the <code>scverse</code> ecosystem such as <code>Scanpy</code>.</li> <li>You can also try the CLI or the Snakemake pipeline of Sopa.</li> </ul>"},{"location":"tutorials/cli_usage/","title":"CLI usage","text":"<p>Here, we provide a minimal example of command line usage. For more details and to learn about other optional arguments, refer to the full CLI documentation.</p> <p>Tip</p> <p>The Snakemake pipeline is recommended to get started with Sopa. Using the CLI is advised if you want more flexibility, but you'll need to parallelize the segmentation yourself, as detailed below.</p>"},{"location":"tutorials/cli_usage/#save-the-spatialdata-object","title":"Save the <code>SpatialData</code> object","text":"<p>For this tutorial, we use a generated dataset. You can expect a total runtime of a few minutes.</p> <p>The command below will generate and save it on disk (you can change the path <code>tuto.zarr</code> to save it somewhere else). If you want to load your own data: choose the right panel below. For more information, refer to this FAQ describing which data input you need, or see the <code>sopa read</code> documentation.</p> TutorialXeniumMERSCOPECosMXPhenoCyclerMACSimaHyperion <pre><code># it will generate a 'tuto.zarr' directory\nsopa read . --sdata-path tuto.zarr --technology uniform\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology xenium\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology merscope\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology cosmx\n</code></pre> <pre><code># it will generate a '/path/to/sample.zarr' directory\nsopa read /path/to/sample.qptiff --technology phenocycler\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology macsima\n</code></pre> <pre><code># it will generate a '/path/to/sample/directory.zarr' directory\nsopa read /path/to/sample/directory --technology hyperion\n</code></pre> <p>Info</p> <p>It has created a <code>.zarr</code> directory which stores a <code>SpatialData</code> object corresponding to your data sample. You can choose the location of the <code>.zarr</code> directory using the <code>--sdata-path</code> command line argument.</p>"},{"location":"tutorials/cli_usage/#optional-roi-selection","title":"(Optional) ROI selection","text":"<p>Sometimes, your slide may contain a region with low-quality data, and we want to run the analysis only on the good-quality region. For this, we can interactively select a region of interest (ROI), and Sopa will only run on the selected ROI.</p> If working locallyIf working on a machine without interactive mode <p>Run the following command line and follow the instructions displayed in the console: <pre><code>sopa crop --sdata-path tuto.zarr --channels DAPI\n</code></pre></p> <p>When interactive mode is unavailable, the ROI selection will be performed in three steps.</p> <ol> <li> <p>On the machine where the data is stored, save a light view of the original image (here, it will create a file called <code>image.zarr.zip</code>): <pre><code>sopa crop --sdata-path tuto.zarr --channels DAPI --intermediate-image image.zarr.zip\n</code></pre></p> </li> <li> <p>Download the <code>image.zip</code> file locally (or on a machine with interactive mode), and select the ROI. Here, it will create a file called <code>roi.zarr.zip</code>: <pre><code>sopa crop --intermediate-image image.zarr.zip --intermediate-polygon roi.zarr.zip\n</code></pre></p> </li> <li> <p>Upload the <code>roi.zarr.zip</code> file, and save it inside the <code>SpatialData</code> object: <pre><code>sopa crop --sdata-path tuto.zarr --intermediate-polygon roi.zarr.zip\n</code></pre></p> </li> </ol>"},{"location":"tutorials/cli_usage/#run-segmentation","title":"Run segmentation","text":""},{"location":"tutorials/cli_usage/#option-1-cellpose","title":"Option 1: Cellpose","text":"<p>First, generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify image tuto.zarr --patch-width-pixel 1500 --patch-overlap-pixel 50\n</code></pre> <p>Now, we can run Cellpose on each individual patch. Execute the following command line on all <code>patch-index</code> (i.e., <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>) to run Cellpose using DAPI only (you can add an additional channel, for instance, <code>--channels DAPI --channels PolyT</code>):</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in our Snakefile. If you prefer using the already existing pipeline instead of the CLI, you can read our Snakemake pipeline tutorial.</p> <p>To automatically get the number of patches, you can either open the <code>tuto.zarr/.sopa_cache/patches_file_image</code> file, or compute <code>len(sdata['sopa_patches'])</code> in Python.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 0\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 1\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 2\n</code></pre> <pre><code>sopa segmentation cellpose tuto.zarr \\\n    --channels DAPI \\\n    --diameter 35 \\\n    --min-area 2000 \\\n    --patch-index 3\n</code></pre> <p>Note</p> <p>In the above commands, the <code>--diameter</code> and <code>--min-area</code> parameters are specific to the data type we work on. For your own data, consider using the default parameters from one of our config files. Here, <code>min-area</code> is in pixels^2.</p> <p>At this stage, you executed 4 times Cellpose (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches: <pre><code>sopa resolve cellpose tuto.zarr\n</code></pre></p>"},{"location":"tutorials/cli_usage/#option-2-baysor","title":"Option 2: Baysor","text":"<p>Baysor needs a config to be executed. You can find official config examples here.</p> <p>Note</p> <p>You can also reuse the Baysor parameter we have defined for each machine, as in our Snakemake config files. Note that, our Snakemake config is a <code>.yaml</code> file, but the Baysor config should still be a <code>.toml</code> file.</p> <p>For this tutorial, we will use the config below. Save this in a <code>config.toml</code> file. <pre><code>[data]\nforce_2d = true\nmin_molecules_per_cell = 10\nx = \"x\"\ny = \"y\"\nz = \"z\"\ngene = \"genes\"\nmin_molecules_per_gene = 0\nmin_molecules_per_segment = 3\nconfidence_nn_id = 6\n\n[segmentation]\nscale = 30                          # typical cell radius\nscale_std = \"25%\"                   # cell radius standard deviation\nprior_segmentation_confidence = 0\nestimate_scale_from_centers = false\nn_clusters = 4\niters = 500\nn_cells_init = 0\nnuclei_genes = \"\"\ncyto_genes = \"\"\nnew_component_weight = 0.2\nnew_component_fraction = 0.3\n</code></pre></p> <p>Then, we generate the bounding boxes of the patches on which Baysor will be run. Here, the patches have a width and height of 1200 microns and an overlap of 50 microns. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p> <pre><code># config.toml is the Baysor config file you generated above\nsopa patchify baysor tuto.zarr --config-path config.toml --patch-width-microns 1200 --patch-overlap-microns 50\n</code></pre> <p>Now, we can run Baysor on each individual patch. Execute the following command lines to run Baysor on each patch (i.e., <code>0</code>, <code>1</code>, <code>2</code>, and <code>3</code>).</p> <p>Tip</p> <p>Manually running the commands below can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p> <p>To automatically get the number of patches, you can open the <code>tuto.zarr/.sopa_cache/patches_file_baysor</code> file. This lists the names of the directories inside <code>tuto.zarr/.sopa_cache/baysor</code> related to each patch. If you selected an ROI, the excluded patches are effectively not in the <code>patches_file_baysor</code> file.</p> Patch 0Patch 1Patch 2Patch 3 <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/0\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/1\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/2\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <pre><code>cd tuto.zarr/.sopa_cache/baysor_boundaries/3\n\n# 'baysor' is the official baysor executable. If unavailable, replace it with your path to the executable\nbaysor run --save-polygons GeoJSON -c config.toml transcripts.csv\n</code></pre> <p>At this stage, you executed 4 times Baysor (once per patch). Now, we need to resolve the conflict, i.e. where boundaries are overlapping due to segmentation on multiple patches: <pre><code>sopa resolve baysor tuto.zarr --gene-column genes\n</code></pre></p>"},{"location":"tutorials/cli_usage/#aggregation","title":"Aggregation","text":"<p>This mandatory step turns the data into an <code>AnnData</code> object. We can count the transcript inside each cell, and/or average each channel intensity inside each cell boundary.</p> <p>Info</p> <p>The <code>--gene-column</code> option below tells which column contains the gene names inside the transcript dataframe. If you don't know it, you can look to our configs to find the right <code>gene-column</code> corresponding to your machine.</p> Count transcripts + average intensitiesCount transcriptsAverage intensities <pre><code>sopa aggregate tuto.zarr --gene-column genes --average-intensities --min-transcripts 10\n</code></pre> <pre><code>sopa aggregate tuto.zarr --gene-column genes --min-transcripts 10\n</code></pre> <pre><code>sopa aggregate tuto.zarr --average-intensities\n</code></pre> <p>If using Baysor</p> <p>Baysor already counts the transcripts inside each cell to create a cell-by-gene table. So you'll always have this table, and there is no need to use the <code>--gene-column</code> argument. If you don't want to average the intensities, you will still need to run <code>sopa aggregate tuto.zarr</code> before continuing.</p>"},{"location":"tutorials/cli_usage/#annotation","title":"Annotation","text":"<p>If desired, cell-type annotation can be run. Currently, we support Tangram for transcript-based annotation and a simple scoring approach for channel-based annotation (called channel z-score).</p> Channel Z-score annotationTangram annotation <p>For now, our fluorescence-based annotation is very simple. We provide a dictionary where a channel is associated with a population. Then, each cell is associated with the cell type whose corresponding channel is the brightest (according to a certain Z-score). In this tutorial example, we can annotate Tumoral cells, T cells, and B cells: <pre><code>sopa annotate fluorescence tuto.zarr --marker-cell-dict '{\"CK\": \"Tumoral cell\", \"CD3\": \"T cell\", \"CD20\": \"B cell\"}'\n</code></pre></p> <p>More complex annotation</p> <p>If you have a large number of channels, it may be preferable to run clustering on your data, for instance, using `Leiden clustering. Then, you can annotate each cluster manually by plotting a heatmap of all channels expressions per cluster.</p> <p>Tangram is a transcript-based annotation that uses an annotated single-cell reference. Let's suppose your reference <code>AnnData</code> object is stored in a file called <code>adata_reference.h5ad</code> (preferably, keep raw counts), and the cell type is in <code>adata.obs[\"cell_type\"]</code>. Then, you can annotate your spatial data as follows: <pre><code>sopa annotate tangram tuto.zarr --sc-reference-path adata_reference.h5ad --cell-type-key cell_type\n</code></pre></p>"},{"location":"tutorials/cli_usage/#pipeline-report","title":"Pipeline report","text":"<p>You can optionally create an HTML report of the pipeline run (in the example below, we save it under <code>report.html</code>). It contains some quality controls for your data.</p> <pre><code>sopa report tuto.zarr report.html\n</code></pre>"},{"location":"tutorials/cli_usage/#visualization-xenium-explorer","title":"Visualization (Xenium Explorer)","text":"<p>The Xenium Explorer is a software developed by 10X Genomics for visualizing spatial data, and it can be downloaded freely here. Sopa allows the conversion to the Xenium Explorer, whatever the type of spatial data you worked on. It will create some files under a new <code>tuto.explorer</code> directory:</p> <pre><code>sopa explorer write tuto.zarr --gene-column genes\n</code></pre> <p>If you have downloaded the Xenium Explorer, you can now open the results in the explorer: <code>open tuto.explorer/experiment.xenium</code> (if using a Unix operating system), or double-click on the latter file.</p> <p>Time efficiency</p> <p>Creating the image needed by the Xenium Explorer can be time-consuming. Therefore, we recommend performing one run for the image generation (below) and another to save the transcripts/boundaries/observations. <pre><code># this can be done directly after saving the raw data in a .zarr directory\nsopa explorer write tuto.zarr --mode \"+i\" --no-save-h5ad\n</code></pre></p> <p>After running everything with Sopa, you can finally save all the other Xenium Explorer input (e.g. boundaries and cell categories): <pre><code># this should be done after aggregation and an eventual annotation\nsopa explorer write tuto.zarr --mode \"-i\" --gene-column genes\n</code></pre> For more details and customization, refer to the command line helper.</p>"},{"location":"tutorials/cli_usage/#geometric-and-spatial-statistics","title":"Geometric and spatial statistics","text":"<p>All functions to compute geometric and spatial statistics are detailed in the <code>sopa.spatial</code> API. You can also read this tutorial.</p>"},{"location":"tutorials/cli_usage/#further-analyses","title":"Further analyses","text":"<ul> <li>If you are familiar with the <code>spatialdata</code> library, you can directly use the <code>tuto.zarr</code> directory, corresponding to a <code>SpatialData</code> object: <pre><code>import spatialdata\n\nsdata = spatialdata.read_zarr(\"tuto.zarr\")\n</code></pre></li> <li>You can use Squidpy which operates on both the <code>SpatialData</code> object or the <code>AnnData</code> object, or use other tools of the <code>scverse</code> ecosystem such as <code>Scanpy</code>.</li> <li>You can also use the file <code>tuto.explorer/adata.h5ad</code> if you prefer the <code>AnnData</code> object instead of the full <code>SpatialData</code> object.</li> </ul>"},{"location":"tutorials/comseg/","title":"ComSeg usage","text":"In\u00a0[1]: Copied! <pre>import sopa\nimport sopa.io\nimport sopa.segmentation\nfrom sopa.segmentation.transcripts import resolve\nfrom sopa.segmentation.methods import comseg_patch\n</pre> import sopa import sopa.io import sopa.segmentation from sopa.segmentation.transcripts import resolve from sopa.segmentation.methods import comseg_patch In\u00a0[2]: Copied! <pre>image_key = \"image\"\npoints_key = \"transcripts\"\ngene_column = \"genes\"\n\n### Load the data\nsdata = sopa.io.uniform()  # here, we use the toy dataset\n\npatches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50)\npatches.write()\n\nchannels = [\"DAPI\"]\nmethod = sopa.segmentation.methods.cellpose_patch(\n    diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6\n)\nsegmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500)\n\n# The cellpose boundaries will be temporary saved here. You can choose a different path\ncellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\"\nsegmentation.write_patches_cells(cellpose_temp_dir)\n\ncells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir)\ncells = sopa.segmentation.shapes.solve_conflicts(cells)\n\nshapes_key = \"cellpose_boundaries\"  # name of the key given to the cells in sdata.shapes\nsopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key)\n</pre> image_key = \"image\" points_key = \"transcripts\" gene_column = \"genes\"  ### Load the data sdata = sopa.io.uniform()  # here, we use the toy dataset  patches = sopa.segmentation.Patches2D(sdata, image_key, patch_width=1200, patch_overlap=50) patches.write()  channels = [\"DAPI\"] method = sopa.segmentation.methods.cellpose_patch(     diameter=35, channels=channels, flow_threshold=2, cellprob_threshold=-6 ) segmentation = sopa.segmentation.StainingSegmentation(sdata, method, channels, min_area=2500)  # The cellpose boundaries will be temporary saved here. You can choose a different path cellpose_temp_dir = \"tuto.zarr/.sopa_cache/cellpose\" segmentation.write_patches_cells(cellpose_temp_dir)  cells = sopa.segmentation.StainingSegmentation.read_patches_cells(cellpose_temp_dir) cells = sopa.segmentation.shapes.solve_conflicts(cells)  shapes_key = \"cellpose_boundaries\"  # name of the key given to the cells in sdata.shapes sopa.segmentation.StainingSegmentation.add_shapes(sdata, cells, image_key, shapes_key) <pre>[INFO] (sopa.utils.data) Image of size ((4, 2048, 2048)) with 400 cells and 100 transcripts per cell\n[INFO] (sopa.patches.patches) 4 patches were saved in sdata['sopa_patches']\n[WARNING] (sopa.segmentation.stainings) Running segmentation in a sequential manner. This is not recommended on large images because it can be extremely slow (see https://github.com/gustaveroussy/sopa/discussions/36 for more details)\nRun all patches:   0%|          | 0/4 [00:00&lt;?, ?it/s][INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 0.71% (usually due to segmentation artefacts)\nRun all patches:  25%|\u2588\u2588\u258c       | 1/4 [00:14&lt;00:42, 14.30s/it][INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 0.00% (usually due to segmentation artefacts)\nRun all patches:  50%|\u2588\u2588\u2588\u2588\u2588     | 2/4 [00:23&lt;00:22, 11.19s/it][INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 1.00% (usually due to segmentation artefacts)\nRun all patches:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 3/4 [00:32&lt;00:10, 10.13s/it][INFO] (sopa.segmentation.shapes) Percentage of non-geometrized cells: 1.37% (usually due to segmentation artefacts)\nRun all patches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:39&lt;00:00,  9.78s/it]\nReading patches: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 78.56it/s]\n[INFO] (sopa.segmentation.stainings) Found 388 total cells\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 68/68 [00:00&lt;00:00, 9159.63it/s]\n[INFO] (sopa.segmentation.stainings) Added 367 cell boundaries in sdata['cellpose_boundaries']\n</pre> In\u00a0[3]: Copied! <pre>temp_dir = \"tuto.zarr/.sopa_cache/comseg\"\n\npatches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=200, patch_overlap=50)\n\nvalid_indices = patches.patchify_transcripts(\n    temp_dir, use_prior=True, min_transcripts_per_patch=1000\n)\nvalid_indices_centroid = patches.patchify_centroids(temp_dir, min_cells_per_patch=1)\nvalid_indices = list(set(valid_indices_centroid).intersection(set(valid_indices)))\n</pre> temp_dir = \"tuto.zarr/.sopa_cache/comseg\"  patches = sopa.segmentation.Patches2D(sdata, points_key, patch_width=200, patch_overlap=50)  valid_indices = patches.patchify_transcripts(     temp_dir, use_prior=True, min_transcripts_per_patch=1000 ) valid_indices_centroid = patches.patchify_centroids(temp_dir, min_cells_per_patch=1) valid_indices = list(set(valid_indices_centroid).intersection(set(valid_indices))) <pre>[INFO] (sopa.patches.patches) Writing sub-CSV for transcript segmentation\n</pre> <pre>[########################################] | 100% Completed | 350.58 ms\n</pre> <pre>[INFO] (sopa.patches.patches) Patches saved in directory tuto.zarr/.sopa_cache/comseg\n[INFO] (sopa.patches.patches) Writing sub-CSV for transcript segmentation\n[INFO] (sopa.patches.patches) Patches saved in directory tuto.zarr/.sopa_cache/comseg\n</pre> In\u00a0[\u00a0]: Copied! <pre>config = {\n    \"dict_scale\": {\"x\": 1, \"y\": 1, \"z\": 1},  # spot coordinates already in \u00b5m\n    \"mean_cell_diameter\": 15,\n    \"max_cell_radius\": 25,\n    \"norm_vector\": False,\n    \"alpha\": 0.5,  # alpha value to compute the polygon https://pypi.org/project/alphashape/\n    \"allow_disconnected_polygon\": False,\n    \"min_rna_per_cell\": 5,  # minimal number of RNAs for a cell to be taken into account\n    \"gene_column\": \"genes\",\n}\n\nfor patch_index in valid_indices:\n    comseg_patch(temp_dir, patch_index, config)\n</pre> config = {     \"dict_scale\": {\"x\": 1, \"y\": 1, \"z\": 1},  # spot coordinates already in \u00b5m     \"mean_cell_diameter\": 15,     \"max_cell_radius\": 25,     \"norm_vector\": False,     \"alpha\": 0.5,  # alpha value to compute the polygon https://pypi.org/project/alphashape/     \"allow_disconnected_polygon\": False,     \"min_rna_per_cell\": 5,  # minimal number of RNAs for a cell to be taken into account     \"gene_column\": \"genes\", }  for patch_index in valid_indices:     comseg_patch(temp_dir, patch_index, config) In\u00a0[14]: Copied! <pre>shapes_key = \"comseg_boundaries\"\n\nresolve(sdata, temp_dir, gene_column, min_area=10, shapes_key=shapes_key)\n\naggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key)\naggregator.compute_table(gene_column=gene_column, average_intensities=True)\n</pre> shapes_key = \"comseg_boundaries\"  resolve(sdata, temp_dir, gene_column, min_area=10, shapes_key=shapes_key)  aggregator = sopa.segmentation.Aggregator(sdata, image_key=image_key, shapes_key=shapes_key) aggregator.compute_table(gene_column=gene_column, average_intensities=True) <pre>[INFO] (sopa.segmentation.transcripts) Cells whose area is less than 10 microns^2 will be removed\nReading transcript-segmentation outputs: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 21.80it/s]\nResolving conflicts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 534/534 [00:00&lt;00:00, 8223.37it/s]\n[INFO] (sopa.segmentation.transcripts) Aggregating transcripts on merged cells\n[INFO] (sopa.segmentation.aggregate) Aggregating transcripts over 155 cells\n</pre> <pre>[########################################] | 100% Completed | 397.50 ms\n</pre> <pre>[INFO] (sopa.segmentation.transcripts) Added sdata.tables['table'], and 367 cell boundaries to sdata['comseg_boundaries']\n[INFO] (sopa.segmentation.aggregate) Using existing table for aggregation\n[WARNING] (sopa.segmentation.aggregate) sdata.table is already existing. Transcripts are not count again.\n[INFO] (sopa.segmentation.aggregate) Averaging channels intensity over 367 cells with expansion 0.0\n</pre> <pre>[########################################] | 100% Completed | 101.41 ms\n</pre> <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:92: UserWarning: Key `comseg_boundaries` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:112: UserWarning: Key `table` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> In\u00a0[15]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[16]: Copied! <pre>sdata\\\n    .pl.render_points(size=0.01, color=\"r\")\\\n    .pl.render_images()\\\n    .pl.render_shapes(shapes_key, outline=True, fill_alpha=0, outline_color=\"w\")\\\n    .pl.show(\"global\")\n</pre> sdata\\     .pl.render_points(size=0.01, color=\"r\")\\     .pl.render_images()\\     .pl.render_shapes(shapes_key, outline=True, fill_alpha=0, outline_color=\"w\")\\     .pl.show(\"global\") <pre>INFO     Value for parameter 'color' appears to be a color, using it as such.                                      \n</pre> <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:102: UserWarning: Key `transcripts` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata_plot/pl/render.py:320: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  _cax = ax.scatter(\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> <p>You can also use the Xenium Explorer:</p> In\u00a0[12]: Copied! <pre>sopa.io.write(\"tuto.explorer\", sdata, image_key, points_key=\"transcripts\", gene_column=gene_column, shapes_key=\"comseg_boundaries\")\n</pre> sopa.io.write(\"tuto.explorer\", sdata, image_key, points_key=\"transcripts\", gene_column=gene_column, shapes_key=\"comseg_boundaries\") <pre>[INFO] (sopa.io.explorer.table) Writing table with 5 columns\n[INFO] (sopa.io.explorer.table) Writing 2 cell categories: region, slide\n[INFO] (sopa.io.explorer.shapes) Writing 367 cell polygons\n[INFO] (sopa.io.explorer.points) Writing 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 0: 40000 transcripts\n[INFO] (sopa.io.explorer.points)    &gt; Level 1: 10000 transcripts\n[INFO] (sopa.io.explorer.images) Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n[INFO] (sopa.io.explorer.images)    (Loading image of shape (4, 2048, 2048)) in memory\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 2048, 2048)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 1024, 1024)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 512, 512)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 256, 256)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 128, 128)\n[INFO] (sopa.io.explorer.images)    &gt; Image of shape (4, 64, 64)\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre>"},{"location":"tutorials/comseg/#comseg-usage","title":"ComSeg usage\u00b6","text":"<p>ComSeg  is a transcript-based segmentation method that creates a KNN graph of RNA molecules, weighted by the co-expression of RNA species. Initially, this KNN graph is partitioned into communities of RNAs likely to belong to the same cell. ComSeg then merges these RNA communities to compute the final cell segmentation. The method uses nucleus segmentation as prior to initialize the partitioning of the KNN graph of RNA molecules. ComSeg only segments cells with their nuclei segmented and does not take into account cells without missing nucleus.</p> <p>If nucleus segmentation is not available, ComSeg can operate using  other staining segmentation or solely nucleus centroids obtained from other sources. For more details, please refer to the ComSeg documentation.</p>"},{"location":"tutorials/comseg/#requirements","title":"Requirements\u00b6","text":"<p>To use ComSeg, run <code>pip install comseg</code> in the same environment as <code>sopa</code>. For more installation options, refer to their installation guide.</p> <p>Then, choose one the the three use cases (i.e., Snakemake or CLI or API) below.</p>"},{"location":"tutorials/comseg/#snakemake-usage","title":"Snakemake usage\u00b6","text":"<p>You can run ComSeg with snakemake in a similar way than the other methods. You can run the toy dataset as follow:</p> <pre>snakemake --config sdata_path=tuto.zarr --configfile=config/toy/uniform_comseg.yaml --cores 1 --use-conda\n</pre> <p>See here for MERSCOPE/Xenium/CosMX config files.</p>"},{"location":"tutorials/comseg/#cli-usage","title":"CLI usage\u00b6","text":"<p>First, follow the original CLI tutorial until you finished the \"Cellpose segmentation\" section, and then, continue below.</p>"},{"location":"tutorials/comseg/#1-save-a-comseg-config-file-as-a-configjson-file","title":"1. Save a ComSeg config file as a <code>config.json</code> file\u00b6","text":"<p>We display below a minimal example of a ComSeg <code>config.json</code> file</p> <pre>{\n    \"dict_scale\": {\n        \"x\": 1,\n        \"y\": 1,\n        \"z\": 1\n    },\n    \"mean_cell_diameter\": 15,\n    \"max_cell_radius\": 20,\n    \"allow_disconnected_polygon\" : true,\n    \"alpha\": 0.5,\n    \"min_rna_per_cell\": 5,\n    \"gene_column\": \"genes\",\n    \"norm_vector\": false\n}\n</pre> <p>If you did not install the needed external R packages, set <code>\"norm_vector\": false</code>. More information on the parameters can be found in the ComSeg documentation.</p>"},{"location":"tutorials/comseg/#2-create-the-comseg-patches","title":"2. Create the ComSeg patches\u00b6","text":"<p>On the toy dataset, this will generate 4 patches.</p> <pre><code>sopa patchify comseg tuto.zarr --config-path config.json --patch-width-microns 200 --patch-overlap-microns 50\n</code></pre> <p>The shapes-key argument is the name of the nuclei boundaries shape in the sdata object that will be used for the prior and centroid. In this example, it is set to <code>cellpose_boundaries</code>, which assumes that the Cellpose segmentation has already been run.</p>"},{"location":"tutorials/comseg/#3-run-comseg","title":"3. Run ComSeg\u00b6","text":"<ul> <li>On a specific patch (do that for all <code>&lt;PATCH_INDEX&gt;</code>, i.e. from 0 to 3 for this tutorial): <code>sopa segmentation comseg tuto.zarr --patch-index &lt;PATCH_INDEX&gt;</code></li> <li>Or sequentially on all the patches: <code>sopa segmentation comseg tuto.zarr</code></li> </ul> <p>!!! tip Manually running the commands above can involve using many consecutive commands, so we recommend automatizing it. For instance, this can be done using Snakemake or Nextflow. This will help you parallelize it since you can run each task on separate jobs or using multithreading. You can also see how we do it in the Sopa Snakemake pipeline.</p>"},{"location":"tutorials/comseg/#3-merge-the-results","title":"3. Merge the results\u00b6","text":"<p><code>sopa resolve comseg tuto.zarr --gene-column genes</code></p>"},{"location":"tutorials/comseg/#4-finish-with-the-standard-cli-commands","title":"4. Finish with the standard CLI commands\u00b6","text":"<p>You can finish as in the original CLI tutorial.</p> <p>E.g., you can run:</p> <p><code>sopa aggregate tuto.zarr --gene-column genes --average-intensities --min-transcripts 10</code></p> <p><code>sopa annotate fluorescence tuto.zarr --marker-cell-dict '{\"CK\": \"Tumoral cell\", \"CD3\": \"T cell\", \"CD20\": \"B cell\"}'</code></p> <p><code>sopa explorer write tuto.zarr --gene-column genes</code></p>"},{"location":"tutorials/comseg/#api-usage","title":"API usage\u00b6","text":"<p>In this tutorial, we first compute the nucleus segmentation prior using Cellpose on the DAPI staining</p>"},{"location":"tutorials/comseg/#1-running-cellpose-as-a-prior","title":"1. Running Cellpose as a prior\u00b6","text":"<p>First, we generate the bounding boxes of the patches on which Cellpose will be run. Here, the patches have a width and height of 1500 pixels and an overlap of 50 pixels. We advise bigger sizes for real datasets (see our default parameters in one of our config files). On the toy dataset, this will generate 4 patches.</p>"},{"location":"tutorials/comseg/#2-generating-patches-for-comseg","title":"2. Generating Patches for ComSeg\u00b6","text":"<p>Once the nuclei are segmented, we generate the bounding boxes of the patches on which ComSeg will be run. ComSeg also requires the nuclei centroids from the Cellpose segmentation, which are computed using the <code>patchify_centroids()</code>. In this example, the patches have a width and height of 200 microns with an overlap of 50 microns. For real datasets, we recommend using larger patch sizes, up to 8000 microns, depending on cell density. On the toy dataset, this configuration will generate 4 patches.</p> <p>Note that the patch_width parameter of <code>Patches2D()</code> is specified in microns, not pixels, as it refers to the coordinate system of the transcripts in sdata, which is in microns.</p>"},{"location":"tutorials/comseg/#3-running-comseg-on-each-patch","title":"3. Running ComSeg on each patch\u00b6","text":"<p>Parameters for ComSeg can be gathered into a single configuration dictionary. Below is a simple configuration example for using ComSeg. For a more comprehensive description of the configuration dictionary, please refer to the documentation</p> <p>Of note, ComSeg segments cells as a point cloud of RNA. To generate cell shapes from the segmented RNA point clouds, ComSeg leverages alpha shapes. An important parameter to set is <code>alpha</code>, which influences the shape of the generated cell polygons. More about <code>alpha</code> shapes can be found here</p>"},{"location":"tutorials/comseg/#4-resolve-segmentation-and-aggregate","title":"4. Resolve segmentation and aggregate\u00b6","text":"<p>Now, we need to resolve the conflict, i.e. where boundaries of segmented cells are overlapping due to segmentation on multiple patches. Then, in the aggregation step, transcripts inside each cell are counted and added in a <code>AnnData</code> object in <code>sdata.tables[\"table\"]</code></p>"},{"location":"tutorials/comseg/#5-check-the-segmentation","title":"5. Check the segmentation\u00b6","text":""},{"location":"tutorials/he/","title":"H&amp;E usage","text":"In\u00a0[1]: Copied! <pre>import sopa.io\n\nimport spatialdata_io\nimport spatialdata_plot\n\nfrom pathlib import Path\n</pre> import sopa.io  import spatialdata_io import spatialdata_plot  from pathlib import Path <p>For this tutorial, we will use this Xenium pancreatic cancer dataset. In particular, it has H&amp;E attached to the spatial transcriptomics. You can also use the H&amp;E alone by using the <code>sopa.io.wsi</code> reader.</p> <p>To keep it simple, we will assume the Sopa pipeline has already been run, and for the sake of this tutorial we will directly use the Xenium default segmentation. If you use your own data after running Sopa, simply read your data with the <code>spatialdata.read_zarr</code> function.</p> In\u00a0[\u00a0]: Copied! <pre># here, we will directly open the processed Xenium directory\ndirectory = Path(\"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs\")\nsdata = spatialdata_io.xenium(directory, morphology_focus=False)\n</pre> # here, we will directly open the processed Xenium directory directory = Path(\"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_outs\") sdata = spatialdata_io.xenium(directory, morphology_focus=False) <p>If you have already aligned the H&amp;E image as in this tutorial, you can now add it to your <code>SpatialData</code> object:</p> In\u00a0[\u00a0]: Copied! <pre># reading the H&amp;E image\nimage = sopa.io.wsi(directory / \"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_he_image.ome.tif\", as_image=True)\n\n# this is the path to the alignment file\ntransformation_matrix_path = directory / \"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_he_imagealignment.csv\"\n\nsopa.io.align(sdata, image, transformation_matrix_path)\n\n# this is the name of the HE image that has been added\nhe_image_key = 'Xenium_V1_hPancreas_Cancer_Add_on_FFPE_he_image.ome'\n</pre> # reading the H&amp;E image image = sopa.io.wsi(directory / \"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_he_image.ome.tif\", as_image=True)  # this is the path to the alignment file transformation_matrix_path = directory / \"Xenium_V1_hPancreas_Cancer_Add_on_FFPE_he_imagealignment.csv\"  sopa.io.align(sdata, image, transformation_matrix_path)  # this is the name of the HE image that has been added he_image_key = 'Xenium_V1_hPancreas_Cancer_Add_on_FFPE_he_image.ome' <p>Optionally, we can run tissue segmentation. This will create new polygons saved inside <code>sdata['region_of_interest']</code>:</p> In\u00a0[4]: Copied! <pre>from sopa.segmentation.tissue import hsv_otsu\n\nhsv_otsu(sdata, image_key=he_image_key)\n</pre> from sopa.segmentation.tissue import hsv_otsu  hsv_otsu(sdata, image_key=he_image_key) <pre>[INFO] (sopa.segmentation.tissue) Tissue segmentation saved in sdata['region_of_interest']\n</pre> Out[4]: <pre>True</pre> <p>The tissue segmentation can be shown as below:</p> In\u00a0[5]: Copied! <pre>sdata\\\n    .pl.render_shapes(\"region_of_interest\", outline=True, fill_alpha=0, outline_color=\"#333\")\\\n    .pl.render_images(he_image_key, scale=\"scale3\")\\\n    .pl.show(\"global\")\n</pre> sdata\\     .pl.render_shapes(\"region_of_interest\", outline=True, fill_alpha=0, outline_color=\"#333\")\\     .pl.render_images(he_image_key, scale=\"scale3\")\\     .pl.show(\"global\") <pre>/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</pre> In\u00a0[6]: Copied! <pre>from sopa.patches.infer import infer_wsi_patches\nfrom sopa.patches.cluster import cluster_embeddings\n</pre> from sopa.patches.infer import infer_wsi_patches from sopa.patches.cluster import cluster_embeddings In\u00a0[7]: Copied! <pre>embedding = infer_wsi_patches(\n    sdata, \"Resnet50Features\", patch_width=250, level=1, image_key=he_image_key\n)\n</pre> embedding = infer_wsi_patches(     sdata, \"Resnet50Features\", patch_width=250, level=1, image_key=he_image_key ) <pre>[INFO] (sopa.embedding.patches) Computing 4201 embeddings at level 1\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 132/132 [09:45&lt;00:00,  4.43s/it]\n[INFO] (sopa.embedding.patches) WSI embeddings saved as an image in sdata['sopa_Resnet50Features']\n[INFO] (sopa.segmentation.patching) 4201 patches were saved in sdata['sopa_embedding_patches']\n</pre> <p>Then, clustering can be run on the patches embeddings. This will generate a <code>GeoDataFrame</code> under <code>sdata[\"sopa_patches_inference\"]</code>, as below. Note the <code>\"cluster\"</code> column that has been added.</p> In\u00a0[8]: Copied! <pre>cluster_embeddings(sdata, 'sopa_Resnet50Features')\n\nsdata[\"sopa_patches_inference\"]\n</pre> cluster_embeddings(sdata, 'sopa_Resnet50Features')  sdata[\"sopa_patches_inference\"] <pre>/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> Out[8]: geometry bboxes ilocs cluster 0 POLYGON ((6500.000 1000.000, 6500.000 640.098,... [6000, 500, 6500, 1000] [12, 1] 7 1 POLYGON ((6500.000 1000.000, 6789.944 1000.000... [6500, 500, 7000, 1000] [13, 1] 7 2 POLYGON ((10500.000 1000.000, 10500.000 581.28... [10000, 500, 10500, 1000] [20, 1] 7 3 POLYGON ((10500.000 1000.000, 10993.471 1000.0... [10500, 500, 11000, 1000] [21, 1] 12 4 POLYGON ((14000.000 1000.000, 14000.000 832.12... [13500, 500, 14000, 1000] [27, 1] 8 ... ... ... ... ... 4196 POLYGON ((6000.000 67000.000, 5527.091 67000.0... [5500, 67000, 6000, 67500] [11, 134] 12 4197 POLYGON ((6500.000 67000.000, 6000.000 67000.0... [6000, 67000, 6500, 67500] [12, 134] 12 4198 POLYGON ((7000.000 67000.000, 6500.000 67000.0... [6500, 67000, 7000, 67500] [13, 134] 12 4199 POLYGON ((7000.000 67000.000, 7000.000 67256.4... [7000, 67000, 7500, 67500] [14, 134] 12 4200 POLYGON ((5542.523 67500.000, 5572.879 67530.3... [5500, 67500, 6000, 68000] [11, 135] 12 <p>4201 rows \u00d7 4 columns</p> <p>The patches clusters can be shown with <code>spatialdata_plot</code>:</p> In\u00a0[9]: Copied! <pre>sdata\\\n    .pl.render_shapes(\"region_of_interest\", outline=True, fill_alpha=0, outline_color=\"#333\")\\\n    .pl.render_shapes(\"sopa_patches_inference\", color=\"cluster\")\\\n    .pl.show(\"global\")\n</pre> sdata\\     .pl.render_shapes(\"region_of_interest\", outline=True, fill_alpha=0, outline_color=\"#333\")\\     .pl.render_shapes(\"sopa_patches_inference\", color=\"cluster\")\\     .pl.show(\"global\") <pre>/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n</pre> In\u00a0[10]: Copied! <pre>import sopa.spatial\n</pre> import sopa.spatial In\u00a0[11]: Copied! <pre>res_gdf = sopa.spatial.sjoin(sdata, \"cell_boundaries\", \"sopa_patches_inference\", target_coordinate_system=\"global\")\n</pre> res_gdf = sopa.spatial.sjoin(sdata, \"cell_boundaries\", \"sopa_patches_inference\", target_coordinate_system=\"global\") <p>The resulting <code>GeoDataFrame</code> may have more columns than cells, because one cell may be inside multiple patches. We will keep only the first patch, and then save the resulting <code>\"cluster\"</code> column into the <code>sdata.tables[\"table\"]</code>.</p> In\u00a0[12]: Copied! <pre>sdata.tables[\"table\"].obs[\"cluster\"] = res_gdf[~res_gdf.index.duplicated()][\"cluster\"].values\n</pre> sdata.tables[\"table\"].obs[\"cluster\"] = res_gdf[~res_gdf.index.duplicated()][\"cluster\"].values <p>Now, we can plot the cells and their associated H&amp;E cluster:</p> In\u00a0[13]: Copied! <pre>sdata.pl.render_shapes(\"cell_boundaries\", color=\"cluster\").pl.show(\"global\")\n</pre> sdata.pl.render_shapes(\"cell_boundaries\", color=\"cluster\").pl.show(\"global\") <pre>/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning: Transforming to str index.\n  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n/Users/quentinblampey/Library/Caches/pypoetry/virtualenvs/sopa-hDHgkEug-py3.10/lib/python3.10/site-packages/spatialdata/_utils.py:212: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n  obs[column] = c\n</pre>"},{"location":"tutorials/he/#he-usage","title":"H&amp;E usage\u00b6","text":"<p>The purpose of this notebook is to showcase how to perform basic analyses of H&amp;E data and eventually combine it other modalities (transcriptomics or multiplex imaging).</p> <p>You will need the <code>wsi</code> extra of sopa for this tutorial, i.e. <code>pip install sopa[wsi]</code></p>"},{"location":"tutorials/he/#tissue-segmentation","title":"Tissue segmentation\u00b6","text":""},{"location":"tutorials/he/#patches-embeddings-and-clusters","title":"Patches embeddings and clusters\u00b6","text":"<p>It is common to embed H&amp;E patches using a computer vision model. Here, we use a ResNet model to embedding patches. On the following example, we compute embeddings for patches of width <code>250</code> pixels at the level 1 (i.e., the first sub-resolution image).</p> <p>You can adjust the level to get different resolutions. For instance, <code>level=0, patch_width=100</code> would produce a resolution of about one cell per patch.</p>"},{"location":"tutorials/he/#spatial-join","title":"Spatial join\u00b6","text":"<p>You may be interested in joining the H&amp;E patches and the cells. This way, you could know inside witch patch-cluster belongs each cell. This can be done with <code>sopa.spatial.sjoin</code>.</p>"},{"location":"tutorials/snakemake/","title":"Snakemake pipeline","text":"<p>Sopa comes with an existing Snakemake pipeline to get started quickly. This will not involve any coding but requires some setup specific to <code>snakemake</code>.</p>"},{"location":"tutorials/snakemake/#install-sopa","title":"Install <code>sopa</code>","text":"<p>Follow the \"Snakemake setup\" instructions of our installation page.</p> <p>Baysor usage</p> <p>Even though <code>pip install -e '.[baysor]'</code> will install some dependencies related to baysor, you still have to install the <code>baysor</code> command line (see the official repository) if you want to use it.</p> <p>If your path to the baysor executable is not the default one (i.e. <code>~/.julia/bin/baysor</code>), you can do one of the following:</p> <ul> <li>set a <code>BAYSOR_EXECUTABLE_PATH</code> environment variable with the path to your Baysor executable.</li> <li>update the config described below to provide the right path to your Baysor executable.</li> </ul>"},{"location":"tutorials/snakemake/#choose-a-config","title":"Choose a config","text":"<p>Our pipeline config is a YAML file that describes all the steps desired for the pipeline. It is flexible; for instance, if you remove the <code>baysor</code> arguments from the config, then it will not run baysor. Similarly, if you remove the <code>\"annotation\"</code> section, it will not run annotation.</p> <p>You can choose a config among the existing ones here or create your own.</p> <p>Note the relative path of your config since you'll need it later, e.g. <code>config/merscope/base.yaml</code>.</p>"},{"location":"tutorials/snakemake/#run-the-pipeline","title":"Run the pipeline","text":"<ol> <li> <p>First, locate the path to one sample's raw experiment file(s). This is usually a directory containing one or many image(s) and, eventually, a transcript file. If you don't know what data you need, see our FAQ.</p> </li> <li> <p>Then, activate your environment that has the snakemake command, and go to the <code>workflow</code> directory inside the <code>sopa</code> directory that you cloned earlier: <pre><code>conda activate sopa    # or an environment that has `snakemake`\ncd workflow            # run this at the root of the 'sopa' directory\n</code></pre></p> </li> <li> <p>You can either execute the pipeline locally or on a high-performance-cluster (choose the right option below)</p> </li> </ol> Local execution (e.g., personal laptop)High-performance-cluster (e.g., Slurm cluster) <p>You can execute the pipeline locally as below (in this example, we use only one core):</p> <pre><code># replace the configfile with yours\n# replace data_path with the path to your data directory\n\nsnakemake --config data_path=/path/to/directory --configfile=config/merscope/base.yaml --cores 1 --use-conda\n</code></pre> <p>Faster pipeline</p> <p>Even though Sopa can be run locally, we recommend to use it on high-performance-clusters to benefit from all the pipeline capabilities (see the second tab just above).</p> <p>To benefit from high-performance-cluster, you'll need a Snakemake cluster profile. By default, we use this <code>slurm</code> profile, but you can also update it or create your own profile under <code>sopa/workflow/&lt;hpc-name&gt;/config.yaml</code>.</p> <pre><code># replace the configfile with yours\n# replace data_path with the path to your data directory\n# replace profile with &lt;hpc-name&gt; as above, or keep 'slurm'\n\nsnakemake --profile slurm --config data_path=/path/to/directory --configfile=config/merscope/base.yaml\n</code></pre> <p>Note</p> <p>You may need to update the <code>partition</code> parameters inside the <code>sopa/workflow/Snakefile</code> file, according to the partition names of your cluster. You can also change <code>mem_mb</code>, depending on the RAM capabilities of your cluster.</p> <p>For more customization, see the snakemake CLI documentation.</p>"},{"location":"tutorials/snakemake/#toy-example","title":"Toy example","text":"<p>In the example below, we run the pipeline on a generated toy dataset. Running it locally can help test a new pipeline or config.</p> <p>Make sure you have installed everything as detailed in this tutorial, and then run the following command lines:</p> Cellpose usageBaysor usage <p>Make sure you have installed sopa with the Cellpose extra <pre><code>conda activate sopa    # or an environment that has `snakemake`\ncd workflow            # run this at the root of the 'sopa' directory\n\n# you can replace tuto.zarr by another path where the data will be saved\nsnakemake --config sdata_path=tuto.zarr --configfile=config/toy/uniform_cellpose.yaml --cores 1 --use-conda\n</code></pre></p> <p>Make sure you have installed sopa with the Baysor extra, and that you have installed the <code>baysor</code> command <pre><code>conda activate sopa    # or an environment that has `snakemake`\ncd workflow            # run this at the root of the 'sopa' directory\n\n# replace tuto.zarr by the path where you want the data to be saved\nsnakemake --config sdata_path=tuto.zarr --configfile=config/toy/uniform_baysor.yaml --cores 1 --use-conda\n</code></pre></p> <p>Notes</p> <p>On the above example, it executes snakemake sequentially (one core), which is enough for debugging purposes.</p> <p>You can then check <code>tuto.explorer</code> for output files. Notably, if you have installed the Xenium Explorer, double-click on <code>experiment.xenium</code> to visualize the results.</p>"},{"location":"tutorials/snakemake/#pipeline-outputs","title":"Pipeline outputs","text":"<p>The pipeline outputs consists in two directories located next to your raw data directory. They have the same name as your raw directory, but with extension <code>.zarr</code> and <code>.explorer</code> respectively (see below for more details).</p> <p>Info</p> <p>You can also change the path to the <code>.zarr</code> output, by providing <code>sdata_path=/your/path.zarr</code> just after <code>--config</code> on the snakemake execution line. This will also move the <code>.explorer</code> directory, that will be saved at <code>/your/path.explorer</code></p>"},{"location":"tutorials/snakemake/#spatialdata-directory","title":"<code>SpatialData</code> directory","text":"<p>If you are familiar with the <code>spatialdata</code> library, you can use the <code>.zarr</code> directory, corresponding to a <code>SpatialData</code> object: <pre><code>import spatialdata\n\nsdata = spatialdata.read_zarr(\"/path/to/data.zarr\")\n</code></pre></p>"},{"location":"tutorials/snakemake/#explorer-directory","title":"Explorer directory","text":"<p>The <code>.explorer</code> directory contains the following files:</p> <ul> <li> <p><code>report.html</code> a short quality control of you data, as an HTML report</p> </li> <li> <p><code>adata.h5ad</code> the AnnData object with spatial locations of the cells (see <code>adata.obsm['spatial']</code>), and also cell-by-gene table and/or the cell-by-channel table.</p> </li> <li> <p><code>experiment.xenium</code> the Xenium Explorer file: double-click on it to open it on the Xenium Explorer (download the software here)</p> </li> <li> <p>The other files are data files related and required by the Xenium Explorer</p> </li> </ul>"},{"location":"tutorials/snakemake/#create-your-own-config","title":"Create your own config","text":"<p>If the existing <code>config</code> files are not suited for your project, you can update an existing one or create a whole new one. For this, use this commented config to understand the purpose of each argument. Note that some sections are optional: in this case, remove the section or the argument, and Sopa will not run it.</p> <p>When running snakemake, you will then need to provide the relative or absolute path to your <code>.yaml</code> config, for instance <code>--configfile=/path/to/your/config.yaml</code>.</p>"},{"location":"tutorials/spatial/","title":"Spatial statistics","text":"In\u00a0[1]: Copied! <pre>import anndata\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport sopa\nimport sopa.spatial\n\nheatmap_kwargs = {\"vmax\": 40, \"cmap\": sns.cm.rocket_r, \"cbar_kws\": {'label': 'Mean hop distance'}}\n</pre> import anndata import seaborn as sns import matplotlib.pyplot as plt  import sopa import sopa.spatial  heatmap_kwargs = {\"vmax\": 40, \"cmap\": sns.cm.rocket_r, \"cbar_kws\": {'label': 'Mean hop distance'}} In\u00a0[2]: Copied! <pre>adata = anndata.read_h5ad(\"adata_liver_merscope.h5ad\")\n</pre> adata = anndata.read_h5ad(\"adata_liver_merscope.h5ad\") <p>Then, compute the Delaunay graph on your data. Especially, use the <code>radius</code> argument to drop long edges. In this examples, edges longer than 50 microns are removed.</p> <p>The later function comes from Squidpy.</p> In\u00a0[3]: Copied! <pre>sopa.spatial.spatial_neighbors(adata, radius=[0, 50])\n</pre> sopa.spatial.spatial_neighbors(adata, radius=[0, 50]) <pre>[INFO] (sopa.spatial._build) Computing delaunay graph\n</pre> In\u00a0[4]: Copied! <pre>cell_type_to_cell_type = sopa.spatial.mean_distance(adata, \"cell_type\", \"cell_type\")\n</pre> cell_type_to_cell_type = sopa.spatial.mean_distance(adata, \"cell_type\", \"cell_type\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:08&lt;00:00,  3.37it/s]\n</pre> In\u00a0[5]: Copied! <pre>plt.figure(figsize=(7, 6))\nsns.heatmap(cell_type_to_cell_type, **heatmap_kwargs)\n</pre> plt.figure(figsize=(7, 6)) sns.heatmap(cell_type_to_cell_type, **heatmap_kwargs) Out[5]: <pre>&lt;Axes: xlabel='cell_type', ylabel='cell_type'&gt;</pre> <p>Similary, you can compute the mean hop-distance between all pairs of cell-types and niches:</p> In\u00a0[6]: Copied! <pre>cell_type_to_niche = sopa.spatial.mean_distance(adata, \"cell_type\", \"niches\")\n</pre> cell_type_to_niche = sopa.spatial.mean_distance(adata, \"cell_type\", \"niches\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.28it/s]\n</pre> In\u00a0[7]: Copied! <pre>plt.figure(figsize=(3, 6))\nsns.heatmap(cell_type_to_niche, **heatmap_kwargs)\n</pre> plt.figure(figsize=(3, 6)) sns.heatmap(cell_type_to_niche, **heatmap_kwargs) Out[7]: <pre>&lt;Axes: xlabel='niches', ylabel='cell_type'&gt;</pre> <p>Same between niches and niches:</p> In\u00a0[8]: Copied! <pre>niche_to_niche = sopa.spatial.mean_distance(adata, \"niches\")\n</pre> niche_to_niche = sopa.spatial.mean_distance(adata, \"niches\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.25it/s]\n</pre> In\u00a0[9]: Copied! <pre>plt.figure(figsize=(3, 3))\nsns.heatmap(niche_to_niche, **heatmap_kwargs)\n</pre> plt.figure(figsize=(3, 3)) sns.heatmap(niche_to_niche, **heatmap_kwargs) Out[9]: <pre>&lt;Axes: xlabel='niches', ylabel='niches'&gt;</pre> In\u00a0[10]: Copied! <pre>gdf = sopa.spatial.geometrize_niches(adata, \"niches\")\ngdf\n</pre> gdf = sopa.spatial.geometrize_niches(adata, \"niches\") gdf Out[10]: geometry niches length area roundness 0 POLYGON ((11256.961 7834.639, 11257.304 7835.6... Bile duct 371.136469 6941.104125 0.633244 3 POLYGON ((11122.354 8163.108, 11123.162 8163.7... Bile duct 393.638585 5539.287922 0.449230 6 POLYGON ((10936.163 381.622, 10936.478 381.898... Bile duct 1595.710237 24099.793633 0.118936 8 POLYGON ((11021.489 747.492, 11019.723 748.834... Bile duct 561.516074 5763.341860 0.229699 17 POLYGON ((11042.181 3981.166, 11043.124 3980.8... Bile duct 584.173216 6296.007422 0.231842 ... ... ... ... ... ... 2292 POLYGON ((2805.196 4508.688, 2805.687 4509.714... Vascular 589.849425 13760.673500 0.497012 2370 POLYGON ((459.355 560.935, 460.631 562.344, 46... Vascular 727.372986 7949.503667 0.188815 2378 POLYGON ((192.733 4605.956, 193.558 4606.628, ... Vascular 601.631439 8236.973094 0.285967 2388 POLYGON ((78.743 2939.361, 79.118 2940.362, 80... Vascular 390.753989 8232.263635 0.677520 2390 POLYGON ((10.051 4012.561, 10.497 4013.717, 18... Vascular 395.425837 9050.534716 0.727368 <p>118 rows \u00d7 5 columns</p> <p>Now, each occurence (or connected component) of each niche category is a Polygon. On this example, the Necrosis niche has 3 components, as shown below.</p> In\u00a0[11]: Copied! <pre>legend_kwds = {\"bbox_to_anchor\": (1.04, 0.5), \"loc\": \"center left\", \"borderaxespad\": 0, \"frameon\": False, \"title\": \"Niches\"}\n\ngdf.plot(column=\"niches\", legend=True, legend_kwds=legend_kwds)\n</pre> legend_kwds = {\"bbox_to_anchor\": (1.04, 0.5), \"loc\": \"center left\", \"borderaxespad\": 0, \"frameon\": False, \"title\": \"Niches\"}  gdf.plot(column=\"niches\", legend=True, legend_kwds=legend_kwds) Out[11]: <pre>&lt;Axes: &gt;</pre> In\u00a0[12]: Copied! <pre>df_niches_geometries = sopa.spatial.niches_geometry_stats(adata, \"niches\")\ndf_niches_geometries\n</pre> df_niches_geometries = sopa.spatial.niches_geometry_stats(adata, \"niches\") df_niches_geometries <pre>[INFO] (sopa.spatial.morpho) Computing pairwise distances between 118 components\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/geopandas/geoseries.py:660: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n  result = super().apply(func, args=args, **kwargs)\n</pre> Out[12]: n_components length area roundness min_distance_to_niche_Bile duct min_distance_to_niche_Lymphoid structure min_distance_to_niche_Necrosis min_distance_to_niche_Stroma min_distance_to_niche_Stromal border min_distance_to_niche_Tumour min_distance_to_niche_Tumour-myeloid min_distance_to_niche_Vascular niches Bile duct 53 871.163413 1.968860e+04 0.337805 0.000000 2380.538268 1449.461569 73.698113 606.466864 503.188672 1458.109531 554.878833 Lymphoid structure 2 1036.895946 6.074089e+04 0.655267 99.283752 0.000000 1293.705232 0.000000 484.004416 288.855609 778.042413 727.563948 Necrosis 3 14679.900601 1.859571e+06 0.144873 215.188214 2613.268586 0.000000 0.000000 530.994922 24.705659 0.000000 206.323638 Stroma 1 159551.459121 2.385822e+07 0.011777 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 Stromal border 10 32107.645354 1.562288e+06 0.023618 1282.747393 4533.620464 1263.667065 356.928689 0.000000 0.000000 624.666420 365.469128 Tumour 8 22964.491358 6.363175e+06 0.178266 258.930767 2124.252221 433.590282 2.529358 40.851952 0.000000 257.084459 121.688532 Tumour-myeloid 13 5625.146904 2.741475e+05 0.116237 531.479998 3349.152789 603.320975 0.000000 332.532881 79.196333 0.000000 694.707711 Vascular 28 808.856057 2.111648e+04 0.403680 1065.886005 3766.261346 1702.920627 401.167661 477.280906 283.654705 1370.371248 0.000000 In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(1, 4, figsize=(15, 6))\n\nfor i, name in enumerate([\"n_components\", \"length\", \"area\", \"roundness\"]):\n    vmax = df_niches_geometries[name].sort_values()[-2:].mean()\n    sns.heatmap(df_niches_geometries[[name]], cmap=\"viridis\", annot=True, fmt=\".2f\", vmax=vmax, ax=axes[i])\n\nplt.subplots_adjust(wspace=1.5)\n</pre> fig, axes = plt.subplots(1, 4, figsize=(15, 6))  for i, name in enumerate([\"n_components\", \"length\", \"area\", \"roundness\"]):     vmax = df_niches_geometries[name].sort_values()[-2:].mean()     sns.heatmap(df_niches_geometries[[name]], cmap=\"viridis\", annot=True, fmt=\".2f\", vmax=vmax, ax=axes[i])  plt.subplots_adjust(wspace=1.5) In\u00a0[14]: Copied! <pre>import networkx as nx\nfrom community import community_louvain\nfrom netgraph import Graph\n</pre> import networkx as nx from community import community_louvain from netgraph import Graph In\u00a0[15]: Copied! <pre>weights, node_color, node_size, node_shape = sopa.spatial.prepare_network(adata, \"cell_type\", \"niches\")\n</pre> weights, node_color, node_size, node_shape = sopa.spatial.prepare_network(adata, \"cell_type\", \"niches\") <pre>[INFO] (sopa.spatial.distance) Computing all distances for the 4 pairs of categories\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:07&lt;00:00,  3.61it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.69it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 28/28 [00:07&lt;00:00,  3.52it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:02&lt;00:00,  3.48it/s]\n</pre> In\u00a0[16]: Copied! <pre>g = nx.from_pandas_adjacency(weights)\nnode_to_community = community_louvain.best_partition(g, resolution=1.35)\n</pre> g = nx.from_pandas_adjacency(weights) node_to_community = community_louvain.best_partition(g, resolution=1.35) In\u00a0[17]: Copied! <pre>Graph(g,\n      node_size=node_size,\n      node_color=node_color,\n      node_shape=node_shape,\n      node_edge_width=0,\n      node_layout='community',\n      node_layout_kwargs=dict(node_to_community=node_to_community),\n      node_labels=True,\n      node_label_fontdict=dict(size=6, weight=\"bold\"),\n      edge_alpha=1,\n      edge_width=0.5,\n      edge_layout_kwargs=dict(k=2000),\n      edge_layout='bundled',\n)\n</pre> Graph(g,       node_size=node_size,       node_color=node_color,       node_shape=node_shape,       node_edge_width=0,       node_layout='community',       node_layout_kwargs=dict(node_to_community=node_to_community),       node_labels=True,       node_label_fontdict=dict(size=6, weight=\"bold\"),       edge_alpha=1,       edge_width=0.5,       edge_layout_kwargs=dict(k=2000),       edge_layout='bundled', ) <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/netgraph/_edge_layout.py:978: RuntimeWarning: invalid value encountered in divide\n  displacement = compatibility * delta / distance_squared[..., None]\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/netgraph/_utils.py:360: RuntimeWarning: invalid value encountered in divide\n  v = v / np.linalg.norm(v, axis=-1)[:, None] # unit vector\n</pre> Out[17]: <pre>&lt;netgraph._main.Graph at 0x2b1668fd0&gt;</pre>"},{"location":"tutorials/spatial/#1-prepare-your-data","title":"1. Prepare your data\u00b6","text":"<p>You'll need the <code>AnnData</code> output of Sopa. If using the <code>SpatialData</code> object itself, simply extract the table.</p> <p>Make sure you have at least a cell-type annotation (i.e. a column in <code>adata.obs</code> corresponding to cell-types), and eventually a niche annotation (with algorithms such as STAGATE).</p>"},{"location":"tutorials/spatial/#optional-download-the-tutorial-data","title":"(Optional) Download the tutorial data\u00b6","text":"<p>The <code>.h5ad</code> file used in this tutorial is publicly available on Zenodo here.</p>"},{"location":"tutorials/spatial/#2-distances-between-cell-categories","title":"2. Distances between cell categories\u00b6","text":"<p>You can compute the mean hop-distance between all pairs of cell-types:</p> <p>Below, <code>'cell_type'</code> is the name of the column of <code>adata.obs</code> containing the cell-type annotation</p>"},{"location":"tutorials/spatial/#3-transform-niches-into-shapes","title":"3. Transform niches into shapes\u00b6","text":"<p>If desired, niches can be transformed into Shapely geometries. Each occurence of a specific niche will correspond to one Polygon. This makes efficient further operations on niches, such as the one in the next section.</p>"},{"location":"tutorials/spatial/#4-niches-geometries","title":"4. Niches geometries\u00b6","text":"<p>For each niche, we can compute geometric properties. Here, we computed some simple properties of each niche: their mean length (or perimeter), their mean area, and their mean roundness (score between 0 and 1, where high values means \"circle\"-like shape).</p> <p>NB: Since one niche can be divided into multiple connected components (or multiple occurences), we indeed need to average the above geometric properties over all connected components of one niche category</p>"},{"location":"tutorials/spatial/#5-cell-type-niche-network","title":"5. Cell-type / Niche network\u00b6","text":"<p>The distances between cell-types and/or niches can be summerized into one network, and plot with the Netgraph library. It provides a quick overview of the interactions happening in the micro-environment of one slide.</p> <p>To continue, you'll need to install Louvain and Netgraph:</p> <pre>!pip install python-louvain\n!pip install netgraph\n</pre>"},{"location":"tutorials/xenium_explorer/explorer/","title":"Explorer usage","text":"<p>This tutorial shows interoperability tools between Sopa and the Xenium Explorer. We show how to go back and forth, between analysis and visualization.</p> <p>Ensure that you have already run Sopa, either with the Snakemake pipeline, CLI, or API.</p> <p>For image alignment with the Xenium Explorer, refer to this tutorial.</p> In\u00a0[1]: Copied! <pre>import sopa\nimport sopa.io\nimport sopa.segmentation\nimport spatialdata\n</pre> import sopa import sopa.io import sopa.segmentation import spatialdata <p>For this tutorial, we use some generated data that looks similar to the output of Sopa.</p> In\u00a0[\u00a0]: Copied! <pre>### if you have your own data:\n# sdata = spatialdata.read_zarr(\"...\")\n\n### to use the tutorial data\nsdata = sopa.io.uniform(as_output=True)\n</pre> ### if you have your own data: # sdata = spatialdata.read_zarr(\"...\")  ### to use the tutorial data sdata = sopa.io.uniform(as_output=True) In\u00a0[23]: Copied! <pre>explorer_path = \"tuto.explorer\" # where the Xenium Explorer data was or will be saved\n</pre> explorer_path = \"tuto.explorer\" # where the Xenium Explorer data was or will be saved <p>Now, we need to create the Xenium Explorer input files. If you have already run Sopa on your own data, you don't need to run the lines below because you already have the Xenium Explorer input.</p> In\u00a0[\u00a0]: Copied! <pre>### if you don't have the `.explorer` directory yet\nsopa.io.write(explorer_path, sdata, gene_column=\"genes\")\n</pre> ### if you don't have the `.explorer` directory yet sopa.io.write(explorer_path, sdata, gene_column=\"genes\") In\u00a0[3]: Copied! <pre>import scanpy as sc\n\nadata = sdata.tables[\"table\"]\n</pre> import scanpy as sc  adata = sdata.tables[\"table\"] In\u00a0[4]: Copied! <pre>sc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.tl.leiden(adata, resolution=0.1)\n</pre> sc.pp.normalize_total(adata) sc.pp.log1p(adata) sc.pp.pca(adata) sc.pp.neighbors(adata) sc.tl.umap(adata) sc.tl.leiden(adata, resolution=0.1) <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[5]: Copied! <pre>sc.pl.umap(adata, color=\"leiden\")\n</pre> sc.pl.umap(adata, color=\"leiden\") <p>Now, you can update the explorer with your new cluster assignment. You don't need to re-run the complete conversion; you can edit the <code>analysis.zarr.zip</code> file only, as below.</p> <p>Alternatively, you can use the <code>sopa</code> CLI instead of the API, as detailed here.</p> In\u00a0[8]: Copied! <pre>sopa.io.write_cell_categories(explorer_path, adata)\n</pre> sopa.io.write_cell_categories(explorer_path, adata) <pre>[INFO] (sopa.io.explorer.table) Writing 3 cell categories: region, slide, leiden\n</pre> <p>To visualize these clusters, re-open the <code>experiment.xenium</code> file and select the new <code>\"leiden\"</code> cell group (under the \"Cells\" panel and in the \"Cell groups\" dropdown). See the examples above to see how it looks on the Xenium Explorer.</p> In\u00a0[15]: Copied! <pre>import pandas as pd\n\n# write below the path to the file that you downloaded, e.g. \"Selection_1_cells_stats.csv\"\ndf_selection = pd.read_csv(\"Selection_1_cells_stats.csv\", skiprows=2)\n\n# we create a new column to annotate which cells were selected or not\nadata.obs[\"lasso\"] = \"not-selected\"\nadata.obs.loc[df_selection[\"Cell ID\"].values, \"lasso\"] = \"selected\"\n</pre> import pandas as pd  # write below the path to the file that you downloaded, e.g. \"Selection_1_cells_stats.csv\" df_selection = pd.read_csv(\"Selection_1_cells_stats.csv\", skiprows=2)  # we create a new column to annotate which cells were selected or not adata.obs[\"lasso\"] = \"not-selected\" adata.obs.loc[df_selection[\"Cell ID\"].values, \"lasso\"] = \"selected\" <p>Now, <code>sdata.table.obs[\"lasso\"]</code> denotes which cells have been selected by the lasso tool (either \"selected\" or \"not-selected\").</p> <p>We can then use <code>spatialdata_plot</code> to display the cells that were selected by the lasso tool. Make sure to install <code>spatialdata_plot &gt;= 0.1.0</code>, e.g. via <code>pip install spatialdata_plot</code>. Now, we can render the shapes (i.e., the spots) and colour them based on the <code>\"lasso\"</code> column that was saved in <code>sdata.table.obs</code>:</p> In\u00a0[16]: Copied! <pre>import spatialdata_plot\n</pre> import spatialdata_plot In\u00a0[17]: Copied! <pre>sdata.pl.render_shapes(color=\"lasso\").pl.show(\"global\")\n</pre> sdata.pl.render_shapes(color=\"lasso\").pl.show(\"global\") <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata_plot/pl/basic.py:813: UserWarning: Converting copy of 'lasso' column to categorical dtype for categorical plotting. Consider converting before plotting.\n  _render_shapes(\n</pre> <p>Then, we read the polygon coordinates, and perform a polygon query on the <code>\"global\"</code> coordinate system (i.e., the pixel coordinate system).</p> <p>Note: if not using Xenium data, please provide the <code>pixel_size</code> argument in the <code>sopa.io.add_explorer_selection</code> function below (the <code>pixel_size</code> should be the one that has been used when running Sopa). If you used the snakemake pipeline, this argument can be found in the config. Without this, the polygon may not be in the right coordinate system.</p> In\u00a0[19]: Copied! <pre>import spatialdata_io\n\npolygon = spatialdata_io.xenium_explorer_selection(\"Selection_1_coordinates.csv\")\n</pre> import spatialdata_io  polygon = spatialdata_io.xenium_explorer_selection(\"Selection_1_coordinates.csv\") In\u00a0[20]: Copied! <pre>query_sdata = sdata.query.polygon(polygon, target_coordinate_system=\"global\")\nquery_sdata\n</pre> query_sdata = sdata.query.polygon(polygon, target_coordinate_system=\"global\") query_sdata Out[20]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 1044, 837)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 4) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u2514\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (47, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (47, 5)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), cellpose_boundaries (Shapes)\n\u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Using <code>spatialdata_plot</code>, we see that we indeed selected the cells we desired.</p> In\u00a0[21]: Copied! <pre>query_sdata.pl.render_shapes().pl.show(\"global\")\n</pre> query_sdata.pl.render_shapes().pl.show(\"global\") In\u00a0[20]: Copied! <pre>new_shapes_key = \"large_cells\"\n\nsopa.io.add_explorer_selection(sdata, \"coordinates.csv\", shapes_key=new_shapes_key)\n</pre> new_shapes_key = \"large_cells\"  sopa.io.add_explorer_selection(sdata, \"coordinates.csv\", shapes_key=new_shapes_key) <p>New shapes have been added to the <code>sdata</code> object:</p> In\u00a0[19]: Copied! <pre>sdata\n</pre> sdata Out[19]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 4) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (400, 1) (2D shapes)\n\u2502     \u2514\u2500\u2500 'large_cells': GeoDataFrame shape: (4, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u2514\u2500\u2500 'table': AnnData (400, 5)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), cellpose_boundaries (Shapes), large_cells (Shapes)\n\u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Now, we will update the segmentation. In particular, it will perform aggregation (i.e., counting the transcripts and/or averaging the channels inside the new cells), and it will remove cells that are behind the selected cells:</p> In\u00a0[22]: Copied! <pre>sopa.segmentation.overlay_segmentation(sdata, new_shapes_key, gene_column=\"genes\")\n</pre> sopa.segmentation.overlay_segmentation(sdata, new_shapes_key, gene_column=\"genes\") <pre>[INFO] (sopa.segmentation.aggregate) Aggregating transcripts over 4 cells\n</pre> <pre>[########################################] | 100% Completed | 106.88 ms\n</pre> <pre>[INFO] (sopa.segmentation.aggregate) Averaging channels intensity over 4 cells with expansion 0.0\n</pre> <pre>[########################################] | 100% Completed | 104.65 ms\n</pre> <pre>/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:92: UserWarning: Key `large_cells` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/anndata/_core/anndata.py:1818: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n/Users/quentinblampey/mambaforge/envs/spatial/lib/python3.10/site-packages/spatialdata/_core/_elements.py:112: UserWarning: Key `table` already exists. Overwriting it.\n  self._check_key(key, self.keys(), self._shared_keys)\n</pre> <p>Now, we have a new table (the old table is also kept), and we have new shapes called <code>'cellpose_boundaries+large_cells'</code>.</p> In\u00a0[23]: Copied! <pre>sdata\n</pre> sdata Out[23]: <pre>SpatialData object with:\n\u251c\u2500\u2500 Images\n\u2502     \u2514\u2500\u2500 'image': SpatialImage[cyx] (4, 2048, 2048)\n\u251c\u2500\u2500 Points\n\u2502     \u2514\u2500\u2500 'transcripts': DataFrame with shape: (&lt;Delayed&gt;, 4) (3D points)\n\u251c\u2500\u2500 Shapes\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries': GeoDataFrame shape: (400, 1) (2D shapes)\n\u2502     \u251c\u2500\u2500 'cellpose_boundaries+large_cells': GeoDataFrame shape: (380, 1) (2D shapes)\n\u2502     \u2514\u2500\u2500 'large_cells': GeoDataFrame shape: (4, 1) (2D shapes)\n\u2514\u2500\u2500 Tables\n      \u251c\u2500\u2500 'old_table': AnnData (400, 5)\n      \u2514\u2500\u2500 'table': AnnData (380, 5)\nwith coordinate systems:\n\u25b8 'global', with elements:\n        image (Images), transcripts (Points), cellpose_boundaries (Shapes), cellpose_boundaries+large_cells (Shapes), large_cells (Shapes)\n\u25b8 'microns', with elements:\n        transcripts (Points)</pre> <p>Now, we can update the Xenium Explorer.</p> <p>For this, we provide <code>mode=\"-it\"</code>, which means that images and transcripts will not be computed again. This is particular useful to save time: since we already have these files, they don't need to be updated.</p> In\u00a0[24]: Copied! <pre>sopa.io.write(\n    explorer_path,\n    sdata,\n    shapes_key=\"cellpose_boundaries+large_cells\",\n    gene_column=\"genes\",\n    mode=\"-it\",\n)\n</pre> sopa.io.write(     explorer_path,     sdata,     shapes_key=\"cellpose_boundaries+large_cells\",     gene_column=\"genes\",     mode=\"-it\", ) <pre>[INFO] (sopa.io.explorer.table) Writing table with 5 columns\n[INFO] (sopa.io.explorer.table) Writing 4 cell categories: region, slide, leiden, lasso\n[INFO] (sopa.io.explorer.shapes) Writing 380 cell polygons\n[INFO] (sopa.io.explorer.converter) Saved files in the following directory: tuto.explorer\n[INFO] (sopa.io.explorer.converter) You can open the experiment with 'open tuto.explorer/experiment.xenium'\n</pre> <p>It will lead to the following visualization, i.e. the old cells with an overlay of the cells that we selected with the lasso tool:</p>"},{"location":"tutorials/xenium_explorer/explorer/#update-the-cell-categoriesclusters","title":"Update the cell categories/clusters\u00b6","text":"<p>Here, we run some Leiden clustering with <code>scanpy</code>. Then, we will update the Xenium Explorer files to display the spot clusters.</p> <p>More generally, you can add new cell categories, i.e. a column of <code>sdata.table.obs</code>, and the Xenium Explorer will show it after the instructions below.</p> <p>Note that we only display categorical columns. If a column from <code>sdata.table.obs</code> contains continuous numerical values (e.g., <code>3.13, 7.89, ...</code>), it will not be transformed into a categorical variable, and therefore not shown in the Xenium Explorer. In this case, we recommend using the <code>spatiadata_plot</code> static plotting library or the <code>napari_spatialdata</code> interactive plotting library.</p>"},{"location":"tutorials/xenium_explorer/explorer/#use-the-coordinates-of-a-lasso-selection-in-spatialdata","title":"Use the coordinates of a lasso selection in <code>SpatialData</code>\u00b6","text":"<p>On the Xenium Explorer, you can use the Lasso or Rectangular selection tools to select some regions of interest. Then, you'll be able to analyze back this region of interest using <code>spatialdata</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#selecting-cells-from-a-selection","title":"Selecting cells from a selection\u00b6","text":"<p>After making a selection, click on \"Download Cell Stats as CSV\", as below. It will create a file called <code>\"Selection_1_cells_stats.csv\"</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#cropping-a-spatialdata-object-from-a-selection","title":"Cropping a <code>SpatialData</code> object from a selection\u00b6","text":"<p>You can also export the whole selection as a polygon and use it to crop the <code>spatialdata</code> object. For that, click on \"Download Selection Coordinates as CSV\", as below. It will create a file called <code>\"Selection_1_coordinates.csv\"</code>.</p>"},{"location":"tutorials/xenium_explorer/explorer/#segmentation-overlay","title":"Segmentation overlay\u00b6","text":"<p>Sometimes, you may need to select specific cells and update the segmentation accordingly. This can be specifically inetresting when you have multinucleated giant cells (MGC), which are difficult to segment. In that case, you can perform multiple lasso selections in the Xenium Explorer, and then download them all into one single file, as below.</p> <p>Then, we can load the selection coordinates and save it as new <code>sdata</code> key. Here, we call it <code>\"large_cells\"</code>.</p> <p>Note: if not using Xenium data, please provide the <code>pixel_size</code> argument in the <code>sopa.io.add_explorer_selection</code> function below (the <code>pixel_size</code> should be the one that has been used when running Sopa). If you used the snakemake pipeline, this argument can be found in the config. Without this, the polygon may not be in the right coordinate system.</p>"}]}